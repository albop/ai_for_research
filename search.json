[
  {
    "objectID": "session_1/index.html#how-to-deal-with-text",
    "href": "session_1/index.html#how-to-deal-with-text",
    "title": "From Text Analysis…",
    "section": "How to deal with text?",
    "text": "How to deal with text?\n\nRecall: big data contains heterogenous data\n\ntext / images / sound",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#example-1-fomc-meetings",
    "href": "session_1/index.html#example-1-fomc-meetings",
    "title": "From Text Analysis…",
    "section": "Example 1: FOMC meetings",
    "text": "Example 1: FOMC meetings\nTaking the Fed at its Word: A New Approach to Estimating Central Bank Objectives using Text Analysis, Shapiro and Wilson (2022)\n\nRemember the Taylor rule for central banks?\nGeneralized version: \\(i_t = \\alpha_\\pi (\\pi_t-\\pi^{\\star}) + \\alpha_y (y_t-y)\\)\nIs there a way to measure the preferences of the central bank? (coefficients and inflation target?)\nTraditional way: look at CB decisions ex post + run a regression\nShapiro and Wilson: let’s look at the FOMC meeting transcripts\nExcerpts (there are tons of them: 704,499)\n\n\n\n\nI had several conversations at Jackson Hole with Wall Street economists and journalists, and they said, quite frankly, that they really do not believe that our effective inflation target is 1 to 2 percent. They believe we have morphed into 1+1/2 to 2+1/2 percent, and no one thought that we were really going to do anything over time to bring it down to 1 to 2.\n\nSep 2006 St. Louis Federal Reserve President William Poole\n\n\n\nLike most of you, I am not at all alarmist about inflation. I think the worst that is likely to happen would be 20 or 30 basis points over the next year. But even that amount is a little disconcerting for me. I think it is very important for us to maintain our credibility on inflation and it would be somewhat expensive to bring that additional inflation back down.\n\nMarch 2006 Chairman Ben Bernanke\n\n\n\nWith inflation remaining at such rates, we could begin to lose credibility if markets mistakenly inferred that our comfort zone had drifted higher. When we stop raising rates, we ought to be reasonably confident that policy is restrictive enough to bring inflation back toward the center of our comfort zone, which I believe is 1+1/2 percent…So for today, we should move forward with an increase of 25 basis points…\n\nJan 2006 Chicago Federal Reserve President Michael Moskow",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#example-2",
    "href": "session_1/index.html#example-2",
    "title": "From Text Analysis…",
    "section": "Example 2",
    "text": "Example 2\n\n\n\n\n\n\nSuppose you work in the trading floor of a financial institution\nThese kind of tweets have disturbing impact on the markets. You need to react quickly.\nYou need a machine to assess the risk in real time.\nMore generally, tweeter is a quite unique source of real-time data\nHow do you analyse the content of the tweets?\nComment: actually it’s not only the content of the tweets, but who reads, who retweets: graph analysis",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#text-mining-what-can-we-extract-from-texts",
    "href": "session_1/index.html#text-mining-what-can-we-extract-from-texts",
    "title": "From Text Analysis…",
    "section": "Text-mining: what can we extract from texts",
    "text": "Text-mining: what can we extract from texts\n\nThe main branches of text analysis are:\n\nsentiment analysis (today)\n\nassociate positivity/negativity score to a text\nprecise meaning of “sentiment” is context dependent\n\n\ntopic modeling\n\nclassify texts as belonging to known categories (supervised)\nfinding likely texts (unsupervised)\n\nnamed-entity recognition\n\nfind who gets mentioned in the text\nexample: A Cross-verified Database of Notable People, 3500BC-2018AD\n\nevent-extraction\n\nrecognize mention of events\n\n…",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#clarification",
    "href": "session_1/index.html#clarification",
    "title": "From Text Analysis…",
    "section": "Clarification",
    "text": "Clarification\n\n\nText analysis / text mining are somewhat used interchangeably\nIn general they consist in quantifying information used in a text…\n… so that it can be incorporated in machine learning analysis\nRecently, deep learning (and GPT-3) has changed this state of facts:\n\nsome models get trained direcly on text (intermediary phases are not explicited)",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#the-even-less-glamorous-part",
    "href": "session_1/index.html#the-even-less-glamorous-part",
    "title": "From Text Analysis…",
    "section": "The even-less glamorous part",
    "text": "The even-less glamorous part\n\n\nbefore getting started with text analysis, one needs to get hold of the text in the first place\n\nhow to extract\n\nwebscraping: automate a bot to visit website and download text\ndocument extraction: for instance extract the text from pdf docs, get rid of everything irrelevant\n\n\nhow to store it\n\nwhat kind of database?\nimportant problem when database is big",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#processing-steps",
    "href": "session_1/index.html#processing-steps",
    "title": "From Text Analysis…",
    "section": "Processing steps",
    "text": "Processing steps\n\nLet’s briefly see how text gets processed.\nGoal is to transform the text into a numerical vector of features\n\nStupid approach: “abc”-&gt;[1,2,3]\nwe need to capture some form of language structure\n\nAll the steps can be done fairly easily with nltk\n\nnltk is comparable to sklearn in terms of widespread adoption",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#processing-steps-2",
    "href": "session_1/index.html#processing-steps-2",
    "title": "From Text Analysis…",
    "section": "Processing steps (2)",
    "text": "Processing steps (2)\n\nSteps:\n\ntokenization\nstopwords\nlexicon normalization\n\nstemming\nlemmatization\n\nPOS tagging",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#tokenization",
    "href": "session_1/index.html#tokenization",
    "title": "From Text Analysis…",
    "section": "Tokenization",
    "text": "Tokenization\n\n\n\nTokenization: split input into atomic elements.\n\nWe can recognize sentences.\n\nOr words.\n\nIt is enough for some basic analysis:\n\n\nfrom nltk.probability import FreqDist\nfdist = FreqDist(words)\nprint(fdist.most_common(2))\n[('It', 1), (\"'s\", 1)]\n\n\n\n\nfrom nltk.tokenize import sent_tokenize\ntxt = \"\"\"Animal Farm is a short novel by George Orwell. It was\nwritten during World War II and published in 1945. It is about \na group of farm animals who rebel against their farmer. They \nhope to create a place where the animals can be equal, free,\n and happy.\"\"\"\nsentences  = sent_tokenize(txt)\nprint(sentences)\n\n\n['Animal Farm is a short novel by George Orwell.',\n 'It was\\nwritten during World War II and published in 1945.', \n 'It is about \\na group of farm animals who rebel against their farmer.', \n 'They \\nhope to create a place where the animals can be equal, free,\\n and happy.']\n\n\nfrom nltk.tokenize import word_tokenize\ntxt = \"It's a beautiful thing, the destruction of words.\"\nwords  = word_tokenize(txt)\nprint(words)\n['It', \"'s\", 'a', 'beautiful', 'thing', ',', 'the', 'destruction', 'of', 'words', '.']",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#part-of-speech-tagging",
    "href": "session_1/index.html#part-of-speech-tagging",
    "title": "From Text Analysis…",
    "section": "Part-of speech tagging",
    "text": "Part-of speech tagging\n\n\n\nSometimes we need information about the kind of tokens that we have\n\nWe can perform part-of-speech tagging (aka grammatical tagging)\n\nThis is useful to refine interpretation of some words\n\n“it’s not a beautiful thing”\nvs “it’s a beautiful thing”\nconnotation of beautiful changes\n\n\n\n\nfrom nltk.tokenize import word_tokenize\ntagged = nltk.pos_tag(words)\ntagged\n[('It', 'PRP'),\n (\"'s\", 'VBZ'),\n ('a', 'DT'),\n ('beautiful', 'JJ'),\n ('thing', 'NN'),\n (',', ','),\n ('the', 'DT'),\n ('destruction', 'NN'),\n ('of', 'IN'),\n ('words', 'NNS'),\n ('.', '.')]",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#simplifying-the-text-1-stopwords",
    "href": "session_1/index.html#simplifying-the-text-1-stopwords",
    "title": "From Text Analysis…",
    "section": "Simplifying the text (1): stopwords",
    "text": "Simplifying the text (1): stopwords\n\n\n\nSome words are very frequent and carry no useful meaning\n\n\nThey are called stopwords\n\n\nWe typically remove them from our word list\n\n\n\n\nfrom nltk.corpus import stopwords\nstop_words=set(stopwords.words(\"english\"))\nprint(stop_words)\n{'their', 'then', 'not', 'ma', 'here', ...}\n\n\n\nfiltered_words = [w for w in words if w not in stop_words]\nfiltered_words\n['beautiful', 'thing' 'destruction', 'words']",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#simplifying-the-text-2-lexicon-normalization",
    "href": "session_1/index.html#simplifying-the-text-2-lexicon-normalization",
    "title": "From Text Analysis…",
    "section": "Simplifying the text (2): lexicon normalization",
    "text": "Simplifying the text (2): lexicon normalization\n\n\n\nSometimes, there are several variants of a given word\n\ntight, tightening, tighten\n\n\nStemming: keeping the word root\n\nLemmatization: keeps the word base\n\nlinguistically correct contrary to stemming\n\n\n\n\nfrom nltk.stem import PorterStemmer\nps = PorterStemmer()\n\nwords =  [\"tight\", \"tightening\", \"tighten\"]\nstemmed_words=[ps.stem(w) for w in words]\n['tight', 'tighten', 'tighten']\n\n\nfrom nltk.stem.wordnet import WordNetLemmatizer\nlem = WordNetLemmatizer()\n\nwords =  [\"flying\", \"flyers\", \"fly\"]\nstemmed_words=[ps.stem(w) for w in words]\nlemmatized_words=[lem.lemmatize(w) for w in words]\n# lemmatized\n['flying', 'flyer', 'fly']\n# stemmed\n['fli', 'flyer', 'fli']",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#sentiment-analysis-1",
    "href": "session_1/index.html#sentiment-analysis-1",
    "title": "From Text Analysis…",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\n\nWhat do we do now that we have reduced a text to a series of word occurrences?\nTwo main approaches:\n\nlexical analysis\nmachine learning",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#lexical-analysis",
    "href": "session_1/index.html#lexical-analysis",
    "title": "From Text Analysis…",
    "section": "Lexical analysis",
    "text": "Lexical analysis\n\nUse a “sentiment dictionary” to provide a value (positive or negative) for each word\n\nsum the weights to get positive or negative sentiment\n\n\nExample: \\[\\underbrace{\\text{Sadly}}_{-}\\text{, there wasn't a glimpse of }\\underbrace{\\text{light}}_{+} \\text{ in his } \\text{world } \\text{ of intense }\\underbrace{\\text{suffering.}}_{-}\\]\n\nTotal:\n\n-1+1-1. Sentiment is negative.\n\n\nProblems:\n\nhere, taking grammar into account would change everything\ndoesn’t capture irony\nour dictionary doesn’t have weights for what matters to us \\[ \\text{the central bank forecasts increased }\\underbrace{\\text{inflation}}_{?}\\]",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#machine-learning",
    "href": "session_1/index.html#machine-learning",
    "title": "From Text Analysis…",
    "section": "Machine learning",
    "text": "Machine learning\n\nIdea: we would like the weights to be endogenously determined \\[ \\underbrace{\\text{the}}_{x_1} \\underbrace{\\text{ central}}_{x_2} \\underbrace{\\text{ bank}}_{x_3} \\underbrace{\\text{ forecasts}}_{x_4} \\underbrace{\\text{ increased} }_{x_5} \\underbrace{\\text{ inflation}}_{x_6}\\]\nSuppose we had several texts: we can generate features by counting words in each of them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthe\ncentral\nbank\nforecasts\nincreased\ninflation\neconomy\nexchange rate\ncrisis\nsentiment\n\n\n\n\ntext1\n1\n1\n2\n1\n1\n2\n\n\n\n-1\n\n\ntext2\n3\n\n\n\n\n1\n1\n2\n\n+1\n\n\ntext3\n4\n\n1\n\n\n1\n\n1\n1\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can the train the model: \\(y = x_1 f(w_1) + \\cdots x_K f(w_K)\\) where \\(y\\) is the sentiment and \\(w_i\\) is wordcount of word \\(w_i\\)\n\nof course, we need a similar procedure as before (split the training set and evaluation set, …)\nwe can use any model (like naive bayesian updating)\n\nThis approach is called Bag of Words (BOW)",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#some-issues",
    "href": "session_1/index.html#some-issues",
    "title": "From Text Analysis…",
    "section": "Some issues",
    "text": "Some issues\n\nBag of words has a few pitfalls:\n\nit requires a big training set with labels\nit overweights long documents\nthere is noise due to the very frequent words that don’t affect sentiment\nordering of words / grammar plays no role\n\nImprovement: TF-IDF\n\nstands for Term-Frequency*Inverse-Distribution-Frequency\nreplace word frequency \\(f(w)\\) by \\[\\text{tf-idf} = f(w)\\frac{\\text{number of documents}}{\\text{number of documents containing $w$}}\\]",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1/index.html#deep-learning",
    "href": "session_1/index.html#deep-learning",
    "title": "From Text Analysis…",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\n\n\n\nNeural networks have become very popular.\nA classification problem would look like: \\[c = f(x_1, ..., x_n;\n\\theta)\\] where \\(f\\) is a nonlinear function and \\(\\theta\\) is an unknown vector of parameters\nOr even \\[c = f(\\text{full_text};\\theta)\\]\n\nwhich could potentially capture meaning embedded in syntax\nmany possible versions of \\(f\\) (network topologies)\n\nProblem?\n\ndeep parameters require a bigger dataset\n\nPossible remedy: learn from a wider, more general dataset =&gt; transfer learning",
    "crumbs": [
      "From Text Analysis…"
    ]
  },
  {
    "objectID": "session_1_3/index.html#classification-problem",
    "href": "session_1_3/index.html#classification-problem",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Classification problem",
    "text": "Classification problem\n\nBinary Classification\n\nGoal is to make a prediction \\(c_n = f(x_{1,1}, ... x_{k,n})\\) …\n…where \\(c_i\\) is a binary variable (\\(\\in\\{0,1\\}\\))\n… and \\((x_{i,n})_k\\), \\(k\\) different features to predict \\(c_n\\)\n\nMulticategory Classification\n\nThe variable to predict takes values in a non ordered set with \\(p\\) different values"
  },
  {
    "objectID": "session_1_3/index.html#logistic-regression",
    "href": "session_1_3/index.html#logistic-regression",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Logistic regression",
    "text": "Logistic regression\n\n\n\nGiven a regression model (a linear predictor) \\[ a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n \\]\none can build a classification model: \\[ f(x_1, ..., x_n) = \\sigma( a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n )\\] where \\(\\sigma(x)=\\frac{1}{1+\\exp(-x)}\\) is the logistic function a.k.a. sigmoid\nThe loss function to minimize is: \\[L() = \\sum_n (c_n - \\sigma( a_{0} + a_1 x_{1,n} + a_2 x_{2,n} + \\cdots a_k x_{k,n} ) )^2\\]\nThis works for any regression model (LASSO, RIDGE, nonlinear…)"
  },
  {
    "objectID": "session_1_3/index.html#logistic-regression-1",
    "href": "session_1_3/index.html#logistic-regression-1",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nThe linear model predicts an intensity/score (not a category) \\[ f(x_1, ..., x_n) = \\sigma( \\underbrace{a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n }_{\\text{score}})\\]\nTo make a prediction: round to 0 or 1."
  },
  {
    "objectID": "session_1_3/index.html#multinomial-regression",
    "href": "session_1_3/index.html#multinomial-regression",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Multinomial regression",
    "text": "Multinomial regression\n\n\nIf there are \\(P\\) categories to predict:\n\nbuild a linear predictor \\(f_p\\) for each category \\(p\\)\nlinear predictor is also called score\n\nTo predict:\n\nevaluate the score of all categories\nchoose the one with highest score\n\nTo train the model:\n\ntrain separately all scores (works for any predictor, not just linear)\n… there are more subtle approaches (not here)"
  },
  {
    "objectID": "session_1_3/index.html#common-classification-algorithms",
    "href": "session_1_3/index.html#common-classification-algorithms",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Common classification algorithms",
    "text": "Common classification algorithms\nThere are many:\n\nLogistic Regression\nNaive Bayes Classifier\nNearest Distance\nneural networks (replace score in sigmoid by n.n.)\nDecision Trees\nSupport Vector Machines"
  },
  {
    "objectID": "session_1_3/index.html#nearest-distance",
    "href": "session_1_3/index.html#nearest-distance",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Nearest distance",
    "text": "Nearest distance\n\n\n\nIdea:\n\nin order to predict category \\(c\\) corresponding to \\(x\\) find the closest point \\(x_0\\) in the training set\nAssign to \\(x\\) the same category as \\(x_0\\)\n\nBut this would be very susceptible to noise\nAmended idea: \\(k-nearest\\) neighbours\n\nlook for the \\(k\\) points closest to \\(x\\)\nlabel \\(x\\) with the same category as the majority of them\n\nRemark: this algorithm uses Euclidean distance. This is why it is important to normalize the dataset."
  },
  {
    "objectID": "session_1_3/index.html#decision-tree-random-forests",
    "href": "session_1_3/index.html#decision-tree-random-forests",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Decision Tree / Random Forests",
    "text": "Decision Tree / Random Forests\n\n\n\nDecision Tree\n\nrecursively find simple criteria to subdivide dataset\n\nProblems:\n\nGreedy: algorithm does not simplify branches\neasily overfits\n\nExtension : random tree forest\n\nuses several (randomly generated) trees to generate a prediction\nsolves the overfitting problem"
  },
  {
    "objectID": "session_1_3/index.html#support-vector-classification",
    "href": "session_1_3/index.html#support-vector-classification",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Support Vector Classification",
    "text": "Support Vector Classification\n\n\n\n\nSeparates data by one line (hyperplane).\n\nChooses the largest margin according to support vectors\n\nCan use a nonlinear kernel."
  },
  {
    "objectID": "session_1_3/index.html#all-these-algorithms-are-super-easy-to-use",
    "href": "session_1_3/index.html#all-these-algorithms-are-super-easy-to-use",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "All these algorithms are super easy to use!",
    "text": "All these algorithms are super easy to use!\nExamples:\n\nDecision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\n\n\nSupport Vector\n\nfrom sklearn.svm import SVC\nclf = SVC(random_state=0)\n\n\n\nRidge Regression\n\nfrom sklearn.linear_model import Ridge\nclf = Ridge(random_state=0)"
  },
  {
    "objectID": "session_1_3/index.html#validity-of-a-classification-algorithm",
    "href": "session_1_3/index.html#validity-of-a-classification-algorithm",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Validity of a classification algorithm",
    "text": "Validity of a classification algorithm\n\nIndependently of how the classification is made, its validity can be assessed with a similar procedure as in the regression.\nSeparate training set and test set\n\ndo not touch test set at all during the training\n\nCompute score: number of correctly identified categories\n\nnote that this is not the same as the loss function minimized by the training"
  },
  {
    "objectID": "session_1_3/index.html#classification-matrix",
    "href": "session_1_3/index.html#classification-matrix",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Classification matrix",
    "text": "Classification matrix\n\nFor binary classification, we focus on the classification matrix or confusion matrix.\n\n\n\n\nPredicted\n(0) Actual\n(1) Actual\n\n\n\n\n0\ntrue negatives (TN)\nfalse negatives (FN)\n\n\n1\nfalse positives (FP)\ntrue positives (TP)\n\n\n\n\nWe can then define different measures:\n\nSensitivity aka True Positive Rate (TPR): \\(\\frac{TP}{FP+TP}\\)\nFalse Positive Rate (FPR): \\(\\frac{FP}{TN+FP}\\)\nOverall accuracy: \\(\\frac{\\text{TN}+\\text{TP}}{\\text{total}}\\)\n\n\n\nWhich one to favour depends on the use case"
  },
  {
    "objectID": "session_1_3/index.html#example-london-police",
    "href": "session_1_3/index.html#example-london-police",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Example: London Police",
    "text": "Example: London Police\n\nPolice cameras in LondonAccording to London Police the cameras in London have\n\nTrue Positive Identification rate of over 80% at a fixed number of False Positive Alerts.29 nov. 2022\n\n\nInterpretation? Is failure rate too high?"
  },
  {
    "objectID": "session_1_3/index.html#example",
    "href": "session_1_3/index.html#example",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Example",
    "text": "Example\n\nIn-sample confusion matrixBased on consumer data, an algorithm tries to predict the credit score from.\nCan you calculate: FPR, TPR and overall accuracy?"
  },
  {
    "objectID": "session_1_3/index.html#confusion-matrix-with-sklearn",
    "href": "session_1_3/index.html#confusion-matrix-with-sklearn",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Confusion matrix with sklearn",
    "text": "Confusion matrix with sklearn\n\nPredict on the test set:\n\ny_pred = model.predict(x_test)\n\nCompute confusion matrix:\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)"
  },
  {
    "objectID": "session_1_3/graphs/Untitled1.html",
    "href": "session_1_3/graphs/Untitled1.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport statsmodels.api as sm\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\ncount\n45.000000\n45.000000\n45.000000\n\n\nmean\n41.866667\n52.555556\n47.688889\n\n\nstd\n24.435072\n29.760831\n31.510332\n\n\nmin\n7.000000\n7.000000\n3.000000\n\n\n25%\n21.000000\n26.000000\n16.000000\n\n\n50%\n42.000000\n45.000000\n41.000000\n\n\n75%\n64.000000\n84.000000\n81.000000\n\n\nmax\n81.000000\n100.000000\n97.000000\n\n\n\n\n\n\n\n\ndf.cov()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\nincome\n597.072727\n526.871212\n645.071212\n\n\neducation\n526.871212\n885.707071\n798.904040\n\n\nprestige\n645.071212\n798.904040\n992.901010\n\n\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(figsize=(8,6))\nplt.plot(df['education'],df['income'],'o')\nplt.grid()\nplt.xlabel(\"x (Education)\")\nplt.ylabel(\"y (Income)\")\nplt.savefig(\"data_description.png\")\n\n\n\n\n\n\n\n\n\nfor i in [1,2,3]:\n    xvec = np.linspace(10,100)\n\n    plt.figure(figsize=(12,8))\n    plt.plot(df['education'],df['income'],'o')\n\n    plt.plot(xvec, xvec * 0 + 50)\n    if i&gt;=2:\n        plt.plot(xvec, xvec )\n    if i&gt;=3:\n        plt.plot(xvec,  90- 0.6*xvec )\n\n    plt.grid()\n    plt.xlabel(\"x (Education)\")\n    plt.ylabel(\"y (Income)\")\n    plt.savefig(f\"which_line_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ipywidgets import interact\n\n\nimport matplotlib.patches as patches\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nplt.vlines(x, y+h, y, color='red')\n\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"error_0.png\")\n\n\n\n\n\n\n\n\n\nplt.vlines?\n\n\nSignature:\nplt.vlines(\n    x,\n    ymin,\n    ymax,\n    colors=None,\n    linestyles='solid',\n    label='',\n    *,\n    data=None,\n    **kwargs,\n)\nDocstring:\nPlot vertical lines.\nPlot vertical lines at each *x* from *ymin* to *ymax*.\nParameters\n----------\nx : float or array-like\n    x-indexes where to plot the lines.\nymin, ymax : float or array-like\n    Respective beginning and end of each line. If scalars are\n    provided, all lines will have same length.\ncolors : list of colors, default: :rc:`lines.color`\nlinestyles : {'solid', 'dashed', 'dashdot', 'dotted'}, optional\nlabel : str, default: ''\nReturns\n-------\n`~matplotlib.collections.LineCollection`\nOther Parameters\n----------------\n**kwargs : `~matplotlib.collections.LineCollection` properties.\nSee Also\n--------\nhlines : horizontal lines\naxvline: vertical line across the axes\nNotes\n-----\n.. note::\n    In addition to the above described arguments, this function can take\n    a *data* keyword argument. If such a *data* argument is given,\n    the following arguments can also be string ``s``, which is\n    interpreted as ``data[s]`` (unless this raises an exception):\n    *x*, *ymin*, *ymax*, *colors*.\n    Objects passed as **data** must support item access (``data[s]``) and\n    membership test (``s in data``).\nFile:      ~/.local/opt/miniconda/lib/python3.8/site-packages/matplotlib/pyplot.py\nType:      function\n\n\n\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nif p-y&gt;0:\n    # Create a Rectangle patch\n    rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n    ax.add_patch(rect)\n    \nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"errors_{1}.png\")\n\n\n\n\n\n\n\n\n\ndef L(a,b):\n    Δ = a + b*df['education'] - df['income']\n    return (Δ**2).sum()\n\n\na = 0.1\nb = 0.8\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_2.png\")\n\n\n\n\n\n\n\n\n\na = 90\nb = -0.6\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_3.png\")\n\n\n\n\n\n\n\n\n\nimport scipy.optimize\n\n\nscipy.optimize.minimize(lambda x: L(x[0], x[1]),np.array([0.5, 0.5]))\n\n      fun: 12480.970174488397\n hess_inv: array([[ 7.14169839e-09, -3.91281920e-09],\n       [-3.91281920e-09,  2.46663613e-09]])\n      jac: array([0.00024414, 0.00012207])\n  message: 'Desired error not necessarily achieved due to precision loss.'\n     nfev: 57\n      nit: 7\n     njev: 19\n   status: 2\n  success: False\n        x: array([10.60350224,  0.59485938])\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_4.png\")\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red', alpha=0.5)\n\nplt.plot(60, a + b*60, 'o', color='red',)\n\nprint(a+b*60)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"prediction.png\")\n\n45.4\n\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  (a + b*df['education'] - df['income'])\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(121)\nplt.plot(approx)\nplt.grid(False)\nplt.title(\"Residuals\")\n\n\nplt.subplot(122)\ndistplot(approx)\nplt.title(\"Distribution of residuals\")\nplt.grid()\n\nplt.savefig(\"residuals.png\")\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\n(a + b*df['education'] - df['income']).std()\n\n16.842782676352154\n\n\n\n\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f\n\n\nf(0.3)\n\nTypeError: _parse_args() missing 1 required positional argument: 'dfd'\n\n\n\nnp.rand\n\n\nK = 100\nxvec = np.linspace(0,1,K)\ne1 = np.random.randn(K)*0.1\nyvec = 0.1 + xvec*0.4 + e1\ne2 = np.random.randn(K)*0.05\nyvec2 = 0.1 + xvec*(xvec-1)/2 + e2\ne3 = np.random.randn(K)*xvec/2\nyvec3 = 0.1 + xvec + e3\n\nyvec4 = 0.1 + np.sin(xvec*6) + np.random.randn(K)*xvec/2\n\n\nfrom dolo.numeric.processes import VAR1\n\n\nsim = VAR1( ρ=0.8, Σ=0.001).simulate(N=1,T=100)\nyvec4 = 0.1 + xvec*0.4 + sim.ravel()\n\n\nplt.figure(figsize=(18,6))\nplt.subplot(241)\nplt.plot(xvec, yvec,'o')\nplt.plot(xvec, 0.1 + xvec*0.4 )\nplt.ylabel(\"Series\")\nplt.title(\"white noise\")\nplt.subplot(242)\nplt.plot(xvec, yvec2, 'o')\nplt.plot(xvec, yvec2*0)\nplt.title('nonlinear')\nplt.subplot(243)\nplt.plot(xvec, yvec3,'o')\nplt.plot(xvec, 0.1 + xvec)\nplt.title('heteroskedastic')\nplt.subplot(244)\nplt.plot(xvec, yvec4,'o')\nplt.plot(xvec, xvec*0.6)\n\nplt.title('correlated')\n\n\nplt.subplot(245)\nplt.plot(xvec, e1,'o')\nplt.ylabel(\"Residuals\")\nplt.subplot(246)\nplt.plot(xvec, yvec2-0.075, 'o')\n\nplt.subplot(247)\nplt.plot(xvec, e3,'o')\nplt.subplot(248)\nplt.plot(xvec, sim.ravel(),'o')\n\nplt.tight_layout()\n\nplt.savefig(\"residuals_circus.png\")"
  },
  {
    "objectID": "exercises/pushups_2.html",
    "href": "exercises/pushups_2.html",
    "title": "Python Pushups (2)",
    "section": "",
    "text": "Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\nt = (2,2,4)\n\n\n# change first element of t\n\n\n# appending to t\n\n\n# sorting t\n\n\n# this works and returns a new list\nsorted(t)\n\n[2, 2, 4]\n\n\n\n# reversing t\n\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\n\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\n\n\n\n\nExplain what happens to the value you popped.\nExperiment with calling pop twice."
  },
  {
    "objectID": "exercises/pushups_2.html#tuples-and-dictionaries",
    "href": "exercises/pushups_2.html#tuples-and-dictionaries",
    "title": "Python Pushups (2)",
    "section": "",
    "text": "Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\nt = (2,2,4)\n\n\n# change first element of t\n\n\n# appending to t\n\n\n# sorting t\n\n\n# this works and returns a new list\nsorted(t)\n\n[2, 2, 4]\n\n\n\n# reversing t\n\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\n\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\n\n\n\n\nExplain what happens to the value you popped.\nExperiment with calling pop twice."
  },
  {
    "objectID": "exercises/pushups_2_correction.html",
    "href": "exercises/pushups_2_correction.html",
    "title": "Pushups 2",
    "section": "",
    "text": "Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\nt = (2,2,4)\n\n\n# change first element of t\nt[0] = 100\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n# appending to t\nt.append(3)\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\n# sorting t\nt.sort()\n\nAttributeError: 'tuple' object has no attribute 'sort'\n\n\n\n# this works and returns a new list\nsorted(t)\n\n[2, 2, 4]\n\n\n\n# reversing t\nt.reverse()\n\nAttributeError: 'tuple' object has no attribute 'reverse'\n\n\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n{\n    \"AAPL\": 175.96,\n    \"GOOGL\": 1047.43,\n    \"TVIX\": 8.38\n}\n\n{'AAPL': 175.96, 'GOOGL': 1047.43, 'TVIX': 8.38}\n\n\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\naustralia_data = {\n    \"coast_line\": 253760, #int\n    \"languages\": { # dict\n        \"English\": 72,\n        \"Mandarin\": 2.7,\n        \"Arabic\": 1.4,\n        \"Vietnamese\": 1.3,\n        \"Cantonese\": 1.2,\n        \"other\": 15.7,\n        \"unspecified\": 5.7\n    },\n    \"irrigated_land\": 15.210, #float\n    \"aquifers\": [\"Great Artesian Basin\", \"Canning Basin\"], # list\n    # string\n    \"population_distribution\": \"\"\"population is primarily located on the periphery, with the highest concentration of people residing in the east and southeast; a secondary population center is located in and around Perth in the west; of the States and Territories, New South Wales has, by far, the largest population; the interior, or \"outback\", has a very sparse population\"\"\"\n}\n\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\naustralia_data.pop(\"irrigated_land\")\n\n15.21\n\n\n\naustralia_data\n\n{'coast_line': 253760,\n 'languages': {'English': 72,\n  'Mandarin': 2.7,\n  'Arabic': 1.4,\n  'Vietnamese': 1.3,\n  'Cantonese': 1.2,\n  'other': 15.7,\n  'unspecified': 5.7},\n 'aquifers': ['Great Artesian Basin', 'Canning Basin'],\n 'population_distribution': 'population is primarily located on the periphery, with the highest concentration of people residing in the east and southeast; a secondary population center is located in and around Perth in the west; of the States and Territories, New South Wales has, by far, the largest population; the interior, or \"outback\", has a very sparse population'}\n\n\n\n\n\nExplain what happens to the value you popped.\n\nIt returns the value, and removes it from the dictionary object.\n\n\n'irrigated_land' in australia_data\n\nFalse\n\n\nExperiment with calling pop twice.\n\naustralia_data.pop(\"irrigated_land\")\n## errors because the key is not in the dictionary any more\n\nKeyError: 'irrigated_land'\n\n\n\n\n\n\nNote, if dbnomics is not installed on your machine, install it by running the following cell:"
  },
  {
    "objectID": "exercises/pushups_2_correction.html#tuples-and-dictionaries",
    "href": "exercises/pushups_2_correction.html#tuples-and-dictionaries",
    "title": "Pushups 2",
    "section": "",
    "text": "Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\nt = (2,2,4)\n\n\n# change first element of t\nt[0] = 100\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n# appending to t\nt.append(3)\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\n# sorting t\nt.sort()\n\nAttributeError: 'tuple' object has no attribute 'sort'\n\n\n\n# this works and returns a new list\nsorted(t)\n\n[2, 2, 4]\n\n\n\n# reversing t\nt.reverse()\n\nAttributeError: 'tuple' object has no attribute 'reverse'\n\n\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n{\n    \"AAPL\": 175.96,\n    \"GOOGL\": 1047.43,\n    \"TVIX\": 8.38\n}\n\n{'AAPL': 175.96, 'GOOGL': 1047.43, 'TVIX': 8.38}\n\n\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\naustralia_data = {\n    \"coast_line\": 253760, #int\n    \"languages\": { # dict\n        \"English\": 72,\n        \"Mandarin\": 2.7,\n        \"Arabic\": 1.4,\n        \"Vietnamese\": 1.3,\n        \"Cantonese\": 1.2,\n        \"other\": 15.7,\n        \"unspecified\": 5.7\n    },\n    \"irrigated_land\": 15.210, #float\n    \"aquifers\": [\"Great Artesian Basin\", \"Canning Basin\"], # list\n    # string\n    \"population_distribution\": \"\"\"population is primarily located on the periphery, with the highest concentration of people residing in the east and southeast; a secondary population center is located in and around Perth in the west; of the States and Territories, New South Wales has, by far, the largest population; the interior, or \"outback\", has a very sparse population\"\"\"\n}\n\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\naustralia_data.pop(\"irrigated_land\")\n\n15.21\n\n\n\naustralia_data\n\n{'coast_line': 253760,\n 'languages': {'English': 72,\n  'Mandarin': 2.7,\n  'Arabic': 1.4,\n  'Vietnamese': 1.3,\n  'Cantonese': 1.2,\n  'other': 15.7,\n  'unspecified': 5.7},\n 'aquifers': ['Great Artesian Basin', 'Canning Basin'],\n 'population_distribution': 'population is primarily located on the periphery, with the highest concentration of people residing in the east and southeast; a secondary population center is located in and around Perth in the west; of the States and Territories, New South Wales has, by far, the largest population; the interior, or \"outback\", has a very sparse population'}\n\n\n\n\n\nExplain what happens to the value you popped.\n\nIt returns the value, and removes it from the dictionary object.\n\n\n'irrigated_land' in australia_data\n\nFalse\n\n\nExperiment with calling pop twice.\n\naustralia_data.pop(\"irrigated_land\")\n## errors because the key is not in the dictionary any more\n\nKeyError: 'irrigated_land'"
  },
  {
    "objectID": "exercises/pushups_2_correction.html#prep-work-for-the-philips-curve",
    "href": "exercises/pushups_2_correction.html#prep-work-for-the-philips-curve",
    "title": "Pushups 2",
    "section": "",
    "text": "Note, if dbnomics is not installed on your machine, install it by running the following cell:"
  },
  {
    "objectID": "session_1_2/graphs/inference.html",
    "href": "session_1_2/graphs/inference.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\ndef generate_dataset(μ1, μ2, α, β, σ, N=10):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    return pd.DataFrame({'x': xvec, 'y': yvec})\n\n\ndf = generate_dataset(0.0, 1.0, 0.1, 0.8, 0.1)\n\n\nplt.plot(df['x'], df['y'], 'o')\nplt.grid()\n\n\n\n\n\n\n\n\n\ndef plot_distribution(α, β, σ, N=100000, μ1=0.0, μ2=1.0):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    plt.plot(xvec, yvec, '.r', alpha=0.005)\n    plt.plot(xvec, α + β*xvec, color='black')\n\n# missing ridge line\n\n\nimport statsmodels\n\n\nμ1 = 0\nμ2 = 1.0\nα = 0.1\nβ = 0.8\nσ = 0.2\nN = 20\nK = 1000\n\n\nimport statsmodels.formula.api as smf\n\n\ndf = generate_dataset(μ1, μ2, α, β, σ, N=N)\n\n\nres = smf.ols(formula='y ~ x + 1', data=df).fit()\nparams = res.params\nαhat = params['Intercept']\nβhat = params['x']\nσhat = res.resid.std()\n\n\nres.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ny\nR-squared:\n0.692\n\n\nModel:\nOLS\nAdj. R-squared:\n0.675\n\n\nMethod:\nLeast Squares\nF-statistic:\n40.48\n\n\nDate:\nTue, 26 Jan 2021\nProb (F-statistic):\n5.41e-06\n\n\nTime:\n04:02:36\nLog-Likelihood:\n7.6662\n\n\nNo. Observations:\n20\nAIC:\n-11.33\n\n\nDf Residuals:\n18\nBIC:\n-9.341\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.1210\n0.077\n1.565\n0.135\n-0.041\n0.283\n\n\nx\n0.7941\n0.125\n6.362\n0.000\n0.532\n1.056\n\n\n\n\n\n\nOmnibus:\n1.410\nDurbin-Watson:\n1.507\n\n\nProb(Omnibus):\n0.494\nJarque-Bera (JB):\n0.890\n\n\nSkew:\n-0.081\nProb(JB):\n0.641\n\n\nKurtosis:\n1.979\nCond. No.\n4.20\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nres.predict(df['x'])\n\n0     0.326200\n1     0.211704\n2     0.798819\n3     0.603306\n4     0.573319\n5     0.823919\n6     0.740622\n7     0.503227\n8     0.292622\n9     0.489566\n10    0.138720\n11    0.355157\n12    0.594171\n13    0.883917\n14    0.266229\n15    0.827021\n16    0.912376\n17    0.163088\n18    0.684858\n19    0.732782\ndtype: float64\n\n\n\nfor i in [1,2,3]:\n    \n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {α:.2f} + {β:.2f} x + {σ:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n\n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    if i&gt;=3:\n        plt.plot(df['x'], res.predict(), label=f'$\\hat{{α}}={αhat:.2f}; \\hat{{β}}={βhat:.2f}$')\n        plt.legend(loc='lower right')\n    plt.title(\"Random Draw\")\n    plt.grid()\n    \n    plt.savefig(f\"regression_uncertainty_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scipy.stats\n\n\ndatasets = [generate_dataset(μ1, μ2, αhat, βhat, σhat, N=N) for i in range(K)]\nall_params = [smf.ols(formula='x ~ y + 1', data=df).fit() for df in datasets]\nαvec = np.array( [e.params['Intercept'] for e in all_params] )\nβvec = np.array( [e.params['y'] for e in all_params] )\n\n\ngkd = scipy.stats.kde.gaussian_kde(βvec)\n\n\nfor i in [1,2,3,4,5,6,7,8,9,10,100]:\n\n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {αhat:.2f} + {βhat:.2f} x + {σhat:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    \n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    df = datasets[i]\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    plt.title(\"Random Draw\")\n    plt.grid()\n\n    plt.subplot(313)\n    if i==3:\n        plt.plot(βvec[i], βvec[i]*0, 'o')\n    if i&gt;4:\n        plt.plot(βvec[3:i], βvec[3:i]*0, 'o')\n    if i&gt;10:\n        xx = np.linspace(0.2, 1.4, 10000)\n        plt.plot( βvec, gkd.pdf(βvec), '.')\n    plt.title(\"Distribution of β\")\n    plt.xlim(0.2, 1.4)\n    plt.ylim(-0.1, 4)\n    plt.grid()\n\n    plt.tight_layout()\n\n    plt.savefig(f\"random_estimates_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot( βvec, βvec*0, 'o')"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html",
    "href": "tutorials/session_1/python_fundamentals/functions.html",
    "title": "Functions",
    "section": "",
    "text": "Co-author\n\n\nPhilip Solimine, UBC\n\n\nPrerequisites\n\nGetting Started\n\nBasics\n\nCollections\n\nControl Flow\n\nOutcomes\n\nEconomic Production Functions\n\nUnderstand the basics of production functions in economics\n\n\nFunctions\n\nKnow how to define your own function\n\nKnow how to find and write your own function documentation\n\nKnow why we use functions\n\nUnderstand scoping rules and blocks\n\n\n\n\n\nProduction functions are useful when modeling the economics of firms producing goods or the aggregate output in an economy.\nThough the term “function” is used in a mathematical sense here, we will be making tight connections between the programming of mathematical functions and Python functions.\n\n\nThe factors of production are the inputs used in the production of some sort of output.\nSome example factors of production include\n\nPhysical capital, e.g. machines, buildings, computers, and power stations.\n\nLabor, e.g. all of the hours of work from different types of employees of a firm.\n\nHuman Capital, e.g. the knowledge of employees within a firm.\n\nA production function maps a set of inputs to the output, e.g. the amount of wheat produced by a farm, or widgets produced in a factory.\nAs an example of the notation, we denote the total units of labor and physical capital used in a factory as $ L $ and $ K $ respectively.\nIf we denote the physical output of the factory as $ Y $, then a production function $ F $ that transforms labor and capital into output might have the form:\n\\[\nY = F(K, L)\n\\]\n\n\n\n\nThroughout this lecture, we will use the Cobb-Douglas production function to help us understand how to create Python functions and why they are useful.\nThe Cobb-Douglas production function has appealing statistical properties when brought to data.\nThis function is displayed below.\n\\[\nY = z K^{\\alpha} L^{1-\\alpha}\n\\]\nThe function is parameterized by:\n\nA parameter $ $, called the “output elasticity of capital”.\n\nA value $ z $ called the Total Factor Productivity (TFP).\n\n\n\n\n\nIn this class, we will often talk about functions.\nSo what is a function?\nWe like to think of a function as a production line in a manufacturing plant: we pass zero or more things to it, operations take place in a set linear sequence, and zero or more things come out.\nWe use functions for the following purposes:\n\nRe-usability: Writing code to do a specific task just once, and reuse the code by calling the function.\n\nOrganization: Keep the code for distinct operations separated and organized.\n\nSharing/collaboration: Sharing code across multiple projects or sharing pieces of code with collaborators.\n\n\n\n\nThe basic syntax to create our own function is as follows:\n\ndef function_name(inputs):\n    # step 1\n    # step 2\n    # ...\n    return outputs\n\nHere we see two new keywords: def and return.\n\ndef is used to tell Python we would like to define a new function.\n\nreturn is used to tell Python what we would like to return from a function.\n\nLet’s look at an example and then discuss each part:\n\ndef mean(numbers):\n    total = sum(numbers)\n    N = len(numbers)\n    answer = total / N\n\n    return answer\n\nHere we defined a function mean that has one input (numbers), does three steps, and has one output (answer).\nLet’s see what happens when we call this function on the list of numbers [1, 2, 3, 4].\n\nx = [1, 2, 3, 4]\nthe_mean = mean(x)\nthe_mean\n\nAdditionally, as we saw in the control flow lecture, indentation controls blocks of code (along with the scope rules).\nTo see this, compare a function with no inputs or return values.\n\ndef f():\n    print(\"1\")\n    print(\"2\")\nf()\n\nWith the following change of indentation…\n\ndef f():\n    print(\"1\")\nprint(\"2\")\nf()\n\n\n\n\nNotice that we named the input to the function x and we called the output the_mean.\nWhen we defined the function, the input was called numbers and the output answer… what gives?\nThis is an example of a programming concept called variable scope.\nIn Python, functions define their own scope for variables.\nIn English, this means that regardless of what name we give an input variable (x in this example), the input will always be referred to as numbers inside the body of the mean function.\nIt also means that although we called the output answer inside of the function mean, that this variable name was only valid inside of our function.\nTo use the output of the function, we had to give it our own name (the_mean in this example).\nAnother point to make here is that the intermediate variables we defined inside mean (total and N) are only defined inside of the mean function – we can’t access them from outside. We can verify this by trying to see what the value of total is:\n\ndef mean(numbers):\n    total = sum(numbers)\n    N = len(numbers)\n    answer = total / N\n    return answer # or directly return total / N\n\n# uncomment the line below and execute to see the error\n# total\n\nThis point can be taken even further: the same name can be bound to variables inside of blocks of code and in the outer “scope”.\n\nx = 4\nprint(f\"x = {x}\")\ndef f():\n    x = 5 # a different \"x\"\n    print(f\"x = {x}\")\nf() # calls function\nprint(f\"x = {x}\")\n\nThe final point we want to make about scope is that function inputs and output don’t have to be given a name outside the function.\n\nmean([10, 20, 30])\n\nNotice that we didn’t name the input or the output, but the function was called successfully.\nNow, we’ll use our new knowledge to define a function which computes the output from a Cobb-Douglas production function with parameters $ z = 1 $ and $ = 0.33 $ and takes inputs $ K $ and $ L $.\n\ndef cobb_douglas(K, L):\n\n    # Create alpha and z\n    z = 1\n    alpha = 0.33\n\n    return z * K**alpha * L**(1 - alpha)\n\nWe can use this function as we did the mean function.\n\ncobb_douglas(1.0, 0.5)\n\n\n\n\n\nEconomists are often interested in this question: how much does output change if we modify our inputs?\nFor example, take a production function $ Y_1 = F(K_1,L_1) $ which produces $ Y_1 $ units of the goods.\nIf we then multiply the inputs each by $ \\(, so that\\) K_2 = K_1 $ and $ L_2 = L_1 $, then the output is\n\\[\nY_2 = F(K_2, L_2) = F(\\gamma K_1, \\gamma L_1)\n\\]\nHow does $ Y_1 $ compare to $ Y_2 $?\nAnswering this question involves something called returns to scale.\nReturns to scale tells us whether our inputs are more or less productive as we have more of them.\nFor example, imagine that you run a restaurant. How would you expect the amount of food you could produce would change if you could build an exact replica of your restaurant and kitchen and hire the same number of cooks and waiters? You would probably expect it to double.\nIf, for any $ K, L $, we multiply $ K, L $ by a value $ $ then\n\nIf $ &lt; $ then we say the production function has decreasing returns to scale.\n\nIf $ = $ then we say the production function has constant returns to scale.\n\nIf $ &gt; $ then we say the production function has increasing returns to scale.\n\nLet’s try it and see what our function is!\n\ny1 = cobb_douglas(1.0, 0.5)\nprint(y1)\ny2 = cobb_douglas(2*1.0, 2*0.5)\nprint(y2)\n\nHow did $ Y_1 $ and $ Y_2 $ relate?\n\ny2 / y1\n\n$ Y_2 $ was exactly double $ Y_1 $!\nLet’s write a function that will compute the returns to scale for different values of $ K $ and $ L $.\nThis is an example of how writing functions can allow us to re-use code in ways we might not originally anticipate. (You didn’t know we’d be writing a returns_to_scale function when we wrote cobb_douglas.)\n\ndef returns_to_scale(K, L, gamma):\n    y1 = cobb_douglas(K, L)\n    y2 = cobb_douglas(gamma*K, gamma*L)\n    y_ratio = y2 / y1\n    return y_ratio / gamma\n\n\nreturns_to_scale(1.0, 0.5, 2.0)\n\n\n\n\nSee exercise 1 in the exercise list.\nIt turns out that with a little bit of algebra, we can check that this will always hold for our Cobb-Douglas example above.\nTo show this, take an arbitrary $ K, L $ and multiply the inputs by an arbitrary $ $.\n\\[\n\\begin{aligned}\n    F(\\gamma K, \\gamma L) &= z (\\gamma K)^{\\alpha} (\\gamma L)^{1-\\alpha}\\\\\n    &=  z \\gamma^{\\alpha}\\gamma^{1-\\alpha} K^{\\alpha} L^{1-\\alpha}\\\\\n    &= \\gamma z K^{\\alpha} L^{1-\\alpha} = \\gamma F(K, L)\n\\end{aligned}\n\\]\nFor an example of a production function that is not CRS, look at a generalization of the Cobb-Douglas production function that has different “output elasticities” for the 2 inputs.\n\\[\nY = z K^{\\alpha_1} L^{\\alpha_2}\n\\]\nNote that if $ _2 = 1 - _1 $, this is our Cobb-Douglas production function.\n\n\n\nSee exercise 2 in the exercise list.\n\n\n\n\nAnother valuable element to analyze on production functions is how output changes as we change only one of the inputs. We will call this the marginal product.\nFor example, compare the output using $ K, L $ units of inputs to that with an $ $ units of labor.\nThen the marginal product of labor (MPL) is defined as\n\\[\n\\frac{F(K, L + \\varepsilon) - F(K, L)}{\\varepsilon}\n\\]\nThis tells us how much additional output is created relative to the additional input. (Spoiler alert: This should look like the definition for a partial derivative!)\nIf the input can be divided into small units, then we can use calculus to take this limit, using the partial derivative of the production function relative to that input.\nIn this case, we define the marginal product of labor (MPL) and marginal product of capital (MPK) as\n\\[\n\\begin{aligned}\nMPL(K, L) &= \\frac{\\partial F(K, L)}{\\partial L}\\\\\nMPK(K, L) &= \\frac{\\partial F(K, L)}{\\partial K}\n\\end{aligned}\n\\]\nIn the Cobb-Douglas example above, this becomes\n\\[\n\\begin{aligned}\nMPK(K, L) &= z  \\alpha \\left(\\frac{K}{L} \\right)^{\\alpha - 1}\\\\\nMPL(K, L) &= (1-\\alpha) z \\left(\\frac{K}{L} \\right)^{\\alpha}\\\\\n\\end{aligned}\n\\]\nLet’s test it out with Python! We’ll also see that we can actually return multiple things in a Python function.\nThe syntax for a return statement with multiple items is return item1, item2, ….\nIn this case, we’ll compute both the MPL and the MPK and then return both.\n\ndef marginal_products(K, L, epsilon):\n\n    mpl = (cobb_douglas(K, L + epsilon) - cobb_douglas(K, L)) / epsilon\n    mpk = (cobb_douglas(K + epsilon, L) - cobb_douglas(K, L)) / epsilon\n\n    return mpl, mpk\n\n\ntup = marginal_products(1.0, 0.5,  1e-4)\nprint(tup)\n\nInstead of using the tuple, these can be directly unpacked to variables.\n\nmpl, mpk = marginal_products(1.0, 0.5,  1e-4)\nprint(f\"mpl = {mpl}, mpk = {mpk}\")\n\nWe can use this to calculate the marginal products for different K, fixing L using a comprehension.\n\nKs = [1.0, 2.0, 3.0]\n[marginal_products(K, 0.5, 1e-4) for K in Ks] # create a tuple for each K\n\n\n\n\nIn a previous exercise, we asked you to find help for the cobb_douglas and returns_to_scale functions using ?.\nIt didn’t provide any useful information.\nTo provide this type of help information, we need to add what Python programmers call a “docstring” to our functions.\nThis is done by putting a string (not assigned to any variable name) as the first line of the body of the function (after the line with def).\nBelow is a new version of the template we used to define functions.\n\ndef function_name(inputs):\n    \"\"\"\n    Docstring\n    \"\"\"\n    # step 1\n    # step 2\n    # ...\n    return outputs\n\nLet’s re-define our cobb_douglas function to include a docstring.\n\ndef cobb_douglas(K, L):\n    \"\"\"\n    Computes the production F(K, L) for a Cobb-Douglas production function\n\n    Takes the form F(K, L) = z K^{\\alpha} L^{1 - \\alpha}\n\n    We restrict z = 1 and alpha = 0.33\n    \"\"\"\n    return 1.0 * K**(0.33) * L**(1.0 - 0.33)\n\nNow when we have Jupyter evaluate cobb_douglas?, our message is displayed (or use the Contextual Help window with Jupyterlab and Ctrl-I or Cmd-I).\n\ncobb_douglas?\n\nWe recommend that you always include at least a very simple docstring for nontrivial functions.\nThis is in the same spirit as adding comments to your code — it makes it easier for future readers/users (including yourself) to understand what the code does.\n\n\n\nSee exercise 3 in the exercise list.\n\n\n\nFunctions can have optional arguments.\nTo accomplish this, we must these arguments a default value by saying name=default_value instead of just name as we list the arguments.\nTo demonstrate this functionality, let’s now make $ z $ and $ $ arguments to our cobb_douglas function!\n\ndef cobb_douglas(K, L, alpha=0.33, z=1):\n    \"\"\"\n    Computes the production F(K, L) for a Cobb-Douglas production function\n\n    Takes the form F(K, L) = z K^{\\alpha} L^{1 - \\alpha}\n    \"\"\"\n    return z * K**(alpha) * L**(1.0 - alpha)\n\nWe can now call this function by passing in just K and L. Notice that it will produce same result as earlier because alpha and z are the same as earlier.\n\ncobb_douglas(1.0, 0.5)\n\nHowever, we can also set the other arguments of the function by passing more than just K/L.\n\ncobb_douglas(1.0, 0.5, 0.35, 1.6)\n\nIn the example above, we used alpha = 0.35, z = 1.6.\nWe can also refer to function arguments by their name, instead of only their position (order).\nTo do this, we would write func_name(arg=value) for as many of the arguments as we want.\nHere’s how to do that with our cobb_douglas example.\n\ncobb_douglas(1.0, 0.5, z = 1.5)\n\n\n\n\nSee exercise 4 in the exercise list.\nIn terms of variable scope, the z name within the function is different from any other z in the outer scope.\nTo be clear,\n\nx = 5\ndef f(x):\n    return x\nf(x) # \"coincidence\" that it has the same name\n\nThis is also true with named function arguments, above.\n\nz = 1.5\ncobb_douglas(1.0, 0.5, z = z) # no problem!\n\nIn that example, the z on the left hand side of z = z refers to the local variable name in the function whereas the z on the right hand side refers to the z in the outer scope.\n\n\n\nAs we learned earlier, all variables in Python have a type associated with them.\nDifferent types of variables have different functions or operations defined for them.\nFor example, I can divide one number by another or make a string uppercase.\nIt wouldn’t make sense to divide one string by another or make a number uppercase.\nWhen certain functionality is closely tied to the type of an object, it is often implemented as a special kind of function known as a method.\nFor now, you only need to know two things about methods:\n\nWe call them by doing variable.method_name(other_arguments) instead of function_name(variable, other_arguments).\n\nA method is a function, even though we call it using a different notation.\n\nWhen we introduced the core data types, we saw many methods defined on these types.\nLet’s revisit them for the str, or string type.\nNotice that we call each of these functions using the dot syntax described above.\n\ns = \"This is my handy string!\"\n\n\ns.upper()\n\n\ns.title()\n\n\n\n\nPython allows for Object-Oriented Programming (OOP), allowing you to define your own custom types and merge together some sets of parameters with custom methods. This can help you streamline your code by making it more modular.\nWe are used to defining variables like x = dict(\"a\": 1, \"b\": 2) and then using notation like x[\"a\"] to access the value of 1. We can also define our own custom types and use them in similar ways.\nFor example, a simple class that stores two variables would look like this:\n\nclass MyType:\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y\n\nUsed both internal and external to classes, the __init__ method is a special method that is called when an object is created. It is used to initialize the object’s state. The self argument refers to the object itself. The self argument is always the first argument of any method in a class. The self argument is not passed in when the method is called, but Python will pass in the object itself when the method is called.\nA class, defined by the class keyword, is a blueprint for an object. It defines the attributes and methods that an object will have. An object is an instance of a class that has been created and assigned to a variable. It is created by calling the class name as if it were a function. When you call the class name, the object is created and the __init__ method is called by default.\n\na = MyType(1, 2)\nb = MyType(3, 4)\n# Notice that these are different objects, even though they are the same type!\na == b\n\nYou can see that a and b are both instances of the MyType class by using the type function.\n\ntype(a)\n\nPoint at the debugger to see the a.x etc. fields You can access the attributes of an object using the dot notation. For example, to access the x attribute of the a object, you would use a.x.\n\nprint(f\"a.x = {a.x} and a.y = {a.y}\")\n\nIn addition to attributes, objects can also have methods. Methods are functions that are defined inside of a class. They are accessed using the dot notation as well. For example, let’s define a method that adds the x and y attributes of an object.\n\nclass MyAdder:\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y\n\n  def add(self):\n    return self.x + self.y\n\nWe can now create an object of type MyAdder and call the add method, in the same way that we called methods on built-in types (like the .upper() method on a string.)\n\nb = MyAdder(1, 2)\nprint(b.add())\n\nUsing custom classes can often be a helpful way to organize your code and make it more modular, by grouping together related variables and functions. Understanding how to create and use custom classes is also a key part of understanding how Python works under the hood, and can be crucial to using some of the more advanced Python packages (like PyTorch.)\n\n\n\nSee exercise 5 in the exercise list.\n\n\n\n\nKeep in mind that with mathematical functions, the arguments are just dummy names that can be interchanged.\nThat is, the following are identical.\n\\[\n\\begin{eqnarray}\n    f(K, L) &= z\\, K^{\\alpha} L^{1-\\alpha}\\\\\n    f(K_2, L_2) &= z\\, K_2^{\\alpha} L_2^{1-\\alpha}\n\\end{eqnarray}\n\\]\nThe same concept applies to Python functions, where the arguments are just placeholder names, and our cobb_douglas function is identical to\n\ndef cobb_douglas2(K2, L2): # changed dummy variable names\n\n    # Create alpha and z\n    z = 1\n    alpha = 0.33\n\n    return z * K2**alpha * L2**(1 - alpha)\n\ncobb_douglas2(1.0, 0.5)\n\nThis is an appealing feature of functions for avoiding coding errors: names of variables within the function are localized and won’t clash with those on the outside (with more examples in scope).\nImportantly, when Python looks for variables matching a particular name, it begins in the most local scope.\nThat is, note that having an alpha in the outer scope does not impact the local one.\n\ndef cobb_douglas3(K, L, alpha): # added new argument\n\n    # Create alpha and z\n    z = 1\n\n    return z * K**alpha * L**(1 - alpha) # sees local argument alpha\n\nprint(cobb_douglas3(1.0, 0.5, 0.2))\nprint(\"Setting alpha, does the result change?\")\nalpha = 0.5 # in the outer scope\nprint(cobb_douglas3(1.0, 0.5, 0.2))\n\nA crucial element of the above function is that the alpha variable was available in the local scope of the function.\nConsider the alternative where it is not. We have removed the alpha function parameter as well as the local definition of alpha.\n\ndef cobb_douglas4(K, L): # added new argument\n\n    # Create alpha and z\n    z = 1\n\n    # there are no local alpha in scope!\n    return z * K**alpha * L**(1 - alpha)\n\nalpha = 0.2 # in the outer scope\nprint(f\"alpha = {alpha} gives {cobb_douglas4(1.0, 0.5)}\")\nalpha = 0.3\nprint(f\"alpha = {alpha} gives {cobb_douglas4(1.0, 0.5)}\")\n\nThe intuition of scoping does not apply only for the “global” vs. “function” naming of variables, but also for nesting.\nFor example, we can define a version of cobb_douglas which is also missing a z in its inner-most scope, then put the function inside of another function.\n\nz = 1\ndef output_given_alpha(alpha):\n    # Scoping logic:\n    # 1. local function name doesn't clash with global one\n    # 2. alpha comes from the function parameter\n    # 3. z comes from the outer global scope\n    def cobb_douglas(K, L):\n        return z * K**alpha * L**(1 - alpha)\n\n    # using this function\n    return cobb_douglas(1.0, 0.5)\n\nalpha = 100 # ignored\nalphas = [0.2, 0.3, 0.5]\n# comprehension variables also have local scope\n# and don't clash with the alpha = 100\n[output_given_alpha(alpha) for alpha in alphas]\n\n\n\n\n\n\n\nWhat happens if we try different inputs in our Cobb-Douglas production function?\n\n# Compute returns to scale with different values of `K` and `L` and `gamma`\n\n(back to text)\n\n\n\nDefine a function named var that takes a list (call it x) and computes the variance. This function should use the mean function that we defined earlier.\n$ = _i (x_i - (x))^2 $\n\n# Your code here.\n\n(back to text)\n\n\n\nRedefine the returns_to_scale function and add a docstring.\nConfirm that it works by running the cell containing returns_to_scale? below.\nNote: You do not need to change the actual code in the function — just copy/paste and add a docstring in the correct line.\n\n# re-define the `returns_to_scale` function here\n\n\n# test it here\n\nreturns_to_scale?\n\n(back to text)\n\n\n\nExperiment with the sep and end arguments to the print function.\nThese can only be set by name.\n\n# Your code here.\n\n(back to text)\n\n\n\nDefine a custom class called CobbDouglas that collects the parameters z and alpha as attributes, and has a method called produce that takes K and L as arguments and returns the output from the Cobb-Douglas production function.\n\n# Your code here.\n\nNow create an instance of the CobbDouglas class called cobb_douglas1 with z = 1 and alpha = 0.33. Use the produce method to compute the output when K = 1 and L = 0.5.\n\n# Your code here.\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html#application-production-functions",
    "href": "tutorials/session_1/python_fundamentals/functions.html#application-production-functions",
    "title": "Functions",
    "section": "",
    "text": "Production functions are useful when modeling the economics of firms producing goods or the aggregate output in an economy.\nThough the term “function” is used in a mathematical sense here, we will be making tight connections between the programming of mathematical functions and Python functions.\n\n\nThe factors of production are the inputs used in the production of some sort of output.\nSome example factors of production include\n\nPhysical capital, e.g. machines, buildings, computers, and power stations.\n\nLabor, e.g. all of the hours of work from different types of employees of a firm.\n\nHuman Capital, e.g. the knowledge of employees within a firm.\n\nA production function maps a set of inputs to the output, e.g. the amount of wheat produced by a farm, or widgets produced in a factory.\nAs an example of the notation, we denote the total units of labor and physical capital used in a factory as $ L $ and $ K $ respectively.\nIf we denote the physical output of the factory as $ Y $, then a production function $ F $ that transforms labor and capital into output might have the form:\n\\[\nY = F(K, L)\n\\]\n\n\n\n\nThroughout this lecture, we will use the Cobb-Douglas production function to help us understand how to create Python functions and why they are useful.\nThe Cobb-Douglas production function has appealing statistical properties when brought to data.\nThis function is displayed below.\n\\[\nY = z K^{\\alpha} L^{1-\\alpha}\n\\]\nThe function is parameterized by:\n\nA parameter $ $, called the “output elasticity of capital”.\n\nA value $ z $ called the Total Factor Productivity (TFP)."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html#what-are-python-functions",
    "href": "tutorials/session_1/python_fundamentals/functions.html#what-are-python-functions",
    "title": "Functions",
    "section": "",
    "text": "In this class, we will often talk about functions.\nSo what is a function?\nWe like to think of a function as a production line in a manufacturing plant: we pass zero or more things to it, operations take place in a set linear sequence, and zero or more things come out.\nWe use functions for the following purposes:\n\nRe-usability: Writing code to do a specific task just once, and reuse the code by calling the function.\n\nOrganization: Keep the code for distinct operations separated and organized.\n\nSharing/collaboration: Sharing code across multiple projects or sharing pieces of code with collaborators."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html#how-to-define-python-functions",
    "href": "tutorials/session_1/python_fundamentals/functions.html#how-to-define-python-functions",
    "title": "Functions",
    "section": "",
    "text": "The basic syntax to create our own function is as follows:\n\ndef function_name(inputs):\n    # step 1\n    # step 2\n    # ...\n    return outputs\n\nHere we see two new keywords: def and return.\n\ndef is used to tell Python we would like to define a new function.\n\nreturn is used to tell Python what we would like to return from a function.\n\nLet’s look at an example and then discuss each part:\n\ndef mean(numbers):\n    total = sum(numbers)\n    N = len(numbers)\n    answer = total / N\n\n    return answer\n\nHere we defined a function mean that has one input (numbers), does three steps, and has one output (answer).\nLet’s see what happens when we call this function on the list of numbers [1, 2, 3, 4].\n\nx = [1, 2, 3, 4]\nthe_mean = mean(x)\nthe_mean\n\nAdditionally, as we saw in the control flow lecture, indentation controls blocks of code (along with the scope rules).\nTo see this, compare a function with no inputs or return values.\n\ndef f():\n    print(\"1\")\n    print(\"2\")\nf()\n\nWith the following change of indentation…\n\ndef f():\n    print(\"1\")\nprint(\"2\")\nf()\n\n\n\n\nNotice that we named the input to the function x and we called the output the_mean.\nWhen we defined the function, the input was called numbers and the output answer… what gives?\nThis is an example of a programming concept called variable scope.\nIn Python, functions define their own scope for variables.\nIn English, this means that regardless of what name we give an input variable (x in this example), the input will always be referred to as numbers inside the body of the mean function.\nIt also means that although we called the output answer inside of the function mean, that this variable name was only valid inside of our function.\nTo use the output of the function, we had to give it our own name (the_mean in this example).\nAnother point to make here is that the intermediate variables we defined inside mean (total and N) are only defined inside of the mean function – we can’t access them from outside. We can verify this by trying to see what the value of total is:\n\ndef mean(numbers):\n    total = sum(numbers)\n    N = len(numbers)\n    answer = total / N\n    return answer # or directly return total / N\n\n# uncomment the line below and execute to see the error\n# total\n\nThis point can be taken even further: the same name can be bound to variables inside of blocks of code and in the outer “scope”.\n\nx = 4\nprint(f\"x = {x}\")\ndef f():\n    x = 5 # a different \"x\"\n    print(f\"x = {x}\")\nf() # calls function\nprint(f\"x = {x}\")\n\nThe final point we want to make about scope is that function inputs and output don’t have to be given a name outside the function.\n\nmean([10, 20, 30])\n\nNotice that we didn’t name the input or the output, but the function was called successfully.\nNow, we’ll use our new knowledge to define a function which computes the output from a Cobb-Douglas production function with parameters $ z = 1 $ and $ = 0.33 $ and takes inputs $ K $ and $ L $.\n\ndef cobb_douglas(K, L):\n\n    # Create alpha and z\n    z = 1\n    alpha = 0.33\n\n    return z * K**alpha * L**(1 - alpha)\n\nWe can use this function as we did the mean function.\n\ncobb_douglas(1.0, 0.5)\n\n\n\n\n\nEconomists are often interested in this question: how much does output change if we modify our inputs?\nFor example, take a production function $ Y_1 = F(K_1,L_1) $ which produces $ Y_1 $ units of the goods.\nIf we then multiply the inputs each by $ \\(, so that\\) K_2 = K_1 $ and $ L_2 = L_1 $, then the output is\n\\[\nY_2 = F(K_2, L_2) = F(\\gamma K_1, \\gamma L_1)\n\\]\nHow does $ Y_1 $ compare to $ Y_2 $?\nAnswering this question involves something called returns to scale.\nReturns to scale tells us whether our inputs are more or less productive as we have more of them.\nFor example, imagine that you run a restaurant. How would you expect the amount of food you could produce would change if you could build an exact replica of your restaurant and kitchen and hire the same number of cooks and waiters? You would probably expect it to double.\nIf, for any $ K, L $, we multiply $ K, L $ by a value $ $ then\n\nIf $ &lt; $ then we say the production function has decreasing returns to scale.\n\nIf $ = $ then we say the production function has constant returns to scale.\n\nIf $ &gt; $ then we say the production function has increasing returns to scale.\n\nLet’s try it and see what our function is!\n\ny1 = cobb_douglas(1.0, 0.5)\nprint(y1)\ny2 = cobb_douglas(2*1.0, 2*0.5)\nprint(y2)\n\nHow did $ Y_1 $ and $ Y_2 $ relate?\n\ny2 / y1\n\n$ Y_2 $ was exactly double $ Y_1 $!\nLet’s write a function that will compute the returns to scale for different values of $ K $ and $ L $.\nThis is an example of how writing functions can allow us to re-use code in ways we might not originally anticipate. (You didn’t know we’d be writing a returns_to_scale function when we wrote cobb_douglas.)\n\ndef returns_to_scale(K, L, gamma):\n    y1 = cobb_douglas(K, L)\n    y2 = cobb_douglas(gamma*K, gamma*L)\n    y_ratio = y2 / y1\n    return y_ratio / gamma\n\n\nreturns_to_scale(1.0, 0.5, 2.0)\n\n\n\n\nSee exercise 1 in the exercise list.\nIt turns out that with a little bit of algebra, we can check that this will always hold for our Cobb-Douglas example above.\nTo show this, take an arbitrary $ K, L $ and multiply the inputs by an arbitrary $ $.\n\\[\n\\begin{aligned}\n    F(\\gamma K, \\gamma L) &= z (\\gamma K)^{\\alpha} (\\gamma L)^{1-\\alpha}\\\\\n    &=  z \\gamma^{\\alpha}\\gamma^{1-\\alpha} K^{\\alpha} L^{1-\\alpha}\\\\\n    &= \\gamma z K^{\\alpha} L^{1-\\alpha} = \\gamma F(K, L)\n\\end{aligned}\n\\]\nFor an example of a production function that is not CRS, look at a generalization of the Cobb-Douglas production function that has different “output elasticities” for the 2 inputs.\n\\[\nY = z K^{\\alpha_1} L^{\\alpha_2}\n\\]\nNote that if $ _2 = 1 - _1 $, this is our Cobb-Douglas production function.\n\n\n\nSee exercise 2 in the exercise list.\n\n\n\n\nAnother valuable element to analyze on production functions is how output changes as we change only one of the inputs. We will call this the marginal product.\nFor example, compare the output using $ K, L $ units of inputs to that with an $ $ units of labor.\nThen the marginal product of labor (MPL) is defined as\n\\[\n\\frac{F(K, L + \\varepsilon) - F(K, L)}{\\varepsilon}\n\\]\nThis tells us how much additional output is created relative to the additional input. (Spoiler alert: This should look like the definition for a partial derivative!)\nIf the input can be divided into small units, then we can use calculus to take this limit, using the partial derivative of the production function relative to that input.\nIn this case, we define the marginal product of labor (MPL) and marginal product of capital (MPK) as\n\\[\n\\begin{aligned}\nMPL(K, L) &= \\frac{\\partial F(K, L)}{\\partial L}\\\\\nMPK(K, L) &= \\frac{\\partial F(K, L)}{\\partial K}\n\\end{aligned}\n\\]\nIn the Cobb-Douglas example above, this becomes\n\\[\n\\begin{aligned}\nMPK(K, L) &= z  \\alpha \\left(\\frac{K}{L} \\right)^{\\alpha - 1}\\\\\nMPL(K, L) &= (1-\\alpha) z \\left(\\frac{K}{L} \\right)^{\\alpha}\\\\\n\\end{aligned}\n\\]\nLet’s test it out with Python! We’ll also see that we can actually return multiple things in a Python function.\nThe syntax for a return statement with multiple items is return item1, item2, ….\nIn this case, we’ll compute both the MPL and the MPK and then return both.\n\ndef marginal_products(K, L, epsilon):\n\n    mpl = (cobb_douglas(K, L + epsilon) - cobb_douglas(K, L)) / epsilon\n    mpk = (cobb_douglas(K + epsilon, L) - cobb_douglas(K, L)) / epsilon\n\n    return mpl, mpk\n\n\ntup = marginal_products(1.0, 0.5,  1e-4)\nprint(tup)\n\nInstead of using the tuple, these can be directly unpacked to variables.\n\nmpl, mpk = marginal_products(1.0, 0.5,  1e-4)\nprint(f\"mpl = {mpl}, mpk = {mpk}\")\n\nWe can use this to calculate the marginal products for different K, fixing L using a comprehension.\n\nKs = [1.0, 2.0, 3.0]\n[marginal_products(K, 0.5, 1e-4) for K in Ks] # create a tuple for each K\n\n\n\n\nIn a previous exercise, we asked you to find help for the cobb_douglas and returns_to_scale functions using ?.\nIt didn’t provide any useful information.\nTo provide this type of help information, we need to add what Python programmers call a “docstring” to our functions.\nThis is done by putting a string (not assigned to any variable name) as the first line of the body of the function (after the line with def).\nBelow is a new version of the template we used to define functions.\n\ndef function_name(inputs):\n    \"\"\"\n    Docstring\n    \"\"\"\n    # step 1\n    # step 2\n    # ...\n    return outputs\n\nLet’s re-define our cobb_douglas function to include a docstring.\n\ndef cobb_douglas(K, L):\n    \"\"\"\n    Computes the production F(K, L) for a Cobb-Douglas production function\n\n    Takes the form F(K, L) = z K^{\\alpha} L^{1 - \\alpha}\n\n    We restrict z = 1 and alpha = 0.33\n    \"\"\"\n    return 1.0 * K**(0.33) * L**(1.0 - 0.33)\n\nNow when we have Jupyter evaluate cobb_douglas?, our message is displayed (or use the Contextual Help window with Jupyterlab and Ctrl-I or Cmd-I).\n\ncobb_douglas?\n\nWe recommend that you always include at least a very simple docstring for nontrivial functions.\nThis is in the same spirit as adding comments to your code — it makes it easier for future readers/users (including yourself) to understand what the code does.\n\n\n\nSee exercise 3 in the exercise list.\n\n\n\nFunctions can have optional arguments.\nTo accomplish this, we must these arguments a default value by saying name=default_value instead of just name as we list the arguments.\nTo demonstrate this functionality, let’s now make $ z $ and $ $ arguments to our cobb_douglas function!\n\ndef cobb_douglas(K, L, alpha=0.33, z=1):\n    \"\"\"\n    Computes the production F(K, L) for a Cobb-Douglas production function\n\n    Takes the form F(K, L) = z K^{\\alpha} L^{1 - \\alpha}\n    \"\"\"\n    return z * K**(alpha) * L**(1.0 - alpha)\n\nWe can now call this function by passing in just K and L. Notice that it will produce same result as earlier because alpha and z are the same as earlier.\n\ncobb_douglas(1.0, 0.5)\n\nHowever, we can also set the other arguments of the function by passing more than just K/L.\n\ncobb_douglas(1.0, 0.5, 0.35, 1.6)\n\nIn the example above, we used alpha = 0.35, z = 1.6.\nWe can also refer to function arguments by their name, instead of only their position (order).\nTo do this, we would write func_name(arg=value) for as many of the arguments as we want.\nHere’s how to do that with our cobb_douglas example.\n\ncobb_douglas(1.0, 0.5, z = 1.5)\n\n\n\n\nSee exercise 4 in the exercise list.\nIn terms of variable scope, the z name within the function is different from any other z in the outer scope.\nTo be clear,\n\nx = 5\ndef f(x):\n    return x\nf(x) # \"coincidence\" that it has the same name\n\nThis is also true with named function arguments, above.\n\nz = 1.5\ncobb_douglas(1.0, 0.5, z = z) # no problem!\n\nIn that example, the z on the left hand side of z = z refers to the local variable name in the function whereas the z on the right hand side refers to the z in the outer scope.\n\n\n\nAs we learned earlier, all variables in Python have a type associated with them.\nDifferent types of variables have different functions or operations defined for them.\nFor example, I can divide one number by another or make a string uppercase.\nIt wouldn’t make sense to divide one string by another or make a number uppercase.\nWhen certain functionality is closely tied to the type of an object, it is often implemented as a special kind of function known as a method.\nFor now, you only need to know two things about methods:\n\nWe call them by doing variable.method_name(other_arguments) instead of function_name(variable, other_arguments).\n\nA method is a function, even though we call it using a different notation.\n\nWhen we introduced the core data types, we saw many methods defined on these types.\nLet’s revisit them for the str, or string type.\nNotice that we call each of these functions using the dot syntax described above.\n\ns = \"This is my handy string!\"\n\n\ns.upper()\n\n\ns.title()\n\n\n\n\nPython allows for Object-Oriented Programming (OOP), allowing you to define your own custom types and merge together some sets of parameters with custom methods. This can help you streamline your code by making it more modular.\nWe are used to defining variables like x = dict(\"a\": 1, \"b\": 2) and then using notation like x[\"a\"] to access the value of 1. We can also define our own custom types and use them in similar ways.\nFor example, a simple class that stores two variables would look like this:\n\nclass MyType:\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y\n\nUsed both internal and external to classes, the __init__ method is a special method that is called when an object is created. It is used to initialize the object’s state. The self argument refers to the object itself. The self argument is always the first argument of any method in a class. The self argument is not passed in when the method is called, but Python will pass in the object itself when the method is called.\nA class, defined by the class keyword, is a blueprint for an object. It defines the attributes and methods that an object will have. An object is an instance of a class that has been created and assigned to a variable. It is created by calling the class name as if it were a function. When you call the class name, the object is created and the __init__ method is called by default.\n\na = MyType(1, 2)\nb = MyType(3, 4)\n# Notice that these are different objects, even though they are the same type!\na == b\n\nYou can see that a and b are both instances of the MyType class by using the type function.\n\ntype(a)\n\nPoint at the debugger to see the a.x etc. fields You can access the attributes of an object using the dot notation. For example, to access the x attribute of the a object, you would use a.x.\n\nprint(f\"a.x = {a.x} and a.y = {a.y}\")\n\nIn addition to attributes, objects can also have methods. Methods are functions that are defined inside of a class. They are accessed using the dot notation as well. For example, let’s define a method that adds the x and y attributes of an object.\n\nclass MyAdder:\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y\n\n  def add(self):\n    return self.x + self.y\n\nWe can now create an object of type MyAdder and call the add method, in the same way that we called methods on built-in types (like the .upper() method on a string.)\n\nb = MyAdder(1, 2)\nprint(b.add())\n\nUsing custom classes can often be a helpful way to organize your code and make it more modular, by grouping together related variables and functions. Understanding how to create and use custom classes is also a key part of understanding how Python works under the hood, and can be crucial to using some of the more advanced Python packages (like PyTorch.)\n\n\n\nSee exercise 5 in the exercise list."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html#more-on-scope-optional",
    "href": "tutorials/session_1/python_fundamentals/functions.html#more-on-scope-optional",
    "title": "Functions",
    "section": "",
    "text": "Keep in mind that with mathematical functions, the arguments are just dummy names that can be interchanged.\nThat is, the following are identical.\n\\[\n\\begin{eqnarray}\n    f(K, L) &= z\\, K^{\\alpha} L^{1-\\alpha}\\\\\n    f(K_2, L_2) &= z\\, K_2^{\\alpha} L_2^{1-\\alpha}\n\\end{eqnarray}\n\\]\nThe same concept applies to Python functions, where the arguments are just placeholder names, and our cobb_douglas function is identical to\n\ndef cobb_douglas2(K2, L2): # changed dummy variable names\n\n    # Create alpha and z\n    z = 1\n    alpha = 0.33\n\n    return z * K2**alpha * L2**(1 - alpha)\n\ncobb_douglas2(1.0, 0.5)\n\nThis is an appealing feature of functions for avoiding coding errors: names of variables within the function are localized and won’t clash with those on the outside (with more examples in scope).\nImportantly, when Python looks for variables matching a particular name, it begins in the most local scope.\nThat is, note that having an alpha in the outer scope does not impact the local one.\n\ndef cobb_douglas3(K, L, alpha): # added new argument\n\n    # Create alpha and z\n    z = 1\n\n    return z * K**alpha * L**(1 - alpha) # sees local argument alpha\n\nprint(cobb_douglas3(1.0, 0.5, 0.2))\nprint(\"Setting alpha, does the result change?\")\nalpha = 0.5 # in the outer scope\nprint(cobb_douglas3(1.0, 0.5, 0.2))\n\nA crucial element of the above function is that the alpha variable was available in the local scope of the function.\nConsider the alternative where it is not. We have removed the alpha function parameter as well as the local definition of alpha.\n\ndef cobb_douglas4(K, L): # added new argument\n\n    # Create alpha and z\n    z = 1\n\n    # there are no local alpha in scope!\n    return z * K**alpha * L**(1 - alpha)\n\nalpha = 0.2 # in the outer scope\nprint(f\"alpha = {alpha} gives {cobb_douglas4(1.0, 0.5)}\")\nalpha = 0.3\nprint(f\"alpha = {alpha} gives {cobb_douglas4(1.0, 0.5)}\")\n\nThe intuition of scoping does not apply only for the “global” vs. “function” naming of variables, but also for nesting.\nFor example, we can define a version of cobb_douglas which is also missing a z in its inner-most scope, then put the function inside of another function.\n\nz = 1\ndef output_given_alpha(alpha):\n    # Scoping logic:\n    # 1. local function name doesn't clash with global one\n    # 2. alpha comes from the function parameter\n    # 3. z comes from the outer global scope\n    def cobb_douglas(K, L):\n        return z * K**alpha * L**(1 - alpha)\n\n    # using this function\n    return cobb_douglas(1.0, 0.5)\n\nalpha = 100 # ignored\nalphas = [0.2, 0.3, 0.5]\n# comprehension variables also have local scope\n# and don't clash with the alpha = 100\n[output_given_alpha(alpha) for alpha in alphas]"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/functions.html#exercises",
    "href": "tutorials/session_1/python_fundamentals/functions.html#exercises",
    "title": "Functions",
    "section": "",
    "text": "What happens if we try different inputs in our Cobb-Douglas production function?\n\n# Compute returns to scale with different values of `K` and `L` and `gamma`\n\n(back to text)\n\n\n\nDefine a function named var that takes a list (call it x) and computes the variance. This function should use the mean function that we defined earlier.\n$ = _i (x_i - (x))^2 $\n\n# Your code here.\n\n(back to text)\n\n\n\nRedefine the returns_to_scale function and add a docstring.\nConfirm that it works by running the cell containing returns_to_scale? below.\nNote: You do not need to change the actual code in the function — just copy/paste and add a docstring in the correct line.\n\n# re-define the `returns_to_scale` function here\n\n\n# test it here\n\nreturns_to_scale?\n\n(back to text)\n\n\n\nExperiment with the sep and end arguments to the print function.\nThese can only be set by name.\n\n# Your code here.\n\n(back to text)\n\n\n\nDefine a custom class called CobbDouglas that collects the parameters z and alpha as attributes, and has a method called produce that takes K and L as arguments and returns the output from the Cobb-Douglas production function.\n\n# Your code here.\n\nNow create an instance of the CobbDouglas class called cobb_douglas1 with z = 1 and alpha = 0.33. Use the produce method to compute the output when K = 1 and L = 0.5.\n\n# Your code here.\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html",
    "title": "Control Flow",
    "section": "",
    "text": "Prerequisites\n\nBooleans section in Basics\n\nCollections\n\nOutcomes\n\nAsset pricing and NPV\n\nUnderstand basic principles of pricing assets with deterministic payoffs\n\nApply programming with iteration and conditionals to asset pricing examples\n\n\nConditionals\n\nUnderstand what a conditional is\n\nBe able to construct if/elif/else conditional blocks\n\nUnderstand how conditionals can be used to selectively execute blocks of code\n\n\nIteration\n\nUnderstand what an iterable is\n\nBe able to write for and while loops\n\nUnderstand the keywords break and continue\n\n\n\n\n\nIn this lecture, we’ll introduce two related topics from economics:\n\nNet present valuations\n\nAsset pricing\n\nThese topics will motivate some of the programming we do in this course.\nIn economics and finance, “assets” provide a stream of payoffs.\nThese “assets” can be concrete or abstract: a stock pays dividends over time, a bond pays interest, an apple tree provides apples, a job pays wages, and an education provides possible jobs (which, in turn, pay wages).\nWhen deciding the price to pay for an asset or how to choose between different alternatives, we need to take into account that most people would prefer to receive 1 today vs. 1 next year.\nThis reflection on consumer preferences leads to the notion of a discount rate. If you are indifferent between receiving 1.00 today and 1.10 next year, then the discount rate over the next year is $ r = 0.10 $.\nIf we assume that an individuals preferences are consistent over time, then we can apply that same discount rate to valuing assets further into the future.\nFor example, we would expect that the consumer would be indifferent between consuming 1.00 today and $ (1+r)(1+r) = 1.21 $ dollars two years from now (i.e. discount twice).\nInverting this formula, 1 delivered two years from now is equivalent to $ $ today.\n\n\n\nSee exercise 1 in the exercise list.\n\n\n\nIf an asset pays a stream of payoffs over multiple time periods, then we can use a discount rate to calculate the value to the consumer of a entire sequence of payoffs.\nMost generally, we enumerate each discrete time period (e.g. year, month, day) by the index $ t $ where today is $ t=0 $ and the asset lives for $ T $ periods.\nList the payoff at each time period as $ y_t $, which we will assume, for now, is known in advance.\nThen if the discount factor is $ r $, the consumer “values” the payoff $ y_t $ delivered at time $ t $ as $ y_t $ where we note that if $ t=0 \\(, the value is just the current payoff\\) y_0 $.\nUsing this logic, we can write an expression for the value of the entire sequence of payoffs with a sum.\n \\[\nP_0 = \\sum_{t=0}^T \\left(\\frac{1}{1 + r}\\right)^t y_t \\tag{1}\n\\]\nIf $ y_t $ is a constant, then we can compute this sum with a simple formula!\nBelow, we present some useful formulas that come from infinite series that we will use to get our net present value formula.\nFor any constant $ 0 &lt; &lt; 1 $ and integer value $ &gt; 0 $,\n \\[\n\\begin{aligned}\n\\sum_{t=0}^{\\infty} \\beta^t & = \\frac{1}{1-\\beta}\\\\\n\\sum_{t=0}^{\\tau} \\beta^t &= \\frac{1- \\beta^{\\tau+1}}{1-\\beta}\\\\\n\\sum_{t=\\tau}^{\\infty} \\beta^t &=  \\frac{\\beta^{\\tau}}{1-\\beta}\n\\end{aligned} \\tag{2}\n\\]\nIn the case of an asset which pays one dollar until time $ T $, we can use these formulas, taking $ = $ and $ T = $, to find\n\\[\n\\begin{aligned}\nP_0 &= \\sum_{t=0}^T \\left(\\frac{1}{1 + r}\\right)^t = \\frac{1- (\\frac{1}{1+r})^{\\tau+1}}{1-\\frac{1}{1+r}}\\\\\n&= \\frac{1 + r}{r} - \\frac{1}{r}\\left(\\frac{1}{1+r} \\right)^\\tau\n\\end{aligned}\n\\]\nNote that we can also consider an asset that lives and pays forever if $ T= $, and from (2), the value of an asset which pays 1 forever is $ $.\n\n\n\n\nSometimes, we will only want to execute some piece of code if a certain condition is met.\nThese conditions can be anything.\nFor example, we might add to total sales if the transaction value is positive, but add to total returns if the value is negative.\nOr, we might want to add up all incurred costs, only if the transaction happened before a certain date.\nWe use conditionals to run particular pieces of code when certain criterion are met.\nConditionals are closely tied to booleans, so if you don’t remember what those are, go back to the basics lecture for a refresher.\nThe basic syntax for conditionals is\n\nif condition:\n    # code to run when condition is True\nelse:\n    # code to run if no conditions above are True\n\nNote that immediately following the condition, there is a colon and that the next line begins with blank spaces.\nUsing 4 spaces is a very strong convention, so that is what we do — we recommend that you do the same.\nAlso note that the else clause is optional.\nLet’s see some simple examples.\n\nif True:\n    print(\"This is where `True` code is run\")\n\nAlternatively, you could have a test which returns a booleans\n\nif 1 &lt; 2:\n     print(\"This is where `True` code is run\")\n\nThis example is equivalent to just typing the print statement, but the example below isn’t…\n\nif False:\n    print(\"This is where `True` code is run\")\n\nOr\n\nif 1 &gt; 2:\n     print(\"This is where `True` code is run\")\n\nNotice that when you run the cells above nothing is printed.\nThat is because the condition for the if statement was not true, so the code inside the indented block was never run.\nThis also allows us to demonstrate the role of indentation in determining the “block” of code.\n\nval = False\n\nif val is True: # check an expression\n    print(\"This is where `True` code is run\")\n    print(\"More code in the if block\")\nprint(\"Code runs after 'if' block, regardless of val\")\n\n\n\n\nSee exercise 2 in the exercise list.\nThe next example shows us how else works.\n\nval = (2 == 4)  # returns False\nif val is True:\n    print(\"This is where `True` code is run\")\nelse:\n    print(\"This is where `False` code is run\")\n    print(\"More else code\")\nprint(\"Code runs after 'if' block, regardless of val\")\n\nThe if False: ... part of this example is the same as the example before, but now, we added an else: clause.\nIn this case, because the conditional for the if statement was not True, the if code block was not executed, but the else block was.\nFinally, the Condition is True is assumed in the if statement, and is often left out. For example, the following are identical\n\nif (1 &lt; 2) is True:\n    print(\"1 &lt; 2\")\n\nif 1 &lt; 2:\n    print(\"1 &lt; 2\")\n\n\n\n\nSee exercise 3 in the exercise list.\n\n\n\nSee exercise 4 in the exercise list.\n\n\nSometimes, you have more than one condition you want to check.\nFor example, you might want to run a different set of code based on which quarter a particular transaction took place in.\nIn this case you could check whether the date is in Q1, or in Q2, or in Q3, or if not any of these it must be in Q4.\nThe way to express this type of conditional is to use one or more elif clause in addition to the if and the else.\nThe syntax is\n\nif condition1:\n    # code to run when condition1 is True\nelif condition2:\n    # code to run when condition2 is True\nelif condition3:\n    # code to run when condition3 is True\nelse:\n    # code to run when none of the above are true\n\nYou can include as many elif clauses as you want.\nAs before, the else part is optional.\nHere’s how we might express the quarter example referred to above.\n\nimport datetime\nhalloween = datetime.date(2017, 10, 31)\n\nif halloween.month &gt; 9:\n    print(\"Halloween is in Q4\")\nelif halloween.month &gt; 6:\n    print(\"Halloween is in Q3\")\nelif halloween.month &gt; 3:\n    print(\"Halloween is in Q2\")\nelse:\n    print(\"Halloween is in Q1\")\n\nNote that when there are multiple if or elif conditions, only the code corresponding to the first true clause is run.\nWe saw this in action above.\nWe know that when halloween.month &gt; 9 is true, then halloween.month &gt; 6 and halloween.month &gt; 3 must also be true, but only the code block associated with halloween.month &gt; 9 was printed.\n\n\n\n\nWhen doing computations or analyzing data, we often need to repeat certain operations a finite number of times or until some condition is met.\nExamples include processing all data files in a directory (folder), aggregating revenues and costs for every period in a year, or computing the net present value of certain assets. (In fact, later in this section, we will verify the equations that we wrote down above.)\nThese are all examples of a programming concept called iteration.\nWe feel the concept is best understood through example, so we will present a contrived example and then discuss the details behind doing iteration in Python.\n\n\nSuppose we wanted to print out the first 10 integers and their squares.\nWe could do something like this.\n\nprint(f\"1**2 = {1**2}\")\nprint(f\"2**2 = {2**2}\")\nprint(f\"3**2 = {3**2}\")\nprint(f\"4**2 = {4**2}\")\n# .. and so on until 10\n\nAs you can see, the code above is repetitive.\nFor each integer, the code is exactly the same except for the two places where the “current” integer appears.\nSuppose that I asked you to write the same print statement for an int stored in a variable named i.\nYou might write the following code:\n\nprint(f\"{i}**2 = {i**2}\")\n\nThis more general version of the operation suggests a strategy for achieving our goal with less repetition: have a variable i take on the values 1 through 10 (Quiz: How can we use range to create the numbers 1 to 10?) and run the line of code above for each new value of i.\nThis can be accomplished with a for loop!\n\nfor i in range(1, 11):\n     print(f\"{i}**2 = {i**2}\")\n\nWhoa, what just happened?\nThe integer i took on the values in range(1, 11) one by one and for each new value it did the operations in the indented block (here just one line that called the print function).\n\n\n\nThe general structure of a standard for loop is as follows.\n\nfor item in iterable:\n   # operation 1 with item\n   # operation 2 with item\n   # ...\n   # operation N with item\n\nwhere iterable is anything capable of producing one item at a time (see here for official definition from the Python team).\nWe’ve actually already seen some of the most common iterables!\nLists, tuples, dicts, and range/zip/enumerate objects are all iterables.\nNote that we can have as many operations as we want inside the indented block.\nWe will refer to the indented block as the “body” of the loop.\nWhen the for loop is executed, item will take on one value from iterable at a time and execute the loop body for each value.\n\n\n\n\nSee exercise 5 in the exercise list.\nWhen iterating, each item in iterable might actually contain more than one value.\nRecall that tuples (and lists) can be unpacked directly into variables.\n\ntup = (4, \"test\")\ni, x = tup\nprint(f\"i = {i}, x = {x}, tup = {tup}\")\n\nAlso, recall that the value of a enumerate(iterable) is a tuple of the form (i, x) where iterable[i] == x.\nWhen we use enumerate in a for loop, we can “unpack” both values at the same time as follows:\n\n# revenue by quarter\ncompany_revenue = [5.12, 5.20, 5.50, 6.50]\n\nfor index, value in enumerate(company_revenue):\n    print(f\"quarter {index} revenue is ${value} million\")\n\nSimilarly, the index can be used to access another vector.\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\nfor index, city in enumerate(cities):\n    state = states[index]\n    print(f\"{city} is in {state}\")\n\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nA related but slightly different form of iteration is to repeat something until some condition is met.\nThis is typically achieved using a while loop.\nThe structure of a while loop is\n\nwhile True_condition:\n    # repeat these steps\n\nwhere True_condition is some conditional statement that should evaluate to True when iterations should continue and False when Python should stop iterating.\nFor example, suppose we wanted to know the smallest N such that $ _{i=0}^N i &gt; 1000 $.\nWe figure this out using a while loop as follows.\n\ntotal = 0\ni = 0\nwhile total &lt;= 1000:\n    i = i + 1\n    total = total + i\n\nprint(\"The answer is\", i)\n\nLet’s check our work.\n\n# Should be just less than 1000 because range(45) goes from 0 to 44\nsum(range(45))\n\n\n# should be between 990 + 45 = 1035\nsum(range(46))\n\nA warning: one common programming error with while loops is to forget to set the variable you use in the condition prior to executing. For example, take the following code which correctly sets a counter\n\ni = 0\n\nAnd then executes a while loop\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\nprint(\"done\")\n\nNo problems. But if you were to execute the above cell again, or another cell, the i=3 remains, and code is never executed (since i &lt; 3 begins as False).\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\nprint(\"done\")\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\n\n\n\nSometimes we want to stop a loop early if some condition is met.\nLet’s revisit the example of finding the smallest N such that $ _{i=0}^N i &gt; 1000 $.\nClearly N must be less than 1000, so we know we will find the answer if we start with a for loop over all items in range(1001).\nThen, we can keep a running total as we proceed and tell Python to stop iterating through our range once total goes above 1000.\n\ntotal = 0\nfor i in range(1001):\n    total = total + i\n    if total &gt; 1000:\n        break\n\nprint(\"The answer is\", i)\n\n\n\n\nSee exercise 8 in the exercise list.\n\n\n\nSometimes we might want to stop the body of a loop early if a condition is met.\nTo do this we can use the continue keyword.\nThe basic syntax for doing this is:\n\nfor item in iterable:\n    # always do these operations\n    if condition:\n        continue\n\n    # only do these operations if condition is False\n\nInside the loop body, Python will stop that loop iteration of the loop and continue directly to the next iteration when it encounters the continue statement.\nFor example, suppose I ask you to loop over the numbers 1 to 10 and print out the message “{i} An odd number!” whenever the number i is odd, and do nothing otherwise.\nYou can use continue to do this as follows:\n\nfor i in range(1, 11):\n    if i % 2 == 0:  # an even number... This is modulus division\n        continue\n\n    print(i, \"is an odd number!\")\n\n\n\n\nSee exercise 9 in the exercise list.\n\n\n\n\n\nOften, we will want to perform a very simple operation for every element of some iterable and create a new iterable with these values.\nThis could be done by writing a for loop and saving each value, but often using what is called a comprehension is more readable.\nLike many Python concepts, a comprehension is easiest to understand through example.\nImagine that we have a list x with a list of numbers. We would like to create a list x2 which has the squared values of x.\n\nx = list(range(4))\n\n# Create squared values with a loop\nx2_loop = []\nfor x_val in x:\n    x2_loop.append(x_val**2)\n\n# Create squared values with a comprehension\nx2_comp = [x_val**2 for x_val in x]\n\nprint(x2_loop)\nprint(x2_comp)\n\nNotice that much of the same text appears when we do the operation in the loop and when we do the operation with the comprehension.\n\nWe need to specify what we are iterating over – in both cases, this is for x_val in x.\n\nWe need to square each element x_val**2.\n\nIt needs to be stored somewhere – in x2_loop, this is done by appending each element to a list, and in x2_comp, this is done automatically because the operation is enclosed in a list.\n\nWe can do comprehension with many different types of iterables, so we demonstrate a few more below.\n\n# Create a dictionary from lists\ntickers = [\"AAPL\", \"GOOGL\", \"TVIX\"]\nprices = [175.96, 1047.43, 8.38]\nd = {key: value for key, value in zip(tickers, prices)}\nd\n\n\n# Create a list from a dictionary\nd = {\"AMZN\": \"Seattle\", \"TVIX\": \"Zurich\", \"AAPL\": \"Cupertino\"}\n\nhq_cities = [d[ticker] for ticker in d.keys()]\nhq_cities\n\n\nimport math\n\n# List from list\nx = range(10)\n\nsin_x = [math.sin(x_val) for x_val in x]\nsin_x\n\n\n\n\nSee exercise 10 in the exercise list.\nFinally, we can use this approach to build complicated nested dictionaries.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nexports = [ {\"manufacturing\": 2.4, \"agriculture\": 1.5, \"services\": 0.5},\n            {\"manufacturing\": 2.5, \"agriculture\": 1.4, \"services\": 0.9},\n            {\"manufacturing\": 2.7, \"agriculture\": 1.4, \"services\": 1.5}]\ndata = zip(years, gdp_data,exports)\ndata_dict = {year : {\"gdp\" : gdp, \"exports\": exports} for year, gdp, exports in data}\nprint(data_dict)\n\n# total exports by year\n[data_dict[year][\"exports\"][\"services\"] for year in data_dict.keys()]\n\n\n\n\n\n\n\nGovernment bonds are often issued as zero-coupon bonds meaning that they make no payments throughout the entire time that they are held, but, rather make a single payment at the time of maturity.\nHow much should you be willing to pay for a zero-coupon bond that paid 100 in 10 years with an interest rate of 5%?\n\n# your code here\n\n(back to text)\n\n\n\nRun the following two variations on the code with only a single change in the indentation.\nAfter, modify the x to print 3 and then 2, 3 instead.\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\n    print(\"2\")\nprint(\"3\")\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\nprint(\"2\") # changed the indentation\nprint(\"3\")\n\n(back to text)\n\n\n\nUsing the code cell below as a start, print \"Good afternoon\" if the current_time is past noon.\nOtherwise, do nothing.\nWrite some conditional based on current_time.hour.\n\nimport datetime\ncurrent_time = datetime.datetime.now()\n\n## your code here\n\nmore text after\n(back to text)\n\n\n\nIn this example, you will generate a random number between 0 and 1 and then display “x &gt; 0.5” or “x &lt; 0.5” depending on the value of the number.\nThis also introduces a new package numpy.random for drawing random numbers (more in the randomness lecture).\n\nimport numpy as np\nx = np.random.random()\nprint(f\"x = {x}\")\n\n## your code here\n\n(back to text)\n\n\n\nIn economics, when an individual has some knowledge, skills, or education which provides them with a source of future income, we call it human capital.\nWhen a student graduating from high school is considering whether to continue with post-secondary education, they may consider that it gives them higher paying jobs in the future, but requires that they don’t begin working until after graduation.\nConsider the simplified example where a student has perfectly forecastable employment and is given two choices:\n\nBegin working immediately and make 40,000 a year until they retire 40 years later.\n\nPay 5,000 a year for the next 4 years to attend university, then get a job paying 50,000 a year until they retire 40 years after making the college attendance decision.\n\nShould the student enroll in school if the discount rate is r = 0.05?\n\n# Discount rate\nr = 0.05\n\n# High school wage\nw_hs = 40_000\n\n# College wage and cost of college\nc_college = 5_000\nw_college = 50_000\n\n# Compute npv of being a hs worker\n\n# Compute npv of attending college\n\n# Compute npv of being a college worker\n\n# Is npv_collegeworker - npv_collegecost &gt; npv_hsworker\n\n(back to text)\n\n\n\nInstead of the above, write a for loop that uses the lists of cities and states below to print the same “{city} is in {state}” using a zip instead of an enumerate.\nTry using zip\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n# Your code here\n\n(back to text)\n\n\n\nCompanies often invest in training their employees to raise their productivity. Economists sometimes wonder why companies spend this money when this incentivizes other companies to hire their employees away with higher salaries since employees gain human capital from training?\nLet’s say that it costs a company 25,000 dollars to teach their employees Python, but it raises their output by 2,500 per month. How many months would an employee need to stay for the company to find it profitable to pay for their employees to learn Python if their discount rate is r = 0.01?\n\n# Define cost of teaching python\ncost = 25_000\nr = 0.01\n\n# Per month value\nadded_value = 2500\n\nn_months = 0\ntotal_npv = 0.0\n\n# Put condition below here\nwhile False: # (replace False with your condition here)\n    n_months = n_months + 1  # Increment how many months they've worked\n\n    # Increase total_npv\n\n(back to text)\n\n\n\nTry to find the index of the first value in x that is greater than 0.999 using a for loop and break.\ntry iterating over range(len(x)).\n\nx = np.random.rand(10_000)\n# Your code here\n\n(back to text)\n\n\n\nWrite a for loop that adds up all values in x that are greater than or equal to 0.5.\nUse the continue word to end the body of the loop early for all values of x that are less than 0.5.\nTry starting your loop with for value in x: instead of iterating over the indices of x.\n\nx = np.random.rand(10_000)\n# Your code here\n\n(back to text)\n\n\n\nReturning to our previous example: print “{city} is in {state}” for each combination using a zip and a comprehension.\nTry using zip\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n# your code here\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#net-present-values-and-asset-pricing",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#net-present-values-and-asset-pricing",
    "title": "Control Flow",
    "section": "",
    "text": "In this lecture, we’ll introduce two related topics from economics:\n\nNet present valuations\n\nAsset pricing\n\nThese topics will motivate some of the programming we do in this course.\nIn economics and finance, “assets” provide a stream of payoffs.\nThese “assets” can be concrete or abstract: a stock pays dividends over time, a bond pays interest, an apple tree provides apples, a job pays wages, and an education provides possible jobs (which, in turn, pay wages).\nWhen deciding the price to pay for an asset or how to choose between different alternatives, we need to take into account that most people would prefer to receive 1 today vs. 1 next year.\nThis reflection on consumer preferences leads to the notion of a discount rate. If you are indifferent between receiving 1.00 today and 1.10 next year, then the discount rate over the next year is $ r = 0.10 $.\nIf we assume that an individuals preferences are consistent over time, then we can apply that same discount rate to valuing assets further into the future.\nFor example, we would expect that the consumer would be indifferent between consuming 1.00 today and $ (1+r)(1+r) = 1.21 $ dollars two years from now (i.e. discount twice).\nInverting this formula, 1 delivered two years from now is equivalent to $ $ today."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercise",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercise",
    "title": "Control Flow",
    "section": "",
    "text": "See exercise 1 in the exercise list.\n\n\n\nIf an asset pays a stream of payoffs over multiple time periods, then we can use a discount rate to calculate the value to the consumer of a entire sequence of payoffs.\nMost generally, we enumerate each discrete time period (e.g. year, month, day) by the index $ t $ where today is $ t=0 $ and the asset lives for $ T $ periods.\nList the payoff at each time period as $ y_t $, which we will assume, for now, is known in advance.\nThen if the discount factor is $ r $, the consumer “values” the payoff $ y_t $ delivered at time $ t $ as $ y_t $ where we note that if $ t=0 \\(, the value is just the current payoff\\) y_0 $.\nUsing this logic, we can write an expression for the value of the entire sequence of payoffs with a sum.\n \\[\nP_0 = \\sum_{t=0}^T \\left(\\frac{1}{1 + r}\\right)^t y_t \\tag{1}\n\\]\nIf $ y_t $ is a constant, then we can compute this sum with a simple formula!\nBelow, we present some useful formulas that come from infinite series that we will use to get our net present value formula.\nFor any constant $ 0 &lt; &lt; 1 $ and integer value $ &gt; 0 $,\n \\[\n\\begin{aligned}\n\\sum_{t=0}^{\\infty} \\beta^t & = \\frac{1}{1-\\beta}\\\\\n\\sum_{t=0}^{\\tau} \\beta^t &= \\frac{1- \\beta^{\\tau+1}}{1-\\beta}\\\\\n\\sum_{t=\\tau}^{\\infty} \\beta^t &=  \\frac{\\beta^{\\tau}}{1-\\beta}\n\\end{aligned} \\tag{2}\n\\]\nIn the case of an asset which pays one dollar until time $ T $, we can use these formulas, taking $ = $ and $ T = $, to find\n\\[\n\\begin{aligned}\nP_0 &= \\sum_{t=0}^T \\left(\\frac{1}{1 + r}\\right)^t = \\frac{1- (\\frac{1}{1+r})^{\\tau+1}}{1-\\frac{1}{1+r}}\\\\\n&= \\frac{1 + r}{r} - \\frac{1}{r}\\left(\\frac{1}{1+r} \\right)^\\tau\n\\end{aligned}\n\\]\nNote that we can also consider an asset that lives and pays forever if $ T= $, and from (2), the value of an asset which pays 1 forever is $ $."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#conditional-statements-and-blocks",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#conditional-statements-and-blocks",
    "title": "Control Flow",
    "section": "",
    "text": "Sometimes, we will only want to execute some piece of code if a certain condition is met.\nThese conditions can be anything.\nFor example, we might add to total sales if the transaction value is positive, but add to total returns if the value is negative.\nOr, we might want to add up all incurred costs, only if the transaction happened before a certain date.\nWe use conditionals to run particular pieces of code when certain criterion are met.\nConditionals are closely tied to booleans, so if you don’t remember what those are, go back to the basics lecture for a refresher.\nThe basic syntax for conditionals is\n\nif condition:\n    # code to run when condition is True\nelse:\n    # code to run if no conditions above are True\n\nNote that immediately following the condition, there is a colon and that the next line begins with blank spaces.\nUsing 4 spaces is a very strong convention, so that is what we do — we recommend that you do the same.\nAlso note that the else clause is optional.\nLet’s see some simple examples.\n\nif True:\n    print(\"This is where `True` code is run\")\n\nAlternatively, you could have a test which returns a booleans\n\nif 1 &lt; 2:\n     print(\"This is where `True` code is run\")\n\nThis example is equivalent to just typing the print statement, but the example below isn’t…\n\nif False:\n    print(\"This is where `True` code is run\")\n\nOr\n\nif 1 &gt; 2:\n     print(\"This is where `True` code is run\")\n\nNotice that when you run the cells above nothing is printed.\nThat is because the condition for the if statement was not true, so the code inside the indented block was never run.\nThis also allows us to demonstrate the role of indentation in determining the “block” of code.\n\nval = False\n\nif val is True: # check an expression\n    print(\"This is where `True` code is run\")\n    print(\"More code in the if block\")\nprint(\"Code runs after 'if' block, regardless of val\")"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-1",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-1",
    "title": "Control Flow",
    "section": "",
    "text": "See exercise 2 in the exercise list.\nThe next example shows us how else works.\n\nval = (2 == 4)  # returns False\nif val is True:\n    print(\"This is where `True` code is run\")\nelse:\n    print(\"This is where `False` code is run\")\n    print(\"More else code\")\nprint(\"Code runs after 'if' block, regardless of val\")\n\nThe if False: ... part of this example is the same as the example before, but now, we added an else: clause.\nIn this case, because the conditional for the if statement was not True, the if code block was not executed, but the else block was.\nFinally, the Condition is True is assumed in the if statement, and is often left out. For example, the following are identical\n\nif (1 &lt; 2) is True:\n    print(\"1 &lt; 2\")\n\nif 1 &lt; 2:\n    print(\"1 &lt; 2\")"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-2",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-2",
    "title": "Control Flow",
    "section": "",
    "text": "See exercise 3 in the exercise list."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-3",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-3",
    "title": "Control Flow",
    "section": "",
    "text": "See exercise 4 in the exercise list.\n\n\nSometimes, you have more than one condition you want to check.\nFor example, you might want to run a different set of code based on which quarter a particular transaction took place in.\nIn this case you could check whether the date is in Q1, or in Q2, or in Q3, or if not any of these it must be in Q4.\nThe way to express this type of conditional is to use one or more elif clause in addition to the if and the else.\nThe syntax is\n\nif condition1:\n    # code to run when condition1 is True\nelif condition2:\n    # code to run when condition2 is True\nelif condition3:\n    # code to run when condition3 is True\nelse:\n    # code to run when none of the above are true\n\nYou can include as many elif clauses as you want.\nAs before, the else part is optional.\nHere’s how we might express the quarter example referred to above.\n\nimport datetime\nhalloween = datetime.date(2017, 10, 31)\n\nif halloween.month &gt; 9:\n    print(\"Halloween is in Q4\")\nelif halloween.month &gt; 6:\n    print(\"Halloween is in Q3\")\nelif halloween.month &gt; 3:\n    print(\"Halloween is in Q2\")\nelse:\n    print(\"Halloween is in Q1\")\n\nNote that when there are multiple if or elif conditions, only the code corresponding to the first true clause is run.\nWe saw this in action above.\nWe know that when halloween.month &gt; 9 is true, then halloween.month &gt; 6 and halloween.month &gt; 3 must also be true, but only the code block associated with halloween.month &gt; 9 was printed."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#iteration",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#iteration",
    "title": "Control Flow",
    "section": "",
    "text": "When doing computations or analyzing data, we often need to repeat certain operations a finite number of times or until some condition is met.\nExamples include processing all data files in a directory (folder), aggregating revenues and costs for every period in a year, or computing the net present value of certain assets. (In fact, later in this section, we will verify the equations that we wrote down above.)\nThese are all examples of a programming concept called iteration.\nWe feel the concept is best understood through example, so we will present a contrived example and then discuss the details behind doing iteration in Python.\n\n\nSuppose we wanted to print out the first 10 integers and their squares.\nWe could do something like this.\n\nprint(f\"1**2 = {1**2}\")\nprint(f\"2**2 = {2**2}\")\nprint(f\"3**2 = {3**2}\")\nprint(f\"4**2 = {4**2}\")\n# .. and so on until 10\n\nAs you can see, the code above is repetitive.\nFor each integer, the code is exactly the same except for the two places where the “current” integer appears.\nSuppose that I asked you to write the same print statement for an int stored in a variable named i.\nYou might write the following code:\n\nprint(f\"{i}**2 = {i**2}\")\n\nThis more general version of the operation suggests a strategy for achieving our goal with less repetition: have a variable i take on the values 1 through 10 (Quiz: How can we use range to create the numbers 1 to 10?) and run the line of code above for each new value of i.\nThis can be accomplished with a for loop!\n\nfor i in range(1, 11):\n     print(f\"{i}**2 = {i**2}\")\n\nWhoa, what just happened?\nThe integer i took on the values in range(1, 11) one by one and for each new value it did the operations in the indented block (here just one line that called the print function).\n\n\n\nThe general structure of a standard for loop is as follows.\n\nfor item in iterable:\n   # operation 1 with item\n   # operation 2 with item\n   # ...\n   # operation N with item\n\nwhere iterable is anything capable of producing one item at a time (see here for official definition from the Python team).\nWe’ve actually already seen some of the most common iterables!\nLists, tuples, dicts, and range/zip/enumerate objects are all iterables.\nNote that we can have as many operations as we want inside the indented block.\nWe will refer to the indented block as the “body” of the loop.\nWhen the for loop is executed, item will take on one value from iterable at a time and execute the loop body for each value.\n\n\n\n\nSee exercise 5 in the exercise list.\nWhen iterating, each item in iterable might actually contain more than one value.\nRecall that tuples (and lists) can be unpacked directly into variables.\n\ntup = (4, \"test\")\ni, x = tup\nprint(f\"i = {i}, x = {x}, tup = {tup}\")\n\nAlso, recall that the value of a enumerate(iterable) is a tuple of the form (i, x) where iterable[i] == x.\nWhen we use enumerate in a for loop, we can “unpack” both values at the same time as follows:\n\n# revenue by quarter\ncompany_revenue = [5.12, 5.20, 5.50, 6.50]\n\nfor index, value in enumerate(company_revenue):\n    print(f\"quarter {index} revenue is ${value} million\")\n\nSimilarly, the index can be used to access another vector.\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\nfor index, city in enumerate(cities):\n    state = states[index]\n    print(f\"{city} is in {state}\")\n\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nA related but slightly different form of iteration is to repeat something until some condition is met.\nThis is typically achieved using a while loop.\nThe structure of a while loop is\n\nwhile True_condition:\n    # repeat these steps\n\nwhere True_condition is some conditional statement that should evaluate to True when iterations should continue and False when Python should stop iterating.\nFor example, suppose we wanted to know the smallest N such that $ _{i=0}^N i &gt; 1000 $.\nWe figure this out using a while loop as follows.\n\ntotal = 0\ni = 0\nwhile total &lt;= 1000:\n    i = i + 1\n    total = total + i\n\nprint(\"The answer is\", i)\n\nLet’s check our work.\n\n# Should be just less than 1000 because range(45) goes from 0 to 44\nsum(range(45))\n\n\n# should be between 990 + 45 = 1035\nsum(range(46))\n\nA warning: one common programming error with while loops is to forget to set the variable you use in the condition prior to executing. For example, take the following code which correctly sets a counter\n\ni = 0\n\nAnd then executes a while loop\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\nprint(\"done\")\n\nNo problems. But if you were to execute the above cell again, or another cell, the i=3 remains, and code is never executed (since i &lt; 3 begins as False).\n\nwhile i &lt; 3:\n    print(i)\n    i = i + 1\nprint(\"done\")\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\n\n\n\nSometimes we want to stop a loop early if some condition is met.\nLet’s revisit the example of finding the smallest N such that $ _{i=0}^N i &gt; 1000 $.\nClearly N must be less than 1000, so we know we will find the answer if we start with a for loop over all items in range(1001).\nThen, we can keep a running total as we proceed and tell Python to stop iterating through our range once total goes above 1000.\n\ntotal = 0\nfor i in range(1001):\n    total = total + i\n    if total &gt; 1000:\n        break\n\nprint(\"The answer is\", i)\n\n\n\n\nSee exercise 8 in the exercise list.\n\n\n\nSometimes we might want to stop the body of a loop early if a condition is met.\nTo do this we can use the continue keyword.\nThe basic syntax for doing this is:\n\nfor item in iterable:\n    # always do these operations\n    if condition:\n        continue\n\n    # only do these operations if condition is False\n\nInside the loop body, Python will stop that loop iteration of the loop and continue directly to the next iteration when it encounters the continue statement.\nFor example, suppose I ask you to loop over the numbers 1 to 10 and print out the message “{i} An odd number!” whenever the number i is odd, and do nothing otherwise.\nYou can use continue to do this as follows:\n\nfor i in range(1, 11):\n    if i % 2 == 0:  # an even number... This is modulus division\n        continue\n\n    print(i, \"is an odd number!\")\n\n\n\n\nSee exercise 9 in the exercise list."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#comprehension",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#comprehension",
    "title": "Control Flow",
    "section": "",
    "text": "Often, we will want to perform a very simple operation for every element of some iterable and create a new iterable with these values.\nThis could be done by writing a for loop and saving each value, but often using what is called a comprehension is more readable.\nLike many Python concepts, a comprehension is easiest to understand through example.\nImagine that we have a list x with a list of numbers. We would like to create a list x2 which has the squared values of x.\n\nx = list(range(4))\n\n# Create squared values with a loop\nx2_loop = []\nfor x_val in x:\n    x2_loop.append(x_val**2)\n\n# Create squared values with a comprehension\nx2_comp = [x_val**2 for x_val in x]\n\nprint(x2_loop)\nprint(x2_comp)\n\nNotice that much of the same text appears when we do the operation in the loop and when we do the operation with the comprehension.\n\nWe need to specify what we are iterating over – in both cases, this is for x_val in x.\n\nWe need to square each element x_val**2.\n\nIt needs to be stored somewhere – in x2_loop, this is done by appending each element to a list, and in x2_comp, this is done automatically because the operation is enclosed in a list.\n\nWe can do comprehension with many different types of iterables, so we demonstrate a few more below.\n\n# Create a dictionary from lists\ntickers = [\"AAPL\", \"GOOGL\", \"TVIX\"]\nprices = [175.96, 1047.43, 8.38]\nd = {key: value for key, value in zip(tickers, prices)}\nd\n\n\n# Create a list from a dictionary\nd = {\"AMZN\": \"Seattle\", \"TVIX\": \"Zurich\", \"AAPL\": \"Cupertino\"}\n\nhq_cities = [d[ticker] for ticker in d.keys()]\nhq_cities\n\n\nimport math\n\n# List from list\nx = range(10)\n\nsin_x = [math.sin(x_val) for x_val in x]\nsin_x"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-9",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercise-9",
    "title": "Control Flow",
    "section": "",
    "text": "See exercise 10 in the exercise list.\nFinally, we can use this approach to build complicated nested dictionaries.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nexports = [ {\"manufacturing\": 2.4, \"agriculture\": 1.5, \"services\": 0.5},\n            {\"manufacturing\": 2.5, \"agriculture\": 1.4, \"services\": 0.9},\n            {\"manufacturing\": 2.7, \"agriculture\": 1.4, \"services\": 1.5}]\ndata = zip(years, gdp_data,exports)\ndata_dict = {year : {\"gdp\" : gdp, \"exports\": exports} for year, gdp, exports in data}\nprint(data_dict)\n\n# total exports by year\n[data_dict[year][\"exports\"][\"services\"] for year in data_dict.keys()]"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/control_flow.html#exercises",
    "href": "tutorials/session_1/python_fundamentals/control_flow.html#exercises",
    "title": "Control Flow",
    "section": "",
    "text": "Government bonds are often issued as zero-coupon bonds meaning that they make no payments throughout the entire time that they are held, but, rather make a single payment at the time of maturity.\nHow much should you be willing to pay for a zero-coupon bond that paid 100 in 10 years with an interest rate of 5%?\n\n# your code here\n\n(back to text)\n\n\n\nRun the following two variations on the code with only a single change in the indentation.\nAfter, modify the x to print 3 and then 2, 3 instead.\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\n    print(\"2\")\nprint(\"3\")\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\nprint(\"2\") # changed the indentation\nprint(\"3\")\n\n(back to text)\n\n\n\nUsing the code cell below as a start, print \"Good afternoon\" if the current_time is past noon.\nOtherwise, do nothing.\nWrite some conditional based on current_time.hour.\n\nimport datetime\ncurrent_time = datetime.datetime.now()\n\n## your code here\n\nmore text after\n(back to text)\n\n\n\nIn this example, you will generate a random number between 0 and 1 and then display “x &gt; 0.5” or “x &lt; 0.5” depending on the value of the number.\nThis also introduces a new package numpy.random for drawing random numbers (more in the randomness lecture).\n\nimport numpy as np\nx = np.random.random()\nprint(f\"x = {x}\")\n\n## your code here\n\n(back to text)\n\n\n\nIn economics, when an individual has some knowledge, skills, or education which provides them with a source of future income, we call it human capital.\nWhen a student graduating from high school is considering whether to continue with post-secondary education, they may consider that it gives them higher paying jobs in the future, but requires that they don’t begin working until after graduation.\nConsider the simplified example where a student has perfectly forecastable employment and is given two choices:\n\nBegin working immediately and make 40,000 a year until they retire 40 years later.\n\nPay 5,000 a year for the next 4 years to attend university, then get a job paying 50,000 a year until they retire 40 years after making the college attendance decision.\n\nShould the student enroll in school if the discount rate is r = 0.05?\n\n# Discount rate\nr = 0.05\n\n# High school wage\nw_hs = 40_000\n\n# College wage and cost of college\nc_college = 5_000\nw_college = 50_000\n\n# Compute npv of being a hs worker\n\n# Compute npv of attending college\n\n# Compute npv of being a college worker\n\n# Is npv_collegeworker - npv_collegecost &gt; npv_hsworker\n\n(back to text)\n\n\n\nInstead of the above, write a for loop that uses the lists of cities and states below to print the same “{city} is in {state}” using a zip instead of an enumerate.\nTry using zip\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n# Your code here\n\n(back to text)\n\n\n\nCompanies often invest in training their employees to raise their productivity. Economists sometimes wonder why companies spend this money when this incentivizes other companies to hire their employees away with higher salaries since employees gain human capital from training?\nLet’s say that it costs a company 25,000 dollars to teach their employees Python, but it raises their output by 2,500 per month. How many months would an employee need to stay for the company to find it profitable to pay for their employees to learn Python if their discount rate is r = 0.01?\n\n# Define cost of teaching python\ncost = 25_000\nr = 0.01\n\n# Per month value\nadded_value = 2500\n\nn_months = 0\ntotal_npv = 0.0\n\n# Put condition below here\nwhile False: # (replace False with your condition here)\n    n_months = n_months + 1  # Increment how many months they've worked\n\n    # Increase total_npv\n\n(back to text)\n\n\n\nTry to find the index of the first value in x that is greater than 0.999 using a for loop and break.\ntry iterating over range(len(x)).\n\nx = np.random.rand(10_000)\n# Your code here\n\n(back to text)\n\n\n\nWrite a for loop that adds up all values in x that are greater than or equal to 0.5.\nUse the continue word to end the body of the loop early for all values of x that are less than 0.5.\nTry starting your loop with for value in x: instead of iterating over the indices of x.\n\nx = np.random.rand(10_000)\n# Your code here\n\n(back to text)\n\n\n\nReturning to our previous example: print “{city} is in {state}” for each combination using a zip and a comprehension.\nTry using zip\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n# your code here\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/index.html",
    "href": "tutorials/session_1/python_fundamentals/index.html",
    "title": "Python Fundamentals",
    "section": "",
    "text": "In this section, we begin with the basics.\nWe will talk about what a programming language is and how computers use them to perform operations.\nWe discuss why we chose the Python language for this course.\nWe learn about core concepts like variables, data-types, and functions.\nWe will become familiar with the core data-types built into Python, some standard functions we will frequently use, and learn how to define our own functions.\nBy the end, you should have a solid grasp on core Python concepts, be prepared to study the next sections on numerical programming, and feel comfortable handling data."
  },
  {
    "objectID": "tutorials/session_3/open_ai_api.html",
    "href": "tutorials/session_3/open_ai_api.html",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "api_key = \"\" # set the openAI api key\n\n\ndef f(a,b): a + b\n\n\n\nThe openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n{'warning': 'This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations',\n 'id': 'cmpl-8VL769136bxJoq4c1qQhKbk7JStuX',\n 'object': 'text_completion',\n 'created': 1702480020,\n 'model': 'text-davinci-002',\n 'choices': [{'text': ', there was a web socket, that you could message, that almost always engaged',\n   'index': 0,\n   'logprobs': None,\n   'finish_reason': 'length'}],\n 'usage': {'prompt_tokens': 4, 'completion_tokens': 16, 'total_tokens': 20}}\n\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:\n\n\n\n\n\nImport openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\nimport openai\n\n\nRedo same exercises as with the Rest API.\n\n\n\n\n\nWhat is GPT’s answer when you ask “What is your favourite color?”\n\n\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted\n    api_key=key,\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What is your favourite color?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nchat_completion.choices[0].message.content\n\n\"As an AI, I don't have personal preferences or the ability to see colors.\"\n\n\n\nchat_completion.choices[0].message\n\nChatCompletionMessage(content=\"As an AI, I don't have personal preferences or the ability to see colors.\", role='assistant', function_call=None, tool_calls=None)\n\n\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What is your favourite color?\",\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"As an AI, I don't have personal preferences or the ability to see colors.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"If you were a human, what would be your favourite color?\",\n        },\n        \n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nchat_completion.choices[0].message.content\n\n\"If I were a human, my favorite color could be anything! However, it's important to note that as an AI, I don't have personal preferences or the ability to perceive colors.\"\n\n\n\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n\n\n# let's try with the completions api\n\n\nclient.completions.create(model=\"text-davinci-003\" ,prompt=\"What is your favorite color?\").choices[0].text\n\n'\\n\\nMy favorite color is blue.'\n\n\n\nclient.completions.create(model=\"gpt-3.5-turbo-instruct\" ,prompt=\"What is your favorite color?\").choices[0].text\n\n'\\nAs an AI, I do not have the ability to see or experience colors'\n\n\n\n(bonus) By providing more context, can you override ChatGPT’s default answer?\n\n\nclient.completions.create(model=\"gpt-3.5-turbo-instruct\" ,prompt=\"If you were a woman what would be your most likely favorite color?\").choices[0].text\n\n'\\n\\nIt is impossible for me to have a favorite color as I am an AI'\n\n\n\n\n\n\nLoad the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "tutorials/session_3/open_ai_api.html#rest-api",
    "href": "tutorials/session_3/open_ai_api.html#rest-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "The openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n{'warning': 'This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations',\n 'id': 'cmpl-8VL769136bxJoq4c1qQhKbk7JStuX',\n 'object': 'text_completion',\n 'created': 1702480020,\n 'model': 'text-davinci-002',\n 'choices': [{'text': ', there was a web socket, that you could message, that almost always engaged',\n   'index': 0,\n   'logprobs': None,\n   'finish_reason': 'length'}],\n 'usage': {'prompt_tokens': 4, 'completion_tokens': 16, 'total_tokens': 20}}\n\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:"
  },
  {
    "objectID": "tutorials/session_3/open_ai_api.html#python-api",
    "href": "tutorials/session_3/open_ai_api.html#python-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Import openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\nimport openai\n\n\nRedo same exercises as with the Rest API."
  },
  {
    "objectID": "tutorials/session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "href": "tutorials/session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "What is GPT’s answer when you ask “What is your favourite color?”\n\n\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted\n    api_key=key,\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What is your favourite color?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nchat_completion.choices[0].message.content\n\n\"As an AI, I don't have personal preferences or the ability to see colors.\"\n\n\n\nchat_completion.choices[0].message\n\nChatCompletionMessage(content=\"As an AI, I don't have personal preferences or the ability to see colors.\", role='assistant', function_call=None, tool_calls=None)\n\n\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What is your favourite color?\",\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"As an AI, I don't have personal preferences or the ability to see colors.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"If you were a human, what would be your favourite color?\",\n        },\n        \n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nchat_completion.choices[0].message.content\n\n\"If I were a human, my favorite color could be anything! However, it's important to note that as an AI, I don't have personal preferences or the ability to perceive colors.\"\n\n\n\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n\n\n# let's try with the completions api\n\n\nclient.completions.create(model=\"text-davinci-003\" ,prompt=\"What is your favorite color?\").choices[0].text\n\n'\\n\\nMy favorite color is blue.'\n\n\n\nclient.completions.create(model=\"gpt-3.5-turbo-instruct\" ,prompt=\"What is your favorite color?\").choices[0].text\n\n'\\nAs an AI, I do not have the ability to see or experience colors'\n\n\n\n(bonus) By providing more context, can you override ChatGPT’s default answer?\n\n\nclient.completions.create(model=\"gpt-3.5-turbo-instruct\" ,prompt=\"If you were a woman what would be your most likely favorite color?\").choices[0].text\n\n'\\n\\nIt is impossible for me to have a favorite color as I am an AI'"
  },
  {
    "objectID": "tutorials/session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "href": "tutorials/session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Load the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html",
    "href": "tutorials/session_2/sentiment_analysis_correction.html",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5.\n\n\n\nWe use the News Sentiment Dataset from Kaggle.\n\ncd tutorials/session_2\n\n/files/tutorials/session_2\n\n\n\npwd\n\n'/files/tutorials/session_2'\n\n\n\nImport Dataset as a pandas dataframe\n\n\nimport pandas\ndf = pandas.read_csv(\"Tweets.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n0\ncb774db0d1\nI`d have responded, if I were going\nI`d have responded, if I were going\nneutral\n\n\n1\n549e992a42\nSooo SAD I will 🦈 miss you here in San Diego!!!\nSooo SAD\nnegative\n\n\n2\n088c60f138\nmy boss is bullying me...\nbullying me\nnegative\n\n\n3\n9642c003ef\nwhat interview! leave me alone\nleave me alone\nnegative\n\n\n4\n358bd9e861\nSons of ****, why couldn`t they put them on t...\nSons of ****,\nnegative\n\n\n...\n...\n...\n...\n...\n\n\n27476\n4eac33d1c0\nwish we could come see u on Denver husband l...\nd lost\nnegative\n\n\n27477\n4f4c4fc327\nI`ve wondered about rake to. The client has ...\n, don`t force\nnegative\n\n\n27478\nf67aae2310\nYay good for both of you. Enjoy the break - y...\nYay good for both of you.\npositive\n\n\n27479\ned167662a5\nBut it was worth it ****.\nBut it was worth it ****.\npositive\n\n\n27480\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\nAll this flirting going on - The ATG smiles. Y...\nneutral\n\n\n\n\n27481 rows × 4 columns\n\n\n\n\ndf.__class__\n\npandas.core.frame.DataFrame\n\n\n\n# indices refer to columns by default\ndf['text']\n\n0                      I`d have responded, if I were going\n1          Sooo SAD I will 🦈 miss you here in San Diego!!!\n2                                my boss is bullying me...\n3                           what interview! leave me alone\n4         Sons of ****, why couldn`t they put them on t...\n                               ...                        \n27476     wish we could come see u on Denver  husband l...\n27477     I`ve wondered about rake to.  The client has ...\n27478     Yay good for both of you. Enjoy the break - y...\n27479                           But it was worth it  ****.\n27480       All this flirting going on - The ATG smiles...\nName: text, Length: 27481, dtype: object\n\n\n\ndf.loc[2, 'text']\n\n'my boss is bullying me...'\n\n\n\n# check one entry:\ndf.loc[1200]\n\ntextID                                                  968964a722\ntext              hahahah of course  they have such a nasty dis...\nselected_text                       e such a nasty display picture\nsentiment                                                 negative\nName: 1200, dtype: object\n\n\n\n# keep the text from one entry\ndf.loc[1200]['text']\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\nDescribe Dataset (text and graphs)\n\n\ndf.describe()\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\ncount\n27481\n27480\n27480\n27481\n\n\nunique\n27481\n27480\n22463\n3\n\n\ntop\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\ngood\nneutral\n\n\nfreq\n1\n1\n199\n11118\n\n\n\n\n\n\n\n\n# information about the distrbution of sentiments\nsentiments = df['sentiment']\n\n\ncounts = sentiments.value_counts()\n\n\ncounts / sum(counts) * 100\n\nsentiment\nneutral     40.457043\npositive    31.228849\nnegative    28.314108\nName: count, dtype: float64\n\n\n\n# this is a series where a line is True only if df['text'] contains \"trump\"\nind = df['text'].str.contains(\"trump\", na=False)\nind\n\n0        False\n1        False\n2        False\n3        False\n4        False\n         ...  \n27476    False\n27477    False\n27478    False\n27479    False\n27480    False\nName: text, Length: 27481, dtype: bool\n\n\n\n# which tweets contain word \"trump\"\ndf[ind]\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n1589\n6c5505a37c\nEnjoy! Family trumps everything\nEnjoy! Family trumps everything\npositive\n\n\n6235\n234a562dd9\nLOL I love my MacBook too. Oh and my iMac. Ca...\nlove\npositive\n\n\n14005\n464eafe267\nHow to get a $40 trumpet book - get caught in ...\ncaught\nnegative\n\n\n14615\nfc16472bdf\nSick kid trumps advance planning. Bummer\nSick\nnegative\n\n\n22230\n2762b6624b\n_fan Been busy trumping your cheese omlette wi...\n_fan Been busy trumping your cheese omlette wi...\nneutral\n\n\n\n\n\n\n\n\n# how many tweets contain word \"trump\"\nsum(ind)\n\n5\n\n\n\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?\n\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_test_split?\n\n\nSignature:\ntrain_test_split(\n    *arrays,\n    test_size=None,\n    train_size=None,\n    random_state=None,\n    shuffle=True,\n    stratify=None,\n)\nDocstring:\nSplit arrays or matrices into random train and test subsets.\nQuick utility that wraps input validation,\n``next(ShuffleSplit().split(X, y))``, and application to input data\ninto a single call for splitting (and optionally subsampling) data into a\none-liner.\nRead more in the :ref:`User Guide &lt;cross_validation&gt;`.\nParameters\n----------\n*arrays : sequence of indexables with same length / shape[0]\n    Allowed inputs are lists, numpy arrays, scipy-sparse\n    matrices or pandas dataframes.\ntest_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the proportion\n    of the dataset to include in the test split. If int, represents the\n    absolute number of test samples. If None, the value is set to the\n    complement of the train size. If ``train_size`` is also None, it will\n    be set to 0.25.\ntrain_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the\n    proportion of the dataset to include in the train split. If\n    int, represents the absolute number of train samples. If None,\n    the value is automatically set to the complement of the test size.\nrandom_state : int, RandomState instance or None, default=None\n    Controls the shuffling applied to the data before applying the split.\n    Pass an int for reproducible output across multiple function calls.\n    See :term:`Glossary &lt;random_state&gt;`.\nshuffle : bool, default=True\n    Whether or not to shuffle the data before splitting. If shuffle=False\n    then stratify must be None.\nstratify : array-like, default=None\n    If not None, data is split in a stratified fashion, using this as\n    the class labels.\n    Read more in the :ref:`User Guide &lt;stratification&gt;`.\nReturns\n-------\nsplitting : list, length=2 * len(arrays)\n    List containing train-test split of inputs.\n    .. versionadded:: 0.16\n        If the input is sparse, the output will be a\n        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n        input type.\nExamples\n--------\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.model_selection import train_test_split\n&gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)\n&gt;&gt;&gt; X\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n&gt;&gt;&gt; list(y)\n[0, 1, 2, 3, 4]\n&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\n&gt;&gt;&gt; X_train\narray([[4, 5],\n       [0, 1],\n       [6, 7]])\n&gt;&gt;&gt; y_train\n[2, 0, 3]\n&gt;&gt;&gt; X_test\narray([[2, 3],\n       [8, 9]])\n&gt;&gt;&gt; y_test\n[1, 4]\n&gt;&gt;&gt; train_test_split(y, shuffle=False)\n[[0, 1, 2], [3, 4]]\nFile:      /opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py\nType:      function\n\n\n\n\nimport sklearn\ndf_, df_test  = sklearn.model_selection.train_test_split(df, test_size=0.1)\ndf_train, df_validation  = sklearn.model_selection.train_test_split(df_, test_size=0.1)\n\n\ndf\n\n(2749, 4)\n\n\n\ndf_train.shape\n\n(24732, 4)\n\n\n\n\n\n\nExtract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix.\n\n\n\n\n\nSetup an openai key. Explore openai completion API.\n\n\nimport openai\n\n\n# make sure we have the right version. openai-python API has changed two weeks ago!\nfrom openai import version\nopenai.version.VERSION\n\n'1.3.5'\n\n\n\n# now we setup the API key\n# api_key = \"your_key\"\n# if the notebook is stored online we avoid setting the api key directly\nimport getpass\napi_key = getpass.getpass(prompt=\"Enter your OpenAI API key\")\n\nEnter your OpenAI API key ········\n\n\n\n# lookup on google \"openai completion python\"\n# from the github website, copy the example text\n\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=api_key,\n)\n\nresponse = client.completions.create(\n    prompt = \"Say this is a test\",\n    model=\"gpt-3.5-turbo-instruct\",\n)\n\n\n# examine the response object\n\n\n# there is only one response\n# recall that index numbering starts at 0 with Python\nresponse.choices[0].text\n\n'\\n\\n\"This is a test.\"'\n\n\n\nprint( response.choices[0].text )\n\n\n\n\"This is a test.\"\n\n\n\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\n\n\ntweet = df['text'][1200]\ntweet\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\n# use text concatenation\nprompt = \"Classify the following text as, positive, negative or neutral:\\n\\n\"\nprompt += \"Tweet: \"\nprompt += tweet\nprompt += \"\\n\\n\"\nprompt += \"Answer: \"\n\n\nprint(prompt)\n\nClassify the following text as, positive, negative or neutral:\n\nTweet:  hahahah of course  they have such a nasty display picture :`)\n\nAnswer: \n\n\n\nmodel = \"gpt-3.5-turbo-instruct\"\nresponse = client.completions.create(model=model, prompt=prompt, max_tokens=50)\n\ngenerated_text = response.choices[0].text\nprint(generated_text)\n\n Negative\n\n\n\n# use string interpolation:\nprompt = f\"\"\"Classify the following text as, positive, negative or neutral:\n\nTweet: {tweet}\nAnswer:\n\"\"\"\nprint(prompt)\n\nClassify the following text as, positive, negative or neutral:\n\nTweet:  hahahah of course  they have such a nasty display picture :`)\nAnswer:\n\n\n\n\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer.\n\n\ndef sentiment( tweet: str, model = \"gpt-3.5-turbo-instruct\"  )-&gt;int:\n    \"\"\"Compute the sentiment for the tweet.\n\n    tweet: string containing the tweet\n    model: string characterizing the openai model to use\n    \"\"\"\n    \n    # this is inside the function (indented)\n\n    # to indent a line Ctrl+] (right) or Ctrl+[\n    # on mac: Ctrl is Cmd\n\n    # build the prompt\n    prompt = f\"\"\"Classify the following text as, positive, negative or neutral:\n\n    Tweet: {tweet}\n    Answer:\n    \"\"\"\n\n    response = client.completions.create(model=model, prompt=prompt, max_tokens=50)\n    generated_text = response.choices[0].text\n    \n    std_gen_text = generated_text.lower().strip()\n\n    if std_gen_text == \"positive\":\n        return +1\n    elif std_gen_text==\"negative\": #elseif\n        return -1\n    elif std_gen_text==\"neutral\":\n        return 0\n    else:\n        print(\"Unrecognized output\")\n        return pandas.NA\n    \n# this is outside\n\n\nsentiment?\n\n\nSignature: sentiment(tweet: str, model='gpt-3.5-turbo-instruct') -&gt; int\nDocstring:\nCompute the sentiment for the tweet.\ntweet: string containing the tweet\nmodel: string characterizing the openai model to use\nFile:      /tmp/ipykernel_8903/666341508.py\nType:      function\n\n\n\n\nsentiment(\"prime number 29 is an incredible number\")\n\n'positive'\n\n\n\nresp = sentiment(\"prime number 29 is an incredible number\", model=\"davinci-002\" )\n\nException: Unrecognized output\n\n\n\nprint(resp)\n\n Positive: prime number 29 is an incredible number, because...\n     Neutral: prime number 29 is an incredible number, so...\n     Negative: prime number 29 is an incredible number, even though...\n\ntext-mining classification\n\nshare|im\n\n\n\n\n\n\nCompare the various methods on the test set.\n\n\n# keep the 50 first elements:\ndf_mini = df_test.iloc[:50,:]\n\n# iloc is more adequate for integer indexing\n\n\nvalues = df_mini['text'].apply(sentiment)\n\n\n# compare accuracy against labels\n# add to df_mini\ndf_mini[\"predicted_sentiment\"] = values\n\n/tmp/ipykernel_8903/3713138410.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_mini[\"predicted_sentiment\"] = values\n\n\n\n# compute numerical values for the labels\ndef fun(val):\n    if val == \"positive\":\n        return +1\n    elif val==\"negative\": #elseif\n        return -1\n    elif val==\"neutral\":\n        return 0\ndf_mini['numerical_sentiment'] = df_mini['sentiment'].apply(fun)\n\n/tmp/ipykernel_8903/2987017452.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_mini['numerical_sentiment'] = df_mini['sentiment'].apply(fun)\n\n\n\ndf_mini\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\npredicted_sentiment\nnumerical_sentiment\n\n\n\n\n2747\n331b42de7d\n_Mitchell i`ve never been to the opera before....\ni`ve never been to the opera before...don`t th...\nneutral\n0\n0\n\n\n3885\n22ecd73521\nSo apparently i left my front door wide open b...\nLove\npositive\n0\n1\n\n\n20348\n531fe402e7\nJust started raining in earnest... guess golf ...\nJust started raining in earnest... guess golf ...\nneutral\n-1\n0\n\n\n3591\nbfdad27a0d\nLoved the comment on flashcads! I`m old schoo...\nLoved\npositive\n1\n1\n\n\n269\nde8c4c410d\nHell Yeah!\nHell Yeah!\nneutral\n1\n0\n\n\n18610\n43cc688b89\nmight be seeing my god mothers little boy in a...\ncute\npositive\n1\n1\n\n\n26279\n79c0162c77\nuseless tweet! LOL jk yay!!! You`re coming tm...\nuseless\nnegative\n0\n-1\n\n\n7443\ne944e54713\nJust got home, doing art all day.. i want to b...\nJust got home, doing art all day.. i want to b...\nneutral\n0\n0\n\n\n26757\neb6f587edb\nCan`t I just be a stay at home mom already\nCan`t I just be a stay at home mom already\nneutral\n0\n0\n\n\n12591\na590123cd9\nLoL!! I still would have got a look at his f...\nLoL!! I still would have got a look at his fa...\nneutral\n0\n0\n\n\n2931\nb1e3728694\nI hope when you`re calling this the shitshow...\ne when you`re calling this the shitshow you me...\nneutral\n0\n0\n\n\n841\n81adf60881\nI`ve read good things bout it. Just not feeli...\ngood\npositive\n0\n1\n\n\n15253\nee5b92dd36\nTWEEEEEET! good morning twitterland! going to ...\ngood mo\npositive\n0\n1\n\n\n13587\ne62c88c16c\nbusy exam week coming up! always look on the b...\nalways look on the bright side of life\npositive\n1\n1\n\n\n20076\n04795b9c4a\nthe classes with my students are over gonna m...\ngonna miss them...\nnegative\n1\n-1\n\n\n12305\n52618a6457\nI know. I have such guilt associated with pi...\nh guilt\nnegative\n-1\n-1\n\n\n23178\ne4e71486e3\nIf anyone needs help with images, let me know ...\ni will convo you\npositive\n0\n1\n\n\n18086\n4b0a1d060d\n..dat dude look crazy w/ dat hair on his face ...\n.these dudes are clowns\nnegative\n-1\n-1\n\n\n23410\ne4cb8a6252\nLast Heroes ep until Sept Sick & drugged for ...\nlacking\nnegative\n-1\n-1\n\n\n14581\na838d1a793\nam sitting in the library with eyes half close...\nam sitting in the library with eyes half close...\nneutral\n-1\n0\n\n\n17564\n588e531efe\nMoooorning! Fancy a coffee?\nMoooorning! Fancy a coffee?\nneutral\n0\n0\n\n\n14747\n344467bdaf\nay buti pa kayo!!!! uy thank you!!\ny thank you!!\npositive\n1\n1\n\n\n21466\n4f5cb8c34f\nAll I want to do is sit back & relax for a lit...\nAll I want to do is sit back & relax for a lit...\nneutral\n-1\n0\n\n\n8975\nbd042c2954\nI saw an all red Audi on the highway. I sped ...\nMy loss\nnegative\n-1\n-1\n\n\n19747\n29506f993d\nYeah, `Age of Aquarius` IS a pretty scary song\nscary\nnegative\n-1\n-1\n\n\n18970\n3bd10905ed\nUgh, i hate waiting in airports. I couldn`t fi...\ni hate\nnegative\n-1\n-1\n\n\n22914\n35bd63a569\ni take it you`re not a fan\ni take it you`re not a fan\nnegative\n-1\n-1\n\n\n455\n754ebd84b4\nhttp://twitpic.com/67qv3 - Me at Forever 21 E...\nMe at Forever 21 Ethan couldn`t be there\nnegative\n0\n-1\n\n\n1077\n3d5c1ed21b\nUp is out? I didn`t get the memo It looks ...\no It looks amazi\npositive\n0\n1\n\n\n11170\n45b75eb618\nsunniest week for ages....and exams\nsunniest week for ages....and exams\nneutral\n1\n0\n\n\n7434\ne2e0d8b057\nI have class tomorrow and tomorrow is Saturday...\nhate\nnegative\n-1\n-1\n\n\n6188\n5c5522b7b7\nAND, We have your fabulous interracial ****! ...\nAND, We have your fabulous interracial ****! ...\npositive\n1\n1\n\n\n405\nbd0fa6cebd\nthe 'no pants' idea could be the new attempt ...\nthe 'no pants' idea could be the new attempt w...\nneutral\n0\n0\n\n\n13386\n9d7b65be19\nHaha. I just won a $1000 bet. I settled for $1...\nwon\npositive\n1\n1\n\n\n9674\n0a87bc8dfd\nThe reason why I can`t find the latest Arena m...\nrecession.\nnegative\n-1\n-1\n\n\n16411\n7d1e81e0b9\nI know we need it but I`m not a fan of daily ...\nenjoy\npositive\n-1\n1\n\n\n15736\n58015c3988\nI know what you mean rain sucks...\nn sucks\nnegative\n-1\n-1\n\n\n26158\n7949730012\nwhy weren`t we invited?\nwhy weren`t we invited?\nneutral\n-1\n0\n\n\n1391\n743c5b85ca\nwatching Bones with Naty. Have made her a fan!...\nfan!\npositive\n1\n1\n\n\n4176\na27a31f5b8\n- well i greatly appreciate your comment. Th...\ngreatly appreciate\npositive\n1\n1\n\n\n26841\n8d8b6e78ae\nSome idiot just crashed into me on his bike. ...\ncrashed\nnegative\n-1\n-1\n\n\n15187\ne47b0e317c\ndamnit i didn`t but neither did you so win!\ndamnit i didn`t but neither did you so win!\nneutral\n0\n0\n\n\n20692\nb36d8acbd1\nYes, you should write an article.\nYes, you should write an article.\nneutral\n0\n0\n\n\n20657\n60c30e4bd8\nSometimes all it takes to solve our problems i...\nHope today is beautiful for you\npositive\n1\n1\n\n\n12794\n112e8afc05\nr that squeeze bacon looks like poop\nr that squeeze bacon looks like poop\nneutral\n-1\n0\n\n\n8793\n51f98e5b08\nup and at work im ina good mood\ngood\npositive\n1\n1\n\n\n4670\nb1e9db3db7\ngood day to all of you!! Another lindy day tod...\ngood\npositive\n1\n1\n\n\n14864\n5a0e0c34b8\nis super happy at the new interest rate. whoo...\nsuper happy\npositive\n1\n1\n\n\n22529\n9389b2e59d\nLOL. dood, i love you and miss you.\ni love you and miss you.\nneutral\n1\n0\n\n\n4227\ndfa0d5ca14\nI just dyededed my hair\nI just dyededed my hair\nneutral\n0\n0\n\n\n\n\n\n\n\n\n# number of true values:\nTV = sum(df_mini['predicted_sentiment']==df_mini[\"numerical_sentiment\"])\n\n\nFV = sum(df_mini['predicted_sentiment']!=df_mini[\"numerical_sentiment\"])\n\n\n# accuracy rrate:\n\nTV/(TV+FV)\n\n0.66\n\n\n\n# confusion matrix\n# ...\n\n\ndf_mini[df_mini['predicted_sentiment']!=df_mini[\"numerical_sentiment\"]]\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\npredicted_sentiment\nnumerical_sentiment\n\n\n\n\n3885\n22ecd73521\nSo apparently i left my front door wide open b...\nLove\npositive\n0\n1\n\n\n20348\n531fe402e7\nJust started raining in earnest... guess golf ...\nJust started raining in earnest... guess golf ...\nneutral\n-1\n0\n\n\n269\nde8c4c410d\nHell Yeah!\nHell Yeah!\nneutral\n1\n0\n\n\n26279\n79c0162c77\nuseless tweet! LOL jk yay!!! You`re coming tm...\nuseless\nnegative\n0\n-1\n\n\n841\n81adf60881\nI`ve read good things bout it. Just not feeli...\ngood\npositive\n0\n1\n\n\n15253\nee5b92dd36\nTWEEEEEET! good morning twitterland! going to ...\ngood mo\npositive\n0\n1\n\n\n20076\n04795b9c4a\nthe classes with my students are over gonna m...\ngonna miss them...\nnegative\n1\n-1\n\n\n23178\ne4e71486e3\nIf anyone needs help with images, let me know ...\ni will convo you\npositive\n0\n1\n\n\n14581\na838d1a793\nam sitting in the library with eyes half close...\nam sitting in the library with eyes half close...\nneutral\n-1\n0\n\n\n21466\n4f5cb8c34f\nAll I want to do is sit back & relax for a lit...\nAll I want to do is sit back & relax for a lit...\nneutral\n-1\n0\n\n\n455\n754ebd84b4\nhttp://twitpic.com/67qv3 - Me at Forever 21 E...\nMe at Forever 21 Ethan couldn`t be there\nnegative\n0\n-1\n\n\n1077\n3d5c1ed21b\nUp is out? I didn`t get the memo It looks ...\no It looks amazi\npositive\n0\n1\n\n\n11170\n45b75eb618\nsunniest week for ages....and exams\nsunniest week for ages....and exams\nneutral\n1\n0\n\n\n16411\n7d1e81e0b9\nI know we need it but I`m not a fan of daily ...\nenjoy\npositive\n-1\n1\n\n\n26158\n7949730012\nwhy weren`t we invited?\nwhy weren`t we invited?\nneutral\n-1\n0\n\n\n12794\n112e8afc05\nr that squeeze bacon looks like poop\nr that squeeze bacon looks like poop\nneutral\n-1\n0\n\n\n22529\n9389b2e59d\nLOL. dood, i love you and miss you.\ni love you and miss you.\nneutral\n1\n0\n\n\n\n\n\n\n\n\nsum( abs((df_mini['predicted_sentiment'] - df_mini[\"numerical_sentiment\"]) ) == 2 )\n\n2"
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html#ai-for-research-2023",
    "href": "tutorials/session_2/sentiment_analysis_correction.html#ai-for-research-2023",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html#the-dataset",
    "href": "tutorials/session_2/sentiment_analysis_correction.html#the-dataset",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "We use the News Sentiment Dataset from Kaggle.\n\ncd tutorials/session_2\n\n/files/tutorials/session_2\n\n\n\npwd\n\n'/files/tutorials/session_2'\n\n\n\nImport Dataset as a pandas dataframe\n\n\nimport pandas\ndf = pandas.read_csv(\"Tweets.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n0\ncb774db0d1\nI`d have responded, if I were going\nI`d have responded, if I were going\nneutral\n\n\n1\n549e992a42\nSooo SAD I will 🦈 miss you here in San Diego!!!\nSooo SAD\nnegative\n\n\n2\n088c60f138\nmy boss is bullying me...\nbullying me\nnegative\n\n\n3\n9642c003ef\nwhat interview! leave me alone\nleave me alone\nnegative\n\n\n4\n358bd9e861\nSons of ****, why couldn`t they put them on t...\nSons of ****,\nnegative\n\n\n...\n...\n...\n...\n...\n\n\n27476\n4eac33d1c0\nwish we could come see u on Denver husband l...\nd lost\nnegative\n\n\n27477\n4f4c4fc327\nI`ve wondered about rake to. The client has ...\n, don`t force\nnegative\n\n\n27478\nf67aae2310\nYay good for both of you. Enjoy the break - y...\nYay good for both of you.\npositive\n\n\n27479\ned167662a5\nBut it was worth it ****.\nBut it was worth it ****.\npositive\n\n\n27480\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\nAll this flirting going on - The ATG smiles. Y...\nneutral\n\n\n\n\n27481 rows × 4 columns\n\n\n\n\ndf.__class__\n\npandas.core.frame.DataFrame\n\n\n\n# indices refer to columns by default\ndf['text']\n\n0                      I`d have responded, if I were going\n1          Sooo SAD I will 🦈 miss you here in San Diego!!!\n2                                my boss is bullying me...\n3                           what interview! leave me alone\n4         Sons of ****, why couldn`t they put them on t...\n                               ...                        \n27476     wish we could come see u on Denver  husband l...\n27477     I`ve wondered about rake to.  The client has ...\n27478     Yay good for both of you. Enjoy the break - y...\n27479                           But it was worth it  ****.\n27480       All this flirting going on - The ATG smiles...\nName: text, Length: 27481, dtype: object\n\n\n\ndf.loc[2, 'text']\n\n'my boss is bullying me...'\n\n\n\n# check one entry:\ndf.loc[1200]\n\ntextID                                                  968964a722\ntext              hahahah of course  they have such a nasty dis...\nselected_text                       e such a nasty display picture\nsentiment                                                 negative\nName: 1200, dtype: object\n\n\n\n# keep the text from one entry\ndf.loc[1200]['text']\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\nDescribe Dataset (text and graphs)\n\n\ndf.describe()\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\ncount\n27481\n27480\n27480\n27481\n\n\nunique\n27481\n27480\n22463\n3\n\n\ntop\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\ngood\nneutral\n\n\nfreq\n1\n1\n199\n11118\n\n\n\n\n\n\n\n\n# information about the distrbution of sentiments\nsentiments = df['sentiment']\n\n\ncounts = sentiments.value_counts()\n\n\ncounts / sum(counts) * 100\n\nsentiment\nneutral     40.457043\npositive    31.228849\nnegative    28.314108\nName: count, dtype: float64\n\n\n\n# this is a series where a line is True only if df['text'] contains \"trump\"\nind = df['text'].str.contains(\"trump\", na=False)\nind\n\n0        False\n1        False\n2        False\n3        False\n4        False\n         ...  \n27476    False\n27477    False\n27478    False\n27479    False\n27480    False\nName: text, Length: 27481, dtype: bool\n\n\n\n# which tweets contain word \"trump\"\ndf[ind]\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n1589\n6c5505a37c\nEnjoy! Family trumps everything\nEnjoy! Family trumps everything\npositive\n\n\n6235\n234a562dd9\nLOL I love my MacBook too. Oh and my iMac. Ca...\nlove\npositive\n\n\n14005\n464eafe267\nHow to get a $40 trumpet book - get caught in ...\ncaught\nnegative\n\n\n14615\nfc16472bdf\nSick kid trumps advance planning. Bummer\nSick\nnegative\n\n\n22230\n2762b6624b\n_fan Been busy trumping your cheese omlette wi...\n_fan Been busy trumping your cheese omlette wi...\nneutral\n\n\n\n\n\n\n\n\n# how many tweets contain word \"trump\"\nsum(ind)\n\n5\n\n\n\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?\n\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_test_split?\n\n\nSignature:\ntrain_test_split(\n    *arrays,\n    test_size=None,\n    train_size=None,\n    random_state=None,\n    shuffle=True,\n    stratify=None,\n)\nDocstring:\nSplit arrays or matrices into random train and test subsets.\nQuick utility that wraps input validation,\n``next(ShuffleSplit().split(X, y))``, and application to input data\ninto a single call for splitting (and optionally subsampling) data into a\none-liner.\nRead more in the :ref:`User Guide &lt;cross_validation&gt;`.\nParameters\n----------\n*arrays : sequence of indexables with same length / shape[0]\n    Allowed inputs are lists, numpy arrays, scipy-sparse\n    matrices or pandas dataframes.\ntest_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the proportion\n    of the dataset to include in the test split. If int, represents the\n    absolute number of test samples. If None, the value is set to the\n    complement of the train size. If ``train_size`` is also None, it will\n    be set to 0.25.\ntrain_size : float or int, default=None\n    If float, should be between 0.0 and 1.0 and represent the\n    proportion of the dataset to include in the train split. If\n    int, represents the absolute number of train samples. If None,\n    the value is automatically set to the complement of the test size.\nrandom_state : int, RandomState instance or None, default=None\n    Controls the shuffling applied to the data before applying the split.\n    Pass an int for reproducible output across multiple function calls.\n    See :term:`Glossary &lt;random_state&gt;`.\nshuffle : bool, default=True\n    Whether or not to shuffle the data before splitting. If shuffle=False\n    then stratify must be None.\nstratify : array-like, default=None\n    If not None, data is split in a stratified fashion, using this as\n    the class labels.\n    Read more in the :ref:`User Guide &lt;stratification&gt;`.\nReturns\n-------\nsplitting : list, length=2 * len(arrays)\n    List containing train-test split of inputs.\n    .. versionadded:: 0.16\n        If the input is sparse, the output will be a\n        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n        input type.\nExamples\n--------\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.model_selection import train_test_split\n&gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)\n&gt;&gt;&gt; X\narray([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])\n&gt;&gt;&gt; list(y)\n[0, 1, 2, 3, 4]\n&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(\n...     X, y, test_size=0.33, random_state=42)\n...\n&gt;&gt;&gt; X_train\narray([[4, 5],\n       [0, 1],\n       [6, 7]])\n&gt;&gt;&gt; y_train\n[2, 0, 3]\n&gt;&gt;&gt; X_test\narray([[2, 3],\n       [8, 9]])\n&gt;&gt;&gt; y_test\n[1, 4]\n&gt;&gt;&gt; train_test_split(y, shuffle=False)\n[[0, 1, 2], [3, 4]]\nFile:      /opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py\nType:      function\n\n\n\n\nimport sklearn\ndf_, df_test  = sklearn.model_selection.train_test_split(df, test_size=0.1)\ndf_train, df_validation  = sklearn.model_selection.train_test_split(df_, test_size=0.1)\n\n\ndf\n\n(2749, 4)\n\n\n\ndf_train.shape\n\n(24732, 4)"
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html#text-mining",
    "href": "tutorials/session_2/sentiment_analysis_correction.html#text-mining",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "Extract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html#sentiment-analysis-using-gpt-completion",
    "href": "tutorials/session_2/sentiment_analysis_correction.html#sentiment-analysis-using-gpt-completion",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "Setup an openai key. Explore openai completion API.\n\n\nimport openai\n\n\n# make sure we have the right version. openai-python API has changed two weeks ago!\nfrom openai import version\nopenai.version.VERSION\n\n'1.3.5'\n\n\n\n# now we setup the API key\n# api_key = \"your_key\"\n# if the notebook is stored online we avoid setting the api key directly\nimport getpass\napi_key = getpass.getpass(prompt=\"Enter your OpenAI API key\")\n\nEnter your OpenAI API key ········\n\n\n\n# lookup on google \"openai completion python\"\n# from the github website, copy the example text\n\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=api_key,\n)\n\nresponse = client.completions.create(\n    prompt = \"Say this is a test\",\n    model=\"gpt-3.5-turbo-instruct\",\n)\n\n\n# examine the response object\n\n\n# there is only one response\n# recall that index numbering starts at 0 with Python\nresponse.choices[0].text\n\n'\\n\\n\"This is a test.\"'\n\n\n\nprint( response.choices[0].text )\n\n\n\n\"This is a test.\"\n\n\n\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\n\n\ntweet = df['text'][1200]\ntweet\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\n# use text concatenation\nprompt = \"Classify the following text as, positive, negative or neutral:\\n\\n\"\nprompt += \"Tweet: \"\nprompt += tweet\nprompt += \"\\n\\n\"\nprompt += \"Answer: \"\n\n\nprint(prompt)\n\nClassify the following text as, positive, negative or neutral:\n\nTweet:  hahahah of course  they have such a nasty display picture :`)\n\nAnswer: \n\n\n\nmodel = \"gpt-3.5-turbo-instruct\"\nresponse = client.completions.create(model=model, prompt=prompt, max_tokens=50)\n\ngenerated_text = response.choices[0].text\nprint(generated_text)\n\n Negative\n\n\n\n# use string interpolation:\nprompt = f\"\"\"Classify the following text as, positive, negative or neutral:\n\nTweet: {tweet}\nAnswer:\n\"\"\"\nprint(prompt)\n\nClassify the following text as, positive, negative or neutral:\n\nTweet:  hahahah of course  they have such a nasty display picture :`)\nAnswer:\n\n\n\n\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer.\n\n\ndef sentiment( tweet: str, model = \"gpt-3.5-turbo-instruct\"  )-&gt;int:\n    \"\"\"Compute the sentiment for the tweet.\n\n    tweet: string containing the tweet\n    model: string characterizing the openai model to use\n    \"\"\"\n    \n    # this is inside the function (indented)\n\n    # to indent a line Ctrl+] (right) or Ctrl+[\n    # on mac: Ctrl is Cmd\n\n    # build the prompt\n    prompt = f\"\"\"Classify the following text as, positive, negative or neutral:\n\n    Tweet: {tweet}\n    Answer:\n    \"\"\"\n\n    response = client.completions.create(model=model, prompt=prompt, max_tokens=50)\n    generated_text = response.choices[0].text\n    \n    std_gen_text = generated_text.lower().strip()\n\n    if std_gen_text == \"positive\":\n        return +1\n    elif std_gen_text==\"negative\": #elseif\n        return -1\n    elif std_gen_text==\"neutral\":\n        return 0\n    else:\n        print(\"Unrecognized output\")\n        return pandas.NA\n    \n# this is outside\n\n\nsentiment?\n\n\nSignature: sentiment(tweet: str, model='gpt-3.5-turbo-instruct') -&gt; int\nDocstring:\nCompute the sentiment for the tweet.\ntweet: string containing the tweet\nmodel: string characterizing the openai model to use\nFile:      /tmp/ipykernel_8903/666341508.py\nType:      function\n\n\n\n\nsentiment(\"prime number 29 is an incredible number\")\n\n'positive'\n\n\n\nresp = sentiment(\"prime number 29 is an incredible number\", model=\"davinci-002\" )\n\nException: Unrecognized output\n\n\n\nprint(resp)\n\n Positive: prime number 29 is an incredible number, because...\n     Neutral: prime number 29 is an incredible number, so...\n     Negative: prime number 29 is an incredible number, even though...\n\ntext-mining classification\n\nshare|im"
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis_correction.html#performance-shootout",
    "href": "tutorials/session_2/sentiment_analysis_correction.html#performance-shootout",
    "title": "Sentiment analysis (correction)",
    "section": "",
    "text": "Compare the various methods on the test set.\n\n\n# keep the 50 first elements:\ndf_mini = df_test.iloc[:50,:]\n\n# iloc is more adequate for integer indexing\n\n\nvalues = df_mini['text'].apply(sentiment)\n\n\n# compare accuracy against labels\n# add to df_mini\ndf_mini[\"predicted_sentiment\"] = values\n\n/tmp/ipykernel_8903/3713138410.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_mini[\"predicted_sentiment\"] = values\n\n\n\n# compute numerical values for the labels\ndef fun(val):\n    if val == \"positive\":\n        return +1\n    elif val==\"negative\": #elseif\n        return -1\n    elif val==\"neutral\":\n        return 0\ndf_mini['numerical_sentiment'] = df_mini['sentiment'].apply(fun)\n\n/tmp/ipykernel_8903/2987017452.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_mini['numerical_sentiment'] = df_mini['sentiment'].apply(fun)\n\n\n\ndf_mini\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\npredicted_sentiment\nnumerical_sentiment\n\n\n\n\n2747\n331b42de7d\n_Mitchell i`ve never been to the opera before....\ni`ve never been to the opera before...don`t th...\nneutral\n0\n0\n\n\n3885\n22ecd73521\nSo apparently i left my front door wide open b...\nLove\npositive\n0\n1\n\n\n20348\n531fe402e7\nJust started raining in earnest... guess golf ...\nJust started raining in earnest... guess golf ...\nneutral\n-1\n0\n\n\n3591\nbfdad27a0d\nLoved the comment on flashcads! I`m old schoo...\nLoved\npositive\n1\n1\n\n\n269\nde8c4c410d\nHell Yeah!\nHell Yeah!\nneutral\n1\n0\n\n\n18610\n43cc688b89\nmight be seeing my god mothers little boy in a...\ncute\npositive\n1\n1\n\n\n26279\n79c0162c77\nuseless tweet! LOL jk yay!!! You`re coming tm...\nuseless\nnegative\n0\n-1\n\n\n7443\ne944e54713\nJust got home, doing art all day.. i want to b...\nJust got home, doing art all day.. i want to b...\nneutral\n0\n0\n\n\n26757\neb6f587edb\nCan`t I just be a stay at home mom already\nCan`t I just be a stay at home mom already\nneutral\n0\n0\n\n\n12591\na590123cd9\nLoL!! I still would have got a look at his f...\nLoL!! I still would have got a look at his fa...\nneutral\n0\n0\n\n\n2931\nb1e3728694\nI hope when you`re calling this the shitshow...\ne when you`re calling this the shitshow you me...\nneutral\n0\n0\n\n\n841\n81adf60881\nI`ve read good things bout it. Just not feeli...\ngood\npositive\n0\n1\n\n\n15253\nee5b92dd36\nTWEEEEEET! good morning twitterland! going to ...\ngood mo\npositive\n0\n1\n\n\n13587\ne62c88c16c\nbusy exam week coming up! always look on the b...\nalways look on the bright side of life\npositive\n1\n1\n\n\n20076\n04795b9c4a\nthe classes with my students are over gonna m...\ngonna miss them...\nnegative\n1\n-1\n\n\n12305\n52618a6457\nI know. I have such guilt associated with pi...\nh guilt\nnegative\n-1\n-1\n\n\n23178\ne4e71486e3\nIf anyone needs help with images, let me know ...\ni will convo you\npositive\n0\n1\n\n\n18086\n4b0a1d060d\n..dat dude look crazy w/ dat hair on his face ...\n.these dudes are clowns\nnegative\n-1\n-1\n\n\n23410\ne4cb8a6252\nLast Heroes ep until Sept Sick & drugged for ...\nlacking\nnegative\n-1\n-1\n\n\n14581\na838d1a793\nam sitting in the library with eyes half close...\nam sitting in the library with eyes half close...\nneutral\n-1\n0\n\n\n17564\n588e531efe\nMoooorning! Fancy a coffee?\nMoooorning! Fancy a coffee?\nneutral\n0\n0\n\n\n14747\n344467bdaf\nay buti pa kayo!!!! uy thank you!!\ny thank you!!\npositive\n1\n1\n\n\n21466\n4f5cb8c34f\nAll I want to do is sit back & relax for a lit...\nAll I want to do is sit back & relax for a lit...\nneutral\n-1\n0\n\n\n8975\nbd042c2954\nI saw an all red Audi on the highway. I sped ...\nMy loss\nnegative\n-1\n-1\n\n\n19747\n29506f993d\nYeah, `Age of Aquarius` IS a pretty scary song\nscary\nnegative\n-1\n-1\n\n\n18970\n3bd10905ed\nUgh, i hate waiting in airports. I couldn`t fi...\ni hate\nnegative\n-1\n-1\n\n\n22914\n35bd63a569\ni take it you`re not a fan\ni take it you`re not a fan\nnegative\n-1\n-1\n\n\n455\n754ebd84b4\nhttp://twitpic.com/67qv3 - Me at Forever 21 E...\nMe at Forever 21 Ethan couldn`t be there\nnegative\n0\n-1\n\n\n1077\n3d5c1ed21b\nUp is out? I didn`t get the memo It looks ...\no It looks amazi\npositive\n0\n1\n\n\n11170\n45b75eb618\nsunniest week for ages....and exams\nsunniest week for ages....and exams\nneutral\n1\n0\n\n\n7434\ne2e0d8b057\nI have class tomorrow and tomorrow is Saturday...\nhate\nnegative\n-1\n-1\n\n\n6188\n5c5522b7b7\nAND, We have your fabulous interracial ****! ...\nAND, We have your fabulous interracial ****! ...\npositive\n1\n1\n\n\n405\nbd0fa6cebd\nthe 'no pants' idea could be the new attempt ...\nthe 'no pants' idea could be the new attempt w...\nneutral\n0\n0\n\n\n13386\n9d7b65be19\nHaha. I just won a $1000 bet. I settled for $1...\nwon\npositive\n1\n1\n\n\n9674\n0a87bc8dfd\nThe reason why I can`t find the latest Arena m...\nrecession.\nnegative\n-1\n-1\n\n\n16411\n7d1e81e0b9\nI know we need it but I`m not a fan of daily ...\nenjoy\npositive\n-1\n1\n\n\n15736\n58015c3988\nI know what you mean rain sucks...\nn sucks\nnegative\n-1\n-1\n\n\n26158\n7949730012\nwhy weren`t we invited?\nwhy weren`t we invited?\nneutral\n-1\n0\n\n\n1391\n743c5b85ca\nwatching Bones with Naty. Have made her a fan!...\nfan!\npositive\n1\n1\n\n\n4176\na27a31f5b8\n- well i greatly appreciate your comment. Th...\ngreatly appreciate\npositive\n1\n1\n\n\n26841\n8d8b6e78ae\nSome idiot just crashed into me on his bike. ...\ncrashed\nnegative\n-1\n-1\n\n\n15187\ne47b0e317c\ndamnit i didn`t but neither did you so win!\ndamnit i didn`t but neither did you so win!\nneutral\n0\n0\n\n\n20692\nb36d8acbd1\nYes, you should write an article.\nYes, you should write an article.\nneutral\n0\n0\n\n\n20657\n60c30e4bd8\nSometimes all it takes to solve our problems i...\nHope today is beautiful for you\npositive\n1\n1\n\n\n12794\n112e8afc05\nr that squeeze bacon looks like poop\nr that squeeze bacon looks like poop\nneutral\n-1\n0\n\n\n8793\n51f98e5b08\nup and at work im ina good mood\ngood\npositive\n1\n1\n\n\n4670\nb1e9db3db7\ngood day to all of you!! Another lindy day tod...\ngood\npositive\n1\n1\n\n\n14864\n5a0e0c34b8\nis super happy at the new interest rate. whoo...\nsuper happy\npositive\n1\n1\n\n\n22529\n9389b2e59d\nLOL. dood, i love you and miss you.\ni love you and miss you.\nneutral\n1\n0\n\n\n4227\ndfa0d5ca14\nI just dyededed my hair\nI just dyededed my hair\nneutral\n0\n0\n\n\n\n\n\n\n\n\n# number of true values:\nTV = sum(df_mini['predicted_sentiment']==df_mini[\"numerical_sentiment\"])\n\n\nFV = sum(df_mini['predicted_sentiment']!=df_mini[\"numerical_sentiment\"])\n\n\n# accuracy rrate:\n\nTV/(TV+FV)\n\n0.66\n\n\n\n# confusion matrix\n# ...\n\n\ndf_mini[df_mini['predicted_sentiment']!=df_mini[\"numerical_sentiment\"]]\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\npredicted_sentiment\nnumerical_sentiment\n\n\n\n\n3885\n22ecd73521\nSo apparently i left my front door wide open b...\nLove\npositive\n0\n1\n\n\n20348\n531fe402e7\nJust started raining in earnest... guess golf ...\nJust started raining in earnest... guess golf ...\nneutral\n-1\n0\n\n\n269\nde8c4c410d\nHell Yeah!\nHell Yeah!\nneutral\n1\n0\n\n\n26279\n79c0162c77\nuseless tweet! LOL jk yay!!! You`re coming tm...\nuseless\nnegative\n0\n-1\n\n\n841\n81adf60881\nI`ve read good things bout it. Just not feeli...\ngood\npositive\n0\n1\n\n\n15253\nee5b92dd36\nTWEEEEEET! good morning twitterland! going to ...\ngood mo\npositive\n0\n1\n\n\n20076\n04795b9c4a\nthe classes with my students are over gonna m...\ngonna miss them...\nnegative\n1\n-1\n\n\n23178\ne4e71486e3\nIf anyone needs help with images, let me know ...\ni will convo you\npositive\n0\n1\n\n\n14581\na838d1a793\nam sitting in the library with eyes half close...\nam sitting in the library with eyes half close...\nneutral\n-1\n0\n\n\n21466\n4f5cb8c34f\nAll I want to do is sit back & relax for a lit...\nAll I want to do is sit back & relax for a lit...\nneutral\n-1\n0\n\n\n455\n754ebd84b4\nhttp://twitpic.com/67qv3 - Me at Forever 21 E...\nMe at Forever 21 Ethan couldn`t be there\nnegative\n0\n-1\n\n\n1077\n3d5c1ed21b\nUp is out? I didn`t get the memo It looks ...\no It looks amazi\npositive\n0\n1\n\n\n11170\n45b75eb618\nsunniest week for ages....and exams\nsunniest week for ages....and exams\nneutral\n1\n0\n\n\n16411\n7d1e81e0b9\nI know we need it but I`m not a fan of daily ...\nenjoy\npositive\n-1\n1\n\n\n26158\n7949730012\nwhy weren`t we invited?\nwhy weren`t we invited?\nneutral\n-1\n0\n\n\n12794\n112e8afc05\nr that squeeze bacon looks like poop\nr that squeeze bacon looks like poop\nneutral\n-1\n0\n\n\n22529\n9389b2e59d\nLOL. dood, i love you and miss you.\ni love you and miss you.\nneutral\n1\n0\n\n\n\n\n\n\n\n\nsum( abs((df_mini['predicted_sentiment'] - df_mini[\"numerical_sentiment\"]) ) == 2 )\n\n2"
  },
  {
    "objectID": "session_3/open_ai_api.html",
    "href": "session_3/open_ai_api.html",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "api_key = \"\" # set the openAI api key\n\n\n\nThe openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"&lt;APIKEY&gt;\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:\n\n\n\n\n\nImport openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\n\n\nRedo same exercises as with the Rest API.\n\n\n\n\n\nWhat is GPT’s answer when you ask “What is your favourite color?”\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n(bonus) By providing more context, can you override ChatGPT’s default answer?\n\n\n\n\n\nLoad the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "session_3/open_ai_api.html#rest-api",
    "href": "session_3/open_ai_api.html#rest-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "The openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"&lt;APIKEY&gt;\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:"
  },
  {
    "objectID": "session_3/open_ai_api.html#python-api",
    "href": "session_3/open_ai_api.html#python-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Import openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\n\n\nRedo same exercises as with the Rest API."
  },
  {
    "objectID": "session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "href": "session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "What is GPT’s answer when you ask “What is your favourite color?”\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n(bonus) By providing more context, can you override ChatGPT’s default answer?"
  },
  {
    "objectID": "session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "href": "session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Load the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "session_3/plan.html",
    "href": "session_3/plan.html",
    "title": "AI for Research",
    "section": "",
    "text": "Last part about architecture of LLM\n\nencoder / decoder\nattention mechanism\n\nGood practices\n\nwhat went wrong?\n\nchange in library API\n\nAPIs\n\nFinish tutorial from session 2\n\ndescribe data\nrun sentiment analysis\nbonus?\n\nLarge Language Models in the Wild"
  },
  {
    "objectID": "slides/session_1_3/graphs/inference.html",
    "href": "slides/session_1_3/graphs/inference.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\ndef generate_dataset(μ1, μ2, α, β, σ, N=10):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    return pd.DataFrame({'x': xvec, 'y': yvec})\n\n\ndf = generate_dataset(0.0, 1.0, 0.1, 0.8, 0.1)\n\n\nplt.plot(df['x'], df['y'], 'o')\nplt.grid()\n\n\n\n\n\n\n\n\n\ndef plot_distribution(α, β, σ, N=100000, μ1=0.0, μ2=1.0):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    plt.plot(xvec, yvec, '.r', alpha=0.005)\n    plt.plot(xvec, α + β*xvec, color='black')\n\n# missing ridge line\n\n\nimport statsmodels\n\n\nμ1 = 0\nμ2 = 1.0\nα = 0.1\nβ = 0.8\nσ = 0.2\nN = 20\nK = 1000\n\n\nimport statsmodels.formula.api as smf\n\n\ndf = generate_dataset(μ1, μ2, α, β, σ, N=N)\n\n\nres = smf.ols(formula='y ~ x + 1', data=df).fit()\nparams = res.params\nαhat = params['Intercept']\nβhat = params['x']\nσhat = res.resid.std()\n\n\nres.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ny\nR-squared:\n0.692\n\n\nModel:\nOLS\nAdj. R-squared:\n0.675\n\n\nMethod:\nLeast Squares\nF-statistic:\n40.48\n\n\nDate:\nTue, 26 Jan 2021\nProb (F-statistic):\n5.41e-06\n\n\nTime:\n04:02:36\nLog-Likelihood:\n7.6662\n\n\nNo. Observations:\n20\nAIC:\n-11.33\n\n\nDf Residuals:\n18\nBIC:\n-9.341\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.1210\n0.077\n1.565\n0.135\n-0.041\n0.283\n\n\nx\n0.7941\n0.125\n6.362\n0.000\n0.532\n1.056\n\n\n\n\n\n\nOmnibus:\n1.410\nDurbin-Watson:\n1.507\n\n\nProb(Omnibus):\n0.494\nJarque-Bera (JB):\n0.890\n\n\nSkew:\n-0.081\nProb(JB):\n0.641\n\n\nKurtosis:\n1.979\nCond. No.\n4.20\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nres.predict(df['x'])\n\n0     0.326200\n1     0.211704\n2     0.798819\n3     0.603306\n4     0.573319\n5     0.823919\n6     0.740622\n7     0.503227\n8     0.292622\n9     0.489566\n10    0.138720\n11    0.355157\n12    0.594171\n13    0.883917\n14    0.266229\n15    0.827021\n16    0.912376\n17    0.163088\n18    0.684858\n19    0.732782\ndtype: float64\n\n\n\nfor i in [1,2,3]:\n    \n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {α:.2f} + {β:.2f} x + {σ:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n\n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    if i&gt;=3:\n        plt.plot(df['x'], res.predict(), label=f'$\\hat{{α}}={αhat:.2f}; \\hat{{β}}={βhat:.2f}$')\n        plt.legend(loc='lower right')\n    plt.title(\"Random Draw\")\n    plt.grid()\n    \n    plt.savefig(f\"regression_uncertainty_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scipy.stats\n\n\ndatasets = [generate_dataset(μ1, μ2, αhat, βhat, σhat, N=N) for i in range(K)]\nall_params = [smf.ols(formula='x ~ y + 1', data=df).fit() for df in datasets]\nαvec = np.array( [e.params['Intercept'] for e in all_params] )\nβvec = np.array( [e.params['y'] for e in all_params] )\n\n\ngkd = scipy.stats.kde.gaussian_kde(βvec)\n\n\nfor i in [1,2,3,4,5,6,7,8,9,10,100]:\n\n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {αhat:.2f} + {βhat:.2f} x + {σhat:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    \n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    df = datasets[i]\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    plt.title(\"Random Draw\")\n    plt.grid()\n\n    plt.subplot(313)\n    if i==3:\n        plt.plot(βvec[i], βvec[i]*0, 'o')\n    if i&gt;4:\n        plt.plot(βvec[3:i], βvec[3:i]*0, 'o')\n    if i&gt;10:\n        xx = np.linspace(0.2, 1.4, 10000)\n        plt.plot( βvec, gkd.pdf(βvec), '.')\n    plt.title(\"Distribution of β\")\n    plt.xlim(0.2, 1.4)\n    plt.ylim(-0.1, 4)\n    plt.grid()\n\n    plt.tight_layout()\n\n    plt.savefig(f\"random_estimates_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot( βvec, βvec*0, 'o')"
  },
  {
    "objectID": "slides/session_1_2/graphs/inference.html",
    "href": "slides/session_1_2/graphs/inference.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\ndef generate_dataset(μ1, μ2, α, β, σ, N=10):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    return pd.DataFrame({'x': xvec, 'y': yvec})\n\n\ndf = generate_dataset(0.0, 1.0, 0.1, 0.8, 0.1)\n\n\nplt.plot(df['x'], df['y'], 'o')\nplt.grid()\n\n\n\n\n\n\n\n\n\ndef plot_distribution(α, β, σ, N=100000, μ1=0.0, μ2=1.0):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    plt.plot(xvec, yvec, '.r', alpha=0.005)\n    plt.plot(xvec, α + β*xvec, color='black')\n\n# missing ridge line\n\n\nimport statsmodels\n\n\nμ1 = 0\nμ2 = 1.0\nα = 0.1\nβ = 0.8\nσ = 0.2\nN = 20\nK = 1000\n\n\nimport statsmodels.formula.api as smf\n\n\ndf = generate_dataset(μ1, μ2, α, β, σ, N=N)\n\n\nres = smf.ols(formula='y ~ x + 1', data=df).fit()\nparams = res.params\nαhat = params['Intercept']\nβhat = params['x']\nσhat = res.resid.std()\n\n\nres.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ny\nR-squared:\n0.692\n\n\nModel:\nOLS\nAdj. R-squared:\n0.675\n\n\nMethod:\nLeast Squares\nF-statistic:\n40.48\n\n\nDate:\nTue, 26 Jan 2021\nProb (F-statistic):\n5.41e-06\n\n\nTime:\n04:02:36\nLog-Likelihood:\n7.6662\n\n\nNo. Observations:\n20\nAIC:\n-11.33\n\n\nDf Residuals:\n18\nBIC:\n-9.341\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.1210\n0.077\n1.565\n0.135\n-0.041\n0.283\n\n\nx\n0.7941\n0.125\n6.362\n0.000\n0.532\n1.056\n\n\n\n\n\n\nOmnibus:\n1.410\nDurbin-Watson:\n1.507\n\n\nProb(Omnibus):\n0.494\nJarque-Bera (JB):\n0.890\n\n\nSkew:\n-0.081\nProb(JB):\n0.641\n\n\nKurtosis:\n1.979\nCond. No.\n4.20\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nres.predict(df['x'])\n\n0     0.326200\n1     0.211704\n2     0.798819\n3     0.603306\n4     0.573319\n5     0.823919\n6     0.740622\n7     0.503227\n8     0.292622\n9     0.489566\n10    0.138720\n11    0.355157\n12    0.594171\n13    0.883917\n14    0.266229\n15    0.827021\n16    0.912376\n17    0.163088\n18    0.684858\n19    0.732782\ndtype: float64\n\n\n\nfor i in [1,2,3]:\n    \n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {α:.2f} + {β:.2f} x + {σ:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n\n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    if i&gt;=3:\n        plt.plot(df['x'], res.predict(), label=f'$\\hat{{α}}={αhat:.2f}; \\hat{{β}}={βhat:.2f}$')\n        plt.legend(loc='lower right')\n    plt.title(\"Random Draw\")\n    plt.grid()\n    \n    plt.savefig(f\"regression_uncertainty_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scipy.stats\n\n\ndatasets = [generate_dataset(μ1, μ2, αhat, βhat, σhat, N=N) for i in range(K)]\nall_params = [smf.ols(formula='x ~ y + 1', data=df).fit() for df in datasets]\nαvec = np.array( [e.params['Intercept'] for e in all_params] )\nβvec = np.array( [e.params['y'] for e in all_params] )\n\n\ngkd = scipy.stats.kde.gaussian_kde(βvec)\n\n\nfor i in [1,2,3,4,5,6,7,8,9,10,100]:\n\n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {αhat:.2f} + {βhat:.2f} x + {σhat:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    \n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    df = datasets[i]\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    plt.title(\"Random Draw\")\n    plt.grid()\n\n    plt.subplot(313)\n    if i==3:\n        plt.plot(βvec[i], βvec[i]*0, 'o')\n    if i&gt;4:\n        plt.plot(βvec[3:i], βvec[3:i]*0, 'o')\n    if i&gt;10:\n        xx = np.linspace(0.2, 1.4, 10000)\n        plt.plot( βvec, gkd.pdf(βvec), '.')\n    plt.title(\"Distribution of β\")\n    plt.xlim(0.2, 1.4)\n    plt.ylim(-0.1, 4)\n    plt.grid()\n\n    plt.tight_layout()\n\n    plt.savefig(f\"random_estimates_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot( βvec, βvec*0, 'o')"
  },
  {
    "objectID": "slides/session_3/open_ai_api.html",
    "href": "slides/session_3/open_ai_api.html",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "api_key = \"\" # set the openAI api key\n\n\n\nThe openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"&lt;APIKEY&gt;\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:\n\n\n\n\n\nImport openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\n\n\nRedo same exercises as with the Rest API.\n\n\n\n\n\nWhat is GPT’s answer when you ask “What is your favourite color?”\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n(bonus) By providing more context, can you override ChatGPT’s default answer?\n\n\n\n\n\nLoad the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "slides/session_3/open_ai_api.html#rest-api",
    "href": "slides/session_3/open_ai_api.html#rest-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "The openAI services are accessible through a REST API. REST is a protocol designed to call services (through) http requests (POST and GET requests).\n\n# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\nimport requests\nkey = \"&lt;APIKEY&gt;\"\nurl = \" https://api.openai.com/v1/completions\"\nheaders = {\"Authorization\": f\"Bearer {key}\"}\ndata = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\nrequests.post(url, headers=headers, json=data).json()\n\n\nUse the requests library to download the list of available engines. Which ones can be used with the competions API.\n\n\n## Request call\n# the following call lists all available AI engines\n\n\nLocate the openAI API documentation. Find out how to complete the following sentence: Le coup passa si près que le chapeau\nUse the Chat api to complete the following (apocryphal) dialogue:\n\n\nLady Astor: If I were married to you, I would poison your tea\nChurchill:"
  },
  {
    "objectID": "slides/session_3/open_ai_api.html#python-api",
    "href": "slides/session_3/open_ai_api.html#python-api",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Import openai python library. Check that version number is &gt;=1.\n\n\n# import openai python library\n\n\nRedo same exercises as with the Rest API."
  },
  {
    "objectID": "slides/session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "href": "slides/session_3/open_ai_api.html#what-is-gpts-favourite-color",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "What is GPT’s answer when you ask “What is your favourite color?”\nCompare the responses: for the different engines, the different types of calls. What is the difference between instruct/chat/completion calls?\n(bonus) By providing more context, can you override ChatGPT’s default answer?"
  },
  {
    "objectID": "slides/session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "href": "slides/session_3/open_ai_api.html#fine-tuning-the-sentiment-analysis",
    "title": "Using OpenAI GPT",
    "section": "",
    "text": "Load the database from session 1. Split it into a training dataset (10%) and a test dataset (90%).\nWrite/copy a function to perform a sentiment analysis using GPT.\nFine tune a GPT model to do sentiment analysis using 10 random observations from the training dataset.\nCompare accuracy of the two versions on a randomly drawn test set with 100 observations."
  },
  {
    "objectID": "slides/session_3/plan.html",
    "href": "slides/session_3/plan.html",
    "title": "AI for Research",
    "section": "",
    "text": "Last part about architecture of LLM\n\nencoder / decoder\nattention mechanism\n\nGood practices\n\nwhat went wrong?\n\nchange in library API\n\nAPIs\n\nFinish tutorial from session 2\n\ndescribe data\nrun sentiment analysis\nbonus?\n\nLarge Language Models in the Wild"
  },
  {
    "objectID": "slides/session_2/index.html#do-you-like-poetry",
    "href": "slides/session_2/index.html#do-you-like-poetry",
    "title": "…to Large Language Models",
    "section": "Do you like poetry?",
    "text": "Do you like poetry?\n\n\nA rose is a rose is a rose\n\n\n\nGertrude Stein\n\n\n\nBrexit means Brexit means Brexit\n\n\n\nJohn Crace\n\n\n\nElementary my dear Watson\n\n\n\nP.G. Woodehouse"
  },
  {
    "objectID": "slides/session_2/index.html#section",
    "href": "slides/session_2/index.html#section",
    "title": "…to Large Language Models",
    "section": "",
    "text": "There is an easy way for the government to end the strike without withdrawing the pension reform,"
  },
  {
    "objectID": "slides/session_2/index.html#complete-text",
    "href": "slides/session_2/index.html#complete-text",
    "title": "…to Large Language Models",
    "section": "Complete Text",
    "text": "Complete Text\nGenerative language models perform text completion\nThey generate plausible1 text following a prompt.\nThe type of answer, will depend on the kind of prompt.\nhere, plausible, means that it is more likely to be a correct text written by a human, rather than otherwise"
  },
  {
    "objectID": "slides/session_2/index.html#gpt-playground",
    "href": "slides/session_2/index.html#gpt-playground",
    "title": "…to Large Language Models",
    "section": "GPT Playground",
    "text": "GPT Playground\nTo use GPT-3 profficiently, you have to experiment with the prompt.\n\ntry the Playground mode\n\nIt is the same as learning how to do google queries\n\naltavista: +noir +film -\"pinot noir\"\nnowadays: ???\n\n“Prompting” is becoming a discipline in itself… (or is it?)"
  },
  {
    "objectID": "slides/session_2/index.html#some-examples",
    "href": "slides/session_2/index.html#some-examples",
    "title": "…to Large Language Models",
    "section": "Some Examples",
    "text": "Some Examples\nBy providing enough context, it is possible to perform amazing tasks\nLook at the demos"
  },
  {
    "objectID": "slides/session_2/index.html#language-models-and-cryptography",
    "href": "slides/session_2/index.html#language-models-and-cryptography",
    "title": "…to Large Language Models",
    "section": "Language Models and Cryptography",
    "text": "Language Models and Cryptography\n\nThe Caesar code"
  },
  {
    "objectID": "slides/session_2/index.html#section-1",
    "href": "slides/session_2/index.html#section-1",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Zodiac 408 Cipher"
  },
  {
    "objectID": "slides/session_2/index.html#section-2",
    "href": "slides/session_2/index.html#section-2",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Zodiac 408 Cipher\n\n\n\n\n\n\n\nKey for Zodiac 408\n\n\n\n\n\n\nFigure 1: Solved in a week by Bettye and Donald Harden using frequency tables."
  },
  {
    "objectID": "slides/session_2/index.html#section-3",
    "href": "slides/session_2/index.html#section-3",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Later in 2001, in a prison, somewhere in California\n\n\nSolved by Stanford’s Persi Diaconis and his students using Monte Carlo Markov Chains"
  },
  {
    "objectID": "slides/session_2/index.html#monte-carlo-markov-chains",
    "href": "slides/session_2/index.html#monte-carlo-markov-chains",
    "title": "…to Large Language Models",
    "section": "Monte Carlo Markov Chains",
    "text": "Monte Carlo Markov Chains\nTake a letter \\(x_n\\), what is the probability of the next letter being \\(x_{n+1}\\)?\n\\[\\pi_{X,Y} = P(x_{n+1}=Y, x_{n}=X)\\]\nfor \\(X=\\{a, b, .... , z\\} , Y=\\{a,b,c, ... z\\}\\)\nThe language model can be trained using dataset of english language.\nAnd used to determine whether a given cipher-key is consistent with english language.\nIt yields a very efficient algorithm to decode any caesar code (with very small sample)"
  },
  {
    "objectID": "slides/session_2/index.html#mcmc-to-generate-text",
    "href": "slides/session_2/index.html#mcmc-to-generate-text",
    "title": "…to Large Language Models",
    "section": "MCMC to generate text",
    "text": "MCMC to generate text\nMCMCs can also be used to generate text:\n\ntake initial prompt: I think therefore I\n\nlast letter is I\nmost plausible character afterwards is \nmost plausible character afterwards is I\n\nResult: I think therefore I I I I I I\n\nNot good but promising (🤷)"
  },
  {
    "objectID": "slides/session_2/index.html#mcmc-to-generate-text-1",
    "href": "slides/session_2/index.html#mcmc-to-generate-text-1",
    "title": "…to Large Language Models",
    "section": "MCMC to generate text",
    "text": "MCMC to generate text\nGoing further\n\naugment memory\n\nfore I&gt; ???\n\nchange basic unit (use phonems or words)\n\nAn example using MCMC\n\nusing words and 3 states He ha ‘s kill’d me Mother , Run away I pray you Oh this is Counter you false Danish Dogges ."
  },
  {
    "objectID": "slides/session_2/index.html#big-mcmc",
    "href": "slides/session_2/index.html#big-mcmc",
    "title": "…to Large Language Models",
    "section": "Big MCMC",
    "text": "Big MCMC\nCan we augment memory?\n\nif you want to compute the most frequent letter (among 26) after 50 letters, you need to take into account 5.6061847e+70 combinations !\n\nimpossible to store, let alone do the training\n\nbut some combinations are useless:\n\nwjai dfni\nDespite the constant negative press covfefe 🤔"
  },
  {
    "objectID": "slides/session_2/index.html#neural-networks",
    "href": "slides/session_2/index.html#neural-networks",
    "title": "…to Large Language Models",
    "section": "Neural Networks",
    "text": "Neural Networks\n\n\n\n\n\n\n\nNeural Network\n\n\n\n\n\nNeural networks make it possible to increase the state-space to represent\n\n\\[\\forall X, P(x_n=X| x_{n-1}, ..., x_{n-k}) = \\varphi^{NL}( x_{n-1}, ..., x_{n-k}; \\theta )\\]\nwith a smaller vector of parameters \\(\\theta\\)\n\nNeural netowrks reduce endogenously the dimensionality."
  },
  {
    "objectID": "slides/session_2/index.html#recurrent-neural-networks",
    "href": "slides/session_2/index.html#recurrent-neural-networks",
    "title": "…to Large Language Models",
    "section": "Recurrent Neural Networks",
    "text": "Recurrent Neural Networks\n\n\nIn 2015\n\n\n\n\n\nNeural Network reduce dimensionality of data discovering structure\nhidden state encodes meaning of the model so far"
  },
  {
    "objectID": "slides/session_2/index.html#long-short-term-memory",
    "href": "slides/session_2/index.html#long-short-term-memory",
    "title": "…to Large Language Models",
    "section": "Long Short Term Memory",
    "text": "Long Short Term Memory\n\n\n2000-&gt;2019 : Emergence of Long Short Term Memory models\n\nspeech recognition\nLSTM behind “Google Translate”, “Alexa”, …"
  },
  {
    "objectID": "slides/session_2/index.html#the-latest-transformer",
    "href": "slides/session_2/index.html#the-latest-transformer",
    "title": "…to Large Language Models",
    "section": "The Latest: Transformer",
    "text": "The Latest: Transformer\nA special kind of encode/decoder architecture.\n\n\nMost successful models since 2017\n\nPosition Encodings\n\nmodel is not sequential anymore\ntries to learn sequence\n\nAttention\n\nattention is all you need\n\nSelf-Attention\n\n\n\n\n\nExplanations here or here"
  },
  {
    "objectID": "slides/session_2/index.html#the-rise-of-transformers",
    "href": "slides/session_2/index.html#the-rise-of-transformers",
    "title": "…to Large Language Models",
    "section": "The Rise of transformers",
    "text": "The Rise of transformers\nA special kind of encoder/decoder architecture.\n\n\nMost successful models since 2017\n\nPosition Encodings\n\nmodel is not sequential anymore\ntries to learn sequence\n\nAttention\n\nattention is all you need\n\nSelf-Attention\n\n\n\n\n\nExplanations here or here"
  },
  {
    "objectID": "slides/session_2/index.html#encoders-decoders-12",
    "href": "slides/session_2/index.html#encoders-decoders-12",
    "title": "…to Large Language Models",
    "section": "Encoders / Decoders (1/2)",
    "text": "Encoders / Decoders (1/2)\nTake some data \\((x_n)\\in R^x\\).\nConsider two functions:\n\nan encoder \\[\\varphi^E(x; \\theta^E) = h \\in \\mathbb{R^h}\\]\na decoder: \\[\\varphi^D(h; \\theta^D) = x' \\in \\mathbb{R^x}\\]\n\nWhat could possibly the value of training the coefficients with:\n\\[\\min_{\\theta^E, \\theta^D}  \\left( \\varphi^D( \\varphi^E(x_n; \\theta^E), \\theta^D) - x_n\\right)^2\\]?\ni.e. train the nets \\(\\varphi^D\\) and \\(\\varphi^E\\) to predict the “data from the data”? (it is called autoencoding)"
  },
  {
    "objectID": "slides/session_2/index.html#encoders-decoders-22",
    "href": "slides/session_2/index.html#encoders-decoders-22",
    "title": "…to Large Language Models",
    "section": "Encoders / Decoders (2/2)",
    "text": "Encoders / Decoders (2/2)\nThe relation \\(\\varphi^D( \\varphi^E(x_n; \\theta^E), \\theta^D) ~ x_n\\) can be rewritten as\n\\[x_n \\xrightarrow{\\varphi^E(; \\theta^E)} h \\xrightarrow{\\varphi^D(; \\theta^D)} x_n \\]\nWhen that relation is (mostly) satisfied and \\(\\mathbb{R}^h &lt;&lt; \\mathbb{R}^x\\), \\(h\\) can be viewed as a lower dimension representation of \\(x\\). It encodes the information as a lower dimension vector \\(h\\) and is called learned embeddings.\n\ninstead of \\(\\underbrace{x_n}_{\\text{prompt}} \\rightarrow \\underbrace{y_n}_{\\text{text completion}}\\)\none can learn \\(\\underbrace{h_n}_{\\text{prompt (low dim)}} \\xrightarrow{\\varphi^C( ; \\theta^C)} \\underbrace{h_n^c}_{\\text{text completion (low dim)}}\\)\n\nit is easier to learn\n\nand perform the original task as \\[\\underbrace{x_n}_{\\text{prompt}} \\xrightarrow{\\varphi^E}  h_n \\xrightarrow{\\varphi^C} h_n^C \\xrightarrow{\\varphi^D} \\underbrace{y_n}_{\\text{text completion}}\\]\n\nThis very powerful approach can be applied to combine encoders/decoders from different contexts (ex Dall-E)"
  },
  {
    "objectID": "slides/session_2/index.html#attention",
    "href": "slides/session_2/index.html#attention",
    "title": "…to Large Language Models",
    "section": "Attention",
    "text": "Attention\nMain flow with the recursive approach:\n\nthe context made to predict new words/embeddings puts a lower weight on further words/embeddings\nthis is related to the so-called vanishing gradient problem\n\n\n\n\nWith the attention mechanism, each predicted word/embedding is determined by all preceding words/embeddings, with different weights that are endogenous.\n\n\n\n\nAttention"
  },
  {
    "objectID": "slides/session_2/index.html#quick-summary",
    "href": "slides/session_2/index.html#quick-summary",
    "title": "…to Large Language Models",
    "section": "Quick summary",
    "text": "Quick summary\n\nLanguage models\n\nfrequency tables\nmonte carlo markov chains\ndeep learning -&gt; recurrent neural networks\nlong-short-term memory (&gt;2000)\ntransformers (&gt;2018)\n\nattention is all you need . . .\n\n\nSince 2010 main breakthrough came through the development of deep-learning techniques (software/hardware)\nRecently, models/algorithms have improved tremendously"
  },
  {
    "objectID": "slides/session_2/tutorial_2.html",
    "href": "slides/session_2/tutorial_2.html",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5.\n\n\n\nWe use the News Sentiment Dataset from Kaggle.\n\nImport Dataset as a pandas dataframe\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?\n\n\n\n\n\nExtract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix.\n\n\n\n\n\nSetup an openai key. Explore openai completion API.\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer.\n\n\n\n\n\nCompare the various methods on the test set."
  },
  {
    "objectID": "slides/session_2/tutorial_2.html#ai-for-research-2023",
    "href": "slides/session_2/tutorial_2.html#ai-for-research-2023",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5."
  },
  {
    "objectID": "slides/session_2/tutorial_2.html#the-dataset",
    "href": "slides/session_2/tutorial_2.html#the-dataset",
    "title": "Sentiment analysis",
    "section": "",
    "text": "We use the News Sentiment Dataset from Kaggle.\n\nImport Dataset as a pandas dataframe\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?"
  },
  {
    "objectID": "slides/session_2/tutorial_2.html#text-mining",
    "href": "slides/session_2/tutorial_2.html#text-mining",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Extract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix."
  },
  {
    "objectID": "slides/session_2/tutorial_2.html#sentiment-analysis-using-gpt-completion",
    "href": "slides/session_2/tutorial_2.html#sentiment-analysis-using-gpt-completion",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Setup an openai key. Explore openai completion API.\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer."
  },
  {
    "objectID": "slides/session_2/tutorial_2.html#performance-shootout",
    "href": "slides/session_2/tutorial_2.html#performance-shootout",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Compare the various methods on the test set."
  },
  {
    "objectID": "session_0/index.html#introduction",
    "href": "session_0/index.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nHave you heard of ChatGPT ?",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#questions",
    "href": "session_0/index.html#questions",
    "title": "Introduction",
    "section": "Questions?",
    "text": "Questions?\n\nWhat is the difference between GPT and ChatGPT?\nHow is it related to other AI fields\n\nlike machine learning? more precisely Natural Language Processing (aka NLP)?\nWhat are some other applications of generative AI?\n\nCan it be used for research? For which tasks?\nWhat should you pay attention to?\nHow will it evolve?",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#roadmap",
    "href": "session_0/index.html#roadmap",
    "title": "Introduction",
    "section": "Roadmap",
    "text": "Roadmap\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nNov 15, 2023\n\n\nFrom Text Analysis…\n\n\n\n\nNov 15, 2023\n\n\n…to Large Language Models\n\n\n\n\nNov 28, 2023\n\n\nLarge Language Models in the Wild\n\n\n\n\nDec 6, 2023\n\n\nBehavior of Large Language Models\n\n\n\n\nDec 13, 2023\n\n\nResearch Frontiers: What’s Next?\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#coursework",
    "href": "session_0/index.html#coursework",
    "title": "Introduction",
    "section": "Coursework",
    "text": "Coursework\n\nHomework\n\nread papers for next session (if any)\ndo the pushups on Nuvolos, send to me\n\nProjects\n\nreplicate a text analysis paper using gpt\npresent a study about biases of AI (last session)\n\n\n\nGrading?\n\nFully discretionary",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#practicalities",
    "href": "session_0/index.html#practicalities",
    "title": "Introduction",
    "section": "Practicalities",
    "text": "Practicalities\n\nNuvolos:\n\nonline computational platform with full python stack\nfull access during the course\nlogin with your (escp) gmail account\nsend the homework through nuvolos\n\nAfterwards:\n\neverything can be done on your laptop\nwe can set it up during the course\n\nOpenAI:\n\nyou will need a paid subscription",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#random-remarks",
    "href": "session_0/index.html#random-remarks",
    "title": "Introduction",
    "section": "Random Remarks",
    "text": "Random Remarks\n\nHow do Phd learn?\n\nby reading\nby doing\nby sitting/listening to a course\nby pestering asking their PhD adviser any professor\n\nWe are here to exchange\n\nyou have a cool/useful application of AI?\n\nshow and share\n\nspecific research ideas you would like to discuss?\nspeak up",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#why-should-you-learn-programming",
    "href": "session_0/index.html#why-should-you-learn-programming",
    "title": "Introduction",
    "section": "Why Should you learn programming ?",
    "text": "Why Should you learn programming ?\n\n\nResearchers (econometricians or data scientists) spend 80% of their time writing code.\nPresentation (plots, interactive apps) is key and relies on\n\n… programming\n\nInteraction with code becomes unavoidable in business environment\n\nfixing the website\nquerying the database\n…\n\nWorth investing a bit of time to learn it\n\nyou can easily become an expert\n\nPlus it’s fun",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_0/index.html#programming-resources",
    "href": "session_0/index.html#programming-resources",
    "title": "Introduction",
    "section": "Programming resources",
    "text": "Programming resources\nPlenty of online resources to learn python/econometrics/machine learning\n\nlearnpython sponsored by datacamp\nPython Data Science Handbook: by Jake Van der Plas, very complete. Online free version.\nIntroduction to Econometrics with R, in R but very clear (beginner and advanced versions)\n\n\n\nQuantecon: free online lectures to learn python programming and (advanced) economics\n\nnow with a section on datascience\nit is excellent!\nwe will use some of it today",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "session_2/tutorial_2.html",
    "href": "session_2/tutorial_2.html",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5.\n\n\n\nWe use the News Sentiment Dataset from Kaggle.\n\nImport Dataset as a pandas dataframe\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?\n\n\n\n\n\nExtract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix.\n\n\n\n\n\nSetup an openai key. Explore openai completion API.\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer.\n\n\n\n\n\nCompare the various methods on the test set."
  },
  {
    "objectID": "session_2/tutorial_2.html#ai-for-research-2023",
    "href": "session_2/tutorial_2.html#ai-for-research-2023",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5."
  },
  {
    "objectID": "session_2/tutorial_2.html#the-dataset",
    "href": "session_2/tutorial_2.html#the-dataset",
    "title": "Sentiment analysis",
    "section": "",
    "text": "We use the News Sentiment Dataset from Kaggle.\n\nImport Dataset as a pandas dataframe\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?"
  },
  {
    "objectID": "session_2/tutorial_2.html#text-mining",
    "href": "session_2/tutorial_2.html#text-mining",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Extract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix."
  },
  {
    "objectID": "session_2/tutorial_2.html#sentiment-analysis-using-gpt-completion",
    "href": "session_2/tutorial_2.html#sentiment-analysis-using-gpt-completion",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Setup an openai key. Explore openai completion API.\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer."
  },
  {
    "objectID": "session_2/tutorial_2.html#performance-shootout",
    "href": "session_2/tutorial_2.html#performance-shootout",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Compare the various methods on the test set."
  },
  {
    "objectID": "session_2/index.html#do-you-like-poetry",
    "href": "session_2/index.html#do-you-like-poetry",
    "title": "…to Large Language Models",
    "section": "Do you like poetry?",
    "text": "Do you like poetry?\n\n\nA rose is a rose is a rose\n\n\n\nGertrude Stein\n\n\n\nBrexit means Brexit means Brexit\n\n\n\nJohn Crace\n\n\n\nElementary my dear Watson\n\n\n\nP.G. Woodehouse",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#section",
    "href": "session_2/index.html#section",
    "title": "…to Large Language Models",
    "section": "",
    "text": "There is an easy way for the government to end the strike without withdrawing the pension reform,",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#complete-text",
    "href": "session_2/index.html#complete-text",
    "title": "…to Large Language Models",
    "section": "Complete Text",
    "text": "Complete Text\nGenerative language models perform text completion\nThey generate plausible1 text following a prompt.\nThe type of answer, will depend on the kind of prompt.\nhere, plausible, means that it is more likely to be a correct text written by a human, rather than otherwise",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#gpt-playground",
    "href": "session_2/index.html#gpt-playground",
    "title": "…to Large Language Models",
    "section": "GPT Playground",
    "text": "GPT Playground\nTo use GPT-3 profficiently, you have to experiment with the prompt.\n\ntry the Playground mode\n\nIt is the same as learning how to do google queries\n\naltavista: +noir +film -\"pinot noir\"\nnowadays: ???\n\n“Prompting” is becoming a discipline in itself… (or is it?)",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#some-examples",
    "href": "session_2/index.html#some-examples",
    "title": "…to Large Language Models",
    "section": "Some Examples",
    "text": "Some Examples\nBy providing enough context, it is possible to perform amazing tasks\nLook at the demos",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#language-models-and-cryptography",
    "href": "session_2/index.html#language-models-and-cryptography",
    "title": "…to Large Language Models",
    "section": "Language Models and Cryptography",
    "text": "Language Models and Cryptography\n\nThe Caesar code",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#section-1",
    "href": "session_2/index.html#section-1",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Zodiac 408 Cipher",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#section-2",
    "href": "session_2/index.html#section-2",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Zodiac 408 Cipher\n\n\n\n\n\n\n\nKey for Zodiac 408\n\n\n\n\n\n\nFigure 1: Solved in a week by Bettye and Donald Harden using frequency tables.",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#section-3",
    "href": "session_2/index.html#section-3",
    "title": "…to Large Language Models",
    "section": "",
    "text": "Later in 2001, in a prison, somewhere in California\n\n\nSolved by Stanford’s Persi Diaconis and his students using Monte Carlo Markov Chains",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#monte-carlo-markov-chains",
    "href": "session_2/index.html#monte-carlo-markov-chains",
    "title": "…to Large Language Models",
    "section": "Monte Carlo Markov Chains",
    "text": "Monte Carlo Markov Chains\nTake a letter \\(x_n\\), what is the probability of the next letter being \\(x_{n+1}\\)?\n\\[\\pi_{X,Y} = P(x_{n+1}=Y, x_{n}=X)\\]\nfor \\(X=\\{a, b, .... , z\\} , Y=\\{a,b,c, ... z\\}\\)\nThe language model can be trained using dataset of english language.\nAnd used to determine whether a given cipher-key is consistent with english language.\nIt yields a very efficient algorithm to decode any caesar code (with very small sample)",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#mcmc-to-generate-text",
    "href": "session_2/index.html#mcmc-to-generate-text",
    "title": "…to Large Language Models",
    "section": "MCMC to generate text",
    "text": "MCMC to generate text\nMCMCs can also be used to generate text:\n\ntake initial prompt: I think therefore I\n\nlast letter is I\nmost plausible character afterwards is \nmost plausible character afterwards is I\n\nResult: I think therefore I I I I I I\n\nNot good but promising (🤷)",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#mcmc-to-generate-text-1",
    "href": "session_2/index.html#mcmc-to-generate-text-1",
    "title": "…to Large Language Models",
    "section": "MCMC to generate text",
    "text": "MCMC to generate text\nGoing further\n\naugment memory\n\nfore I&gt; ???\n\nchange basic unit (use phonems or words)\n\nAn example using MCMC\n\nusing words and 3 states He ha ‘s kill’d me Mother , Run away I pray you Oh this is Counter you false Danish Dogges .",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#big-mcmc",
    "href": "session_2/index.html#big-mcmc",
    "title": "…to Large Language Models",
    "section": "Big MCMC",
    "text": "Big MCMC\nCan we augment memory?\n\nif you want to compute the most frequent letter (among 26) after 50 letters, you need to take into account 5.6061847e+70 combinations !\n\nimpossible to store, let alone do the training\n\nbut some combinations are useless:\n\nwjai dfni\nDespite the constant negative press covfefe 🤔",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#neural-networks",
    "href": "session_2/index.html#neural-networks",
    "title": "…to Large Language Models",
    "section": "Neural Networks",
    "text": "Neural Networks\n\n\n\n\n\n\n\nNeural Network\n\n\n\n\n\nNeural networks make it possible to increase the state-space to represent\n\n\\[\\forall X, P(x_n=X| x_{n-1}, ..., x_{n-k}) = \\varphi^{NL}( x_{n-1}, ..., x_{n-k}; \\theta )\\]\nwith a smaller vector of parameters \\(\\theta\\)\n\nNeural netowrks reduce endogenously the dimensionality.",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#recurrent-neural-networks",
    "href": "session_2/index.html#recurrent-neural-networks",
    "title": "…to Large Language Models",
    "section": "Recurrent Neural Networks",
    "text": "Recurrent Neural Networks\n\n\nIn 2015\n\n\n\n\n\nNeural Network reduce dimensionality of data discovering structure\nhidden state encodes meaning of the model so far",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#long-short-term-memory",
    "href": "session_2/index.html#long-short-term-memory",
    "title": "…to Large Language Models",
    "section": "Long Short Term Memory",
    "text": "Long Short Term Memory\n\n\n2000-&gt;2019 : Emergence of Long Short Term Memory models\n\nspeech recognition\nLSTM behind “Google Translate”, “Alexa”, …",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#the-latest-transformer",
    "href": "session_2/index.html#the-latest-transformer",
    "title": "…to Large Language Models",
    "section": "The Latest: Transformer",
    "text": "The Latest: Transformer\nA special kind of encode/decoder architecture.\n\n\nMost successful models since 2017\n\nPosition Encodings\n\nmodel is not sequential anymore\ntries to learn sequence\n\nAttention\n\nattention is all you need\n\nSelf-Attention\n\n\n\n\n\nExplanations here or here",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#the-rise-of-transformers",
    "href": "session_2/index.html#the-rise-of-transformers",
    "title": "…to Large Language Models",
    "section": "The Rise of transformers",
    "text": "The Rise of transformers\nA special kind of encoder/decoder architecture.\n\n\nMost successful models since 2017\n\nPosition Encodings\n\nmodel is not sequential anymore\ntries to learn sequence\n\nAttention\n\nattention is all you need\n\nSelf-Attention\n\n\n\n\n\nExplanations here or here",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#encoders-decoders-12",
    "href": "session_2/index.html#encoders-decoders-12",
    "title": "…to Large Language Models",
    "section": "Encoders / Decoders (1/2)",
    "text": "Encoders / Decoders (1/2)\nTake some data \\((x_n)\\in R^x\\).\nConsider two functions:\n\nan encoder \\[\\varphi^E(x; \\theta^E) = h \\in \\mathbb{R^h}\\]\na decoder: \\[\\varphi^D(h; \\theta^D) = x' \\in \\mathbb{R^x}\\]\n\nWhat could possibly the value of training the coefficients with:\n\\[\\min_{\\theta^E, \\theta^D}  \\left( \\varphi^D( \\varphi^E(x_n; \\theta^E), \\theta^D) - x_n\\right)^2\\]?\ni.e. train the nets \\(\\varphi^D\\) and \\(\\varphi^E\\) to predict the “data from the data”? (it is called autoencoding)",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#encoders-decoders-22",
    "href": "session_2/index.html#encoders-decoders-22",
    "title": "…to Large Language Models",
    "section": "Encoders / Decoders (2/2)",
    "text": "Encoders / Decoders (2/2)\nThe relation \\(\\varphi^D( \\varphi^E(x_n; \\theta^E), \\theta^D) ~ x_n\\) can be rewritten as\n\\[x_n \\xrightarrow{\\varphi^E(; \\theta^E)} h \\xrightarrow{\\varphi^D(; \\theta^D)} x_n \\]\nWhen that relation is (mostly) satisfied and \\(\\mathbb{R}^h &lt;&lt; \\mathbb{R}^x\\), \\(h\\) can be viewed as a lower dimension representation of \\(x\\). It encodes the information as a lower dimension vector \\(h\\) and is called learned embeddings.\n\ninstead of \\(\\underbrace{x_n}_{\\text{prompt}} \\rightarrow \\underbrace{y_n}_{\\text{text completion}}\\)\none can learn \\(\\underbrace{h_n}_{\\text{prompt (low dim)}} \\xrightarrow{\\varphi^C( ; \\theta^C)} \\underbrace{h_n^c}_{\\text{text completion (low dim)}}\\)\n\nit is easier to learn\n\nand perform the original task as \\[\\underbrace{x_n}_{\\text{prompt}} \\xrightarrow{\\varphi^E}  h_n \\xrightarrow{\\varphi^C} h_n^C \\xrightarrow{\\varphi^D} \\underbrace{y_n}_{\\text{text completion}}\\]\n\nThis very powerful approach can be applied to combine encoders/decoders from different contexts (ex Dall-E)",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#attention",
    "href": "session_2/index.html#attention",
    "title": "…to Large Language Models",
    "section": "Attention",
    "text": "Attention\nMain flow with the recursive approach:\n\nthe context made to predict new words/embeddings puts a lower weight on further words/embeddings\nthis is related to the so-called vanishing gradient problem\n\n\n\n\nWith the attention mechanism, each predicted word/embedding is determined by all preceding words/embeddings, with different weights that are endogenous.\n\n\n\n\nAttention",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "session_2/index.html#quick-summary",
    "href": "session_2/index.html#quick-summary",
    "title": "…to Large Language Models",
    "section": "Quick summary",
    "text": "Quick summary\n\nLanguage models\n\nfrequency tables\nmonte carlo markov chains\ndeep learning -&gt; recurrent neural networks\nlong-short-term memory (&gt;2000)\ntransformers (&gt;2018)\n\nattention is all you need . . .\n\n\nSince 2010 main breakthrough came through the development of deep-learning techniques (software/hardware)\nRecently, models/algorithms have improved tremendously",
    "crumbs": [
      "…to Large Language Models"
    ]
  },
  {
    "objectID": "slides/session_0/index.html#introduction",
    "href": "slides/session_0/index.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nHave you heard of ChatGPT ?"
  },
  {
    "objectID": "slides/session_0/index.html#questions",
    "href": "slides/session_0/index.html#questions",
    "title": "Introduction",
    "section": "Questions?",
    "text": "Questions?\n\nWhat is the difference between GPT and ChatGPT?\nHow is it related to other AI fields\n\nlike machine learning? more precisely Natural Language Processing (aka NLP)?\nWhat are some other applications of generative AI?\n\nCan it be used for research? For which tasks?\nWhat should you pay attention to?\nHow will it evolve?"
  },
  {
    "objectID": "slides/session_0/index.html#roadmap",
    "href": "slides/session_0/index.html#roadmap",
    "title": "Introduction",
    "section": "Roadmap",
    "text": "Roadmap\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nNov 14, 2024\n\n\nFrom Text Analysis…\n\n\n\n\nNov 21, 2024\n\n\n…to Large Language Models\n\n\n\n\nNov 29, 2024\n\n\nLarge Language Models in the Wild\n\n\n\n\nDec 6, 2024\n\n\nBehavior of Large Language Models\n\n\n\n\nDec 13, 2024\n\n\nResearch Frontiers: What’s Next?\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/session_0/index.html#coursework",
    "href": "slides/session_0/index.html#coursework",
    "title": "Introduction",
    "section": "Coursework",
    "text": "Coursework\n\nHomework\n\nread papers for next session (if any)\ndo the pushups on Nuvolos, send to me\n\nProjects\n\nreplicate a text analysis paper using gpt\npresent a study about biases of AI (last session)\n\n\n\nGrading?\n\nFully discretionary"
  },
  {
    "objectID": "slides/session_0/index.html#practicalities",
    "href": "slides/session_0/index.html#practicalities",
    "title": "Introduction",
    "section": "Practicalities",
    "text": "Practicalities\n\nNuvolos:\n\nonline computational platform with full python stack\nfull access during the course\nlogin with your (escp) gmail account\nsend the homework through nuvolos\n\nLocal setup:\n\nConda / Python\nVSCode + Python extension\n\nOpenAI:\n\nyou will need a paid subscription"
  },
  {
    "objectID": "slides/session_0/index.html#random-remarks",
    "href": "slides/session_0/index.html#random-remarks",
    "title": "Introduction",
    "section": "Random Remarks",
    "text": "Random Remarks\n\nHow do Phd learn?\n\nby reading\nby doing\nby sitting/listening to a course\nby pestering asking their PhD adviser any professor\n\nWe are here to exchange\n\nyou have a cool/useful application of AI?\n\nshow and share\n\nspecific research ideas you would like to discuss?\nspeak up"
  },
  {
    "objectID": "slides/session_0/index.html#why-should-you-learn-programming",
    "href": "slides/session_0/index.html#why-should-you-learn-programming",
    "title": "Introduction",
    "section": "Why Should you learn programming ?",
    "text": "Why Should you learn programming ?\n\n\nResearchers (econometricians or data scientists) spend 80% of their time writing code.\nPresentation (plots, interactive apps) is key and relies on\n\n… programming\n\nInteraction with code becomes unavoidable in business environment\n\nfixing the website\nquerying the database\n…\n\nWorth investing a bit of time to learn it\n\nyou can easily become an expert\n\nPlus it’s fun"
  },
  {
    "objectID": "slides/session_0/index.html#programming-resources",
    "href": "slides/session_0/index.html#programming-resources",
    "title": "Introduction",
    "section": "Programming resources",
    "text": "Programming resources\nPlenty of online resources to learn python/econometrics/machine learning\n\nlearnpython sponsored by datacamp\nPython Data Science Handbook: by Jake Van der Plas, very complete. Online free version.\nIntroduction to Econometrics with R, in R but very clear (beginner and advanced versions)\n\n\n\nQuantecon: free online lectures to learn python programming and (advanced) economics\n\nnow with a section on datascience\nit is excellent!\nwe will use some of it today"
  },
  {
    "objectID": "slides/session_3/index.html#what-went-wrong-last-time",
    "href": "slides/session_3/index.html#what-went-wrong-last-time",
    "title": "Large Language Models in the Wild",
    "section": "What went wrong last time?",
    "text": "What went wrong last time?\n\nTwo bugs prevented flawless execution:\n\npandas datetime\nopenai completion\n\nIn both cases, the problem was a recent change in Application Programming Interface."
  },
  {
    "objectID": "slides/session_3/index.html#what-is-an-api",
    "href": "slides/session_3/index.html#what-is-an-api",
    "title": "Large Language Models in the Wild",
    "section": "What is an API?",
    "text": "What is an API?\nDefinition of an API\n\nhow you call a function from a library\nexample: python function pandas.to_datetime(df)\nexample2: REST calls, info from a website (like https://opentdb.com/api.php?amount=1&category=18)\n\nAPIs are:\n\ndocumented online\nspecific to a given version of the libary\n\nExample: where is the doc for the python API of OpenAI? for the REST API?"
  },
  {
    "objectID": "slides/session_3/index.html#advice-for-writing-code",
    "href": "slides/session_3/index.html#advice-for-writing-code",
    "title": "Large Language Models in the Wild",
    "section": "Advice for writing code",
    "text": "Advice for writing code\n\nCode Hygiene\n\ncomments: in python anything after\ndocstrings: specify the API of your own functions\nversion your code (git, git, git, …) 1\n\nReplicability\n\ndistribute and version data (example)\n\nas raw as possible\n\nspecify running environment\n\nlists the version of the system / all libraries\nconda: conda environment (environment.yml)\n\n\n(Bonus: provide a website with mybinder/shinypython )\n\nthis applies to all writing steps, especially latex documents"
  },
  {
    "objectID": "slides/session_3/index.html#gpt",
    "href": "slides/session_3/index.html#gpt",
    "title": "Large Language Models in the Wild",
    "section": "GPT",
    "text": "GPT\nLast week we described some elements of a transformer architecture.\n\nMost famous engine developped by OpenAI: Generative Pre-trained Transformer (aka GPT)\n\n\n\n\nGPT1 (1018)\n\n0.1 billion parameters\nhad to be fine-tuned to a particular problem\ntransfer learning (few shots learning)\n\nGPT2:\n\nmultitask\nno mandatory fine tuning\n\nGPT3:\n\nbigger: 175 billions parameters\n\nGPT4:\n\neven bigger: 1000 billions parameters ???\non your harddrive: 1Tb"
  },
  {
    "objectID": "slides/session_3/index.html#corpus",
    "href": "slides/session_3/index.html#corpus",
    "title": "Large Language Models in the Wild",
    "section": "Corpus",
    "text": "Corpus\n\n\nGPT-3 was trained1 on\n\nCommonCrawl\nWebText (proprietary db, with opensource alternative )\nWikipedia\nmany books\n\n⇒ 45 TB of data\n\ncured into a smaller datasets\n\n⇒ size ???\nDataset (mostly) ends in 2021.\n\n\n\n\nDetailed information about gpt-4 is harder to find."
  },
  {
    "objectID": "slides/session_3/index.html#how-is-the-model-trained",
    "href": "slides/session_3/index.html#how-is-the-model-trained",
    "title": "Large Language Models in the Wild",
    "section": "How is the model trained?",
    "text": "How is the model trained?\nSeveral concepts are relevant here:\n\n\nunsupervised learning\n\nautoencoding\n⇒ build a representation of the text\n\nfine tuning\nreinforcement learning"
  },
  {
    "objectID": "slides/session_3/index.html#what-is-learning",
    "href": "slides/session_3/index.html#what-is-learning",
    "title": "Large Language Models in the Wild",
    "section": "What is learning?",
    "text": "What is learning?\nA machine can perform a task \\(f(x; \\theta)\\) for some input \\(x\\) in a data-generating process \\(\\mathcal{X}\\) and and some parameters \\(\\theta\\).\nA typical learning task consists in optimizing a loss function (aka theoretical risk): \\[\\min _{\\theta} \\mathcal{L}(\\theta) = \\mathbb{E}_{\\theta} f(x; \\theta)\\]\nThe central learning method to minimize the objective is called stochastic gradient descent.\n\n\n\n.\n\n\n\n\nA common issue in ai is that of preference misspecification. (Cf Bostrom or link)"
  },
  {
    "objectID": "slides/session_3/index.html#learning-set",
    "href": "slides/session_3/index.html#learning-set",
    "title": "Large Language Models in the Wild",
    "section": "Learning Set",
    "text": "Learning Set\nIn practice one has access to a dataset \\((x_n) \\subset \\mathcal{X}\\) and minimizes the “empirical” risk function\n\\[L\\left( (x_n)_{n=1:N}, \\theta \\right) = \\frac{1}{N} \\sum_{n=1}^N f(x; \\theta)\\]\n\nRegular case: in usual cases, we assume that the dataset is generated by the true model (data-generating process)\nTwo important variants:\n\ntransfer learning:\n\ngoal is to use the model \\(\\mathcal{X}\\) but the training dataset is generated from another data-generating process \\(\\mathcal{Y}\\)\n\\(\\mathcal{Y}\\) can be a subset of \\(\\mathcal{X}\\) or (partially) disjoint\ndo you need some data from \\(\\mathcal{Y}\\) (few shots learning) or non at all (zero-shot learning)\n\nreinforcement learning\n\nthe learning algorithm can generate some data to improve learning"
  },
  {
    "objectID": "slides/session_3/index.html#transfer-learning",
    "href": "slides/session_3/index.html#transfer-learning",
    "title": "Large Language Models in the Wild",
    "section": "Transfer learning",
    "text": "Transfer learning\n\n\nGPT is inherently a transfer learning machine\n\nwhy?\n\nearlier versions (GPT-1, GPT-2) needed some examples before being able to perform any given task:\n\nfine-tuning: retrain some coefficients of the wole NN\n\nnew versions (&gt;GPT-3) can perform zero-shot tasks just by text completion\n\nfine-tuning can be emulated by prompting\nthere is still a fine-tuning API"
  },
  {
    "objectID": "slides/session_3/index.html#reinforcement-learning",
    "href": "slides/session_3/index.html#reinforcement-learning",
    "title": "Large Language Models in the Wild",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nA reinforcement learning algorithm can take actions which have two effects:\n\nprovide some reward to the algorithm\ngenerate (more) data to improve the quality of future actions\n\nExample:\n\nchoose a restaurant\ndrive a car\nfamous examples: breakout, hide and seek"
  },
  {
    "objectID": "slides/session_3/index.html#reinforcement-learning-for-gpt-4",
    "href": "slides/session_3/index.html#reinforcement-learning-for-gpt-4",
    "title": "Large Language Models in the Wild",
    "section": "Reinforcement Learning for GPT-4",
    "text": "Reinforcement Learning for GPT-4\nThe GPT-4 model has been fine-tuned with reinforcement learning. The language model was rewarded for providing the right kind of answer:\n\nthe feedback came from kenyan workers (sic!)\n\nTwo main variants on top of foundation model GPT Base:1\n\ninstructGPT\n\nalignment, non-toxicity, …\nfactual correctness\n\nchatGPT\n\nfollow a conversation\norganization of answer\nnot just a context on top of GPT\n\n\nComing next: assistants."
  },
  {
    "objectID": "slides/session_3/index.html#section",
    "href": "slides/session_3/index.html#section",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "There is information about how GPT-3 was trained (check technical paper or summary)"
  },
  {
    "objectID": "slides/session_3/index.html#the-different-variants-of-gpt",
    "href": "slides/session_3/index.html#the-different-variants-of-gpt",
    "title": "Large Language Models in the Wild",
    "section": "The different variants of GPT",
    "text": "The different variants of GPT\nWhich of the following model should you use?\nLots of options:\n\n\ntext-curie-001\ntext-davinci-003\ntext-babbage-001\ntext-ada-001\n…\n\n\nWhat are the differences between the various engines?\n\narchitecture / model size\ntraining set of foundation model (GPT Base)\ntype of fine-tuning (instruct/chat/code)\n\nIt is not clear whether GPT Base will still be accessible in the future or whether it will be fine-tuned for alignement or not.\n\nconsequences?"
  },
  {
    "objectID": "slides/session_3/index.html#section-1",
    "href": "slides/session_3/index.html#section-1",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "Checkout the awesome list!"
  },
  {
    "objectID": "slides/session_3/index.html#section-2",
    "href": "slides/session_3/index.html#section-2",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "What are the trends?\n\nmany foundation Models\n\nmove from opensource to closedsource\nbut: opensource is still very alive\n\nresearch to reduce size of models / training time\nmany more versions specialized (fine-tuned) to specific tasks"
  },
  {
    "objectID": "slides/session_3/index.html#one-common-misconception",
    "href": "slides/session_3/index.html#one-common-misconception",
    "title": "Large Language Models in the Wild",
    "section": "One common misconception",
    "text": "One common misconception\n\nLanguage models hallucinate facts…\n\ntherefore are definitely unreliable for research\n\nThere are possible workarounds\n\navoid tasks where hallucinations occur (like ask for paper citations)\nmore structure in the prompting (like “detail your reasoning”)\n\nAnd research being done…\n\non using fine-tuning for more correctness (e.g. instructGPT)\non developing mixed systems\n\n\nCheck out GPT Assistants and Scite"
  },
  {
    "objectID": "slides/session_3/index.html#how-much-should-we-trust-ai",
    "href": "slides/session_3/index.html#how-much-should-we-trust-ai",
    "title": "Large Language Models in the Wild",
    "section": "How much should we trust AI?",
    "text": "How much should we trust AI?\nAI safety and AI alignment is a very active field right now.\nFor economists, AI behaviour can be characterized in terms of biases:\n\nstatistical bias\npreference misspecification\n\nexplicit\nimplicit\n\nbehavioural biases\n\nFor now we don’t know much."
  },
  {
    "objectID": "slides/session_1_2/graphs/Untitled1.html",
    "href": "slides/session_1_2/graphs/Untitled1.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport statsmodels.api as sm\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\ncount\n45.000000\n45.000000\n45.000000\n\n\nmean\n41.866667\n52.555556\n47.688889\n\n\nstd\n24.435072\n29.760831\n31.510332\n\n\nmin\n7.000000\n7.000000\n3.000000\n\n\n25%\n21.000000\n26.000000\n16.000000\n\n\n50%\n42.000000\n45.000000\n41.000000\n\n\n75%\n64.000000\n84.000000\n81.000000\n\n\nmax\n81.000000\n100.000000\n97.000000\n\n\n\n\n\n\n\n\ndf.cov()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\nincome\n597.072727\n526.871212\n645.071212\n\n\neducation\n526.871212\n885.707071\n798.904040\n\n\nprestige\n645.071212\n798.904040\n992.901010\n\n\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(figsize=(8,6))\nplt.plot(df['education'],df['income'],'o')\nplt.grid()\nplt.xlabel(\"x (Education)\")\nplt.ylabel(\"y (Income)\")\nplt.savefig(\"data_description.png\")\n\n\n\n\n\n\n\n\n\nfor i in [1,2,3]:\n    xvec = np.linspace(10,100)\n\n    plt.figure(figsize=(12,8))\n    plt.plot(df['education'],df['income'],'o')\n\n    plt.plot(xvec, xvec * 0 + 50)\n    if i&gt;=2:\n        plt.plot(xvec, xvec )\n    if i&gt;=3:\n        plt.plot(xvec,  90- 0.6*xvec )\n\n    plt.grid()\n    plt.xlabel(\"x (Education)\")\n    plt.ylabel(\"y (Income)\")\n    plt.savefig(f\"which_line_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ipywidgets import interact\n\n\nimport matplotlib.patches as patches\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nplt.vlines(x, y+h, y, color='red')\n\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"error_0.png\")\n\n\n\n\n\n\n\n\n\nplt.vlines?\n\n\nSignature:\nplt.vlines(\n    x,\n    ymin,\n    ymax,\n    colors=None,\n    linestyles='solid',\n    label='',\n    *,\n    data=None,\n    **kwargs,\n)\nDocstring:\nPlot vertical lines.\nPlot vertical lines at each *x* from *ymin* to *ymax*.\nParameters\n----------\nx : float or array-like\n    x-indexes where to plot the lines.\nymin, ymax : float or array-like\n    Respective beginning and end of each line. If scalars are\n    provided, all lines will have same length.\ncolors : list of colors, default: :rc:`lines.color`\nlinestyles : {'solid', 'dashed', 'dashdot', 'dotted'}, optional\nlabel : str, default: ''\nReturns\n-------\n`~matplotlib.collections.LineCollection`\nOther Parameters\n----------------\n**kwargs : `~matplotlib.collections.LineCollection` properties.\nSee Also\n--------\nhlines : horizontal lines\naxvline: vertical line across the axes\nNotes\n-----\n.. note::\n    In addition to the above described arguments, this function can take\n    a *data* keyword argument. If such a *data* argument is given,\n    the following arguments can also be string ``s``, which is\n    interpreted as ``data[s]`` (unless this raises an exception):\n    *x*, *ymin*, *ymax*, *colors*.\n    Objects passed as **data** must support item access (``data[s]``) and\n    membership test (``s in data``).\nFile:      ~/.local/opt/miniconda/lib/python3.8/site-packages/matplotlib/pyplot.py\nType:      function\n\n\n\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nif p-y&gt;0:\n    # Create a Rectangle patch\n    rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n    ax.add_patch(rect)\n    \nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"errors_{1}.png\")\n\n\n\n\n\n\n\n\n\ndef L(a,b):\n    Δ = a + b*df['education'] - df['income']\n    return (Δ**2).sum()\n\n\na = 0.1\nb = 0.8\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_2.png\")\n\n\n\n\n\n\n\n\n\na = 90\nb = -0.6\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_3.png\")\n\n\n\n\n\n\n\n\n\nimport scipy.optimize\n\n\nscipy.optimize.minimize(lambda x: L(x[0], x[1]),np.array([0.5, 0.5]))\n\n      fun: 12480.970174488397\n hess_inv: array([[ 7.14169839e-09, -3.91281920e-09],\n       [-3.91281920e-09,  2.46663613e-09]])\n      jac: array([0.00024414, 0.00012207])\n  message: 'Desired error not necessarily achieved due to precision loss.'\n     nfev: 57\n      nit: 7\n     njev: 19\n   status: 2\n  success: False\n        x: array([10.60350224,  0.59485938])\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_4.png\")\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red', alpha=0.5)\n\nplt.plot(60, a + b*60, 'o', color='red',)\n\nprint(a+b*60)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"prediction.png\")\n\n45.4\n\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  (a + b*df['education'] - df['income'])\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(121)\nplt.plot(approx)\nplt.grid(False)\nplt.title(\"Residuals\")\n\n\nplt.subplot(122)\ndistplot(approx)\nplt.title(\"Distribution of residuals\")\nplt.grid()\n\nplt.savefig(\"residuals.png\")\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\n(a + b*df['education'] - df['income']).std()\n\n16.842782676352154\n\n\n\n\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f\n\n\nf(0.3)\n\nTypeError: _parse_args() missing 1 required positional argument: 'dfd'\n\n\n\nnp.rand\n\n\nK = 100\nxvec = np.linspace(0,1,K)\ne1 = np.random.randn(K)*0.1\nyvec = 0.1 + xvec*0.4 + e1\ne2 = np.random.randn(K)*0.05\nyvec2 = 0.1 + xvec*(xvec-1)/2 + e2\ne3 = np.random.randn(K)*xvec/2\nyvec3 = 0.1 + xvec + e3\n\nyvec4 = 0.1 + np.sin(xvec*6) + np.random.randn(K)*xvec/2\n\n\nfrom dolo.numeric.processes import VAR1\n\n\nsim = VAR1( ρ=0.8, Σ=0.001).simulate(N=1,T=100)\nyvec4 = 0.1 + xvec*0.4 + sim.ravel()\n\n\nplt.figure(figsize=(18,6))\nplt.subplot(241)\nplt.plot(xvec, yvec,'o')\nplt.plot(xvec, 0.1 + xvec*0.4 )\nplt.ylabel(\"Series\")\nplt.title(\"white noise\")\nplt.subplot(242)\nplt.plot(xvec, yvec2, 'o')\nplt.plot(xvec, yvec2*0)\nplt.title('nonlinear')\nplt.subplot(243)\nplt.plot(xvec, yvec3,'o')\nplt.plot(xvec, 0.1 + xvec)\nplt.title('heteroskedastic')\nplt.subplot(244)\nplt.plot(xvec, yvec4,'o')\nplt.plot(xvec, xvec*0.6)\n\nplt.title('correlated')\n\n\nplt.subplot(245)\nplt.plot(xvec, e1,'o')\nplt.ylabel(\"Residuals\")\nplt.subplot(246)\nplt.plot(xvec, yvec2-0.075, 'o')\n\nplt.subplot(247)\nplt.plot(xvec, e3,'o')\nplt.subplot(248)\nplt.plot(xvec, sim.ravel(),'o')\n\nplt.tight_layout()\n\nplt.savefig(\"residuals_circus.png\")"
  },
  {
    "objectID": "slides/session_1_2/index.html#regressions",
    "href": "slides/session_1_2/index.html#regressions",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Regressions",
    "text": "Regressions"
  },
  {
    "objectID": "slides/session_1_2/index.html#what-is-machine-learning-1",
    "href": "slides/session_1_2/index.html#what-is-machine-learning-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "What is Machine learning?",
    "text": "What is Machine learning?\nDefinition Candidates:\nArthur Samuel: Field of study that gives computers the ability to learn without being explicitly programmed\nTom Mitchell: A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."
  },
  {
    "objectID": "slides/session_1_2/index.html#what-about-artificial-intelligence",
    "href": "slides/session_1_2/index.html#what-about-artificial-intelligence",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "What about artificial intelligence ?",
    "text": "What about artificial intelligence ?\n\n\n\nAIs\n\nthink and learn\nmimmic human cognition"
  },
  {
    "objectID": "slides/session_1_2/index.html#econometrics-vs-machine-learning",
    "href": "slides/session_1_2/index.html#econometrics-vs-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Econometrics vs Machine Learning",
    "text": "Econometrics vs Machine Learning\n\nEconometrics is essentially a subfield of machine learning with a different jargon and a focus on:\n\nstudying properties and validity of results\n\ndata is scarce\ninference\n\nsingling out effects of specific explanatory variables\nestablishing causality\n\nMachine learning:\n\nstructure data\nmake predictions (interpolate data)"
  },
  {
    "objectID": "slides/session_1_2/index.html#data-types",
    "href": "slides/session_1_2/index.html#data-types",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Data types",
    "text": "Data types\n\nstructured:\n\ntabular\n\nlong\nwide\n\n\nunstructured:\n\nfiles\nnetworks\ntext, mails\nimages, sound"
  },
  {
    "objectID": "slides/session_1_2/index.html#tabular-data",
    "href": "slides/session_1_2/index.html#tabular-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Tabular Data",
    "text": "Tabular Data\n\ntabular data"
  },
  {
    "objectID": "slides/session_1_2/index.html#networks",
    "href": "slides/session_1_2/index.html#networks",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Networks",
    "text": "Networks\n\nBanking networks\nProduction network"
  },
  {
    "objectID": "slides/session_1_2/index.html#big-data-1",
    "href": "slides/session_1_2/index.html#big-data-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Big Data",
    "text": "Big Data\n\nBig data:\n\nwide data (K&gt;&gt;N)\nlong data (N&gt;&gt;K)\nheterogenous, unstructured data\n\nMight not even fit in memory\n\nout of core computations\nlearn from a subset of the data"
  },
  {
    "objectID": "slides/session_1_2/index.html#big-subfields-of-machine-learning",
    "href": "slides/session_1_2/index.html#big-subfields-of-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Big Subfields of Machine Learning",
    "text": "Big Subfields of Machine Learning\n\n\n\nTraditional classification\n\nsupervised (labelled data)\n\nregression: predict quantity\nclassification: predict index (categorical variable)\n\nunsupervised (no labels)\n\ndimension reduction\nclustering\n\nsemi-supervised / self-supervised\nreinforcement learning\n\nBazillions of different algorithms: https://scikit-learn.org/stable/user_guide.html\n\n\n\n\n\nregression:\n\nPredict: \\(y = f(x; \\theta)\\)\n\n\n\n\n\nsupervised: regression\n\n\n\n\n\nAge\n\n\nActivity\n\n\nSalary\n\n\n\n\n23\n\n\nExplorer\n\n\n1200\n\n\n\n\n40\n\n\nMortician\n\n\n2000\n\n\n\n\n45\n\n\nMortician\n\n\n2500\n\n\n\n\n33\n\n\nMovie Star\n\n\n3000\n\n\n\n\n35\n\n\nExplorer\n\n\n???\n\n\n\n\n\n\nsupervised: classification\n\nOutput is discrete\nRegular trick: \\(\\sigma(f(x; \\theta))\\) where \\(\\sigma(x)=\\frac{1}{1-e^{-x}}\\)\n\n\n\n\n\nclassification\n\n\n\n\n\nAge\n\n\nSalary\n\n\nActivity\n\n\n\n\n23\n\n\n1200\n\n\nExplorer\n\n\n\n\n40\n\n\n2000\n\n\nMortician\n\n\n\n\n45\n\n\n2500\n\n\nMortician\n\n\n\n\n33\n\n\n3000\n\n\nMovie Star\n\n\n\n\n35\n\n\n3000\n\n\n???\n\n\n\n\n\nunsupervised\n\norganize data without labels\n\ndimension reduction: describe data with less parameters\nclustering: sort data into “similar groups” (exemple)\n\n\n\n\n\nAge\n\n\nSalary\n\n\nActivity\n\n\n\n\n23\n\n\n1200\n\n\nExplorer\n\n\n\n\n40\n\n\n2000\n\n\nMortician\n\n\n\n\n45\n\n\n2500\n\n\nMortician\n\n\n\n\n33\n\n\n3000\n\n\nMovie Star\n\n\n\n\n35\n\n\n3000\n\n\nExplorer\n\n\n\n\n\nunsupervised: clustering\n\n\n\nkmeansclustering\n\n\n\n\nunsupervised: clustering\nWomen buying dresses during the year:"
  },
  {
    "objectID": "slides/session_1_2/index.html#difference-with-traditional-regression",
    "href": "slides/session_1_2/index.html#difference-with-traditional-regression",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\\[\\underbrace{y}_{\\text{explained variable}} = a \\underbrace{x}_{\\text{explanatory variable}} + b\\]"
  },
  {
    "objectID": "slides/session_1_2/index.html#difference-with-traditional-regression-1",
    "href": "slides/session_1_2/index.html#difference-with-traditional-regression-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\\[\\underbrace{y}_{\\text{labels}} = a \\underbrace{x}_{\\text{features}} + b\\]\n\n\n\n\n\n\n\n\nEconometrics\nMachine learning\n\n\n\n\nRegressand / independent variable / explanatory variable\nFeatures\n\n\nRegressor / dependent variable / explained variable\nLabels\n\n\nRegression\nModel Training"
  },
  {
    "objectID": "slides/session_1_2/index.html#difference-with-traditional-regression-2",
    "href": "slides/session_1_2/index.html#difference-with-traditional-regression-2",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\nBig data requires other means to process the data:\n\ndata is long: so many observations \\(x\\) doesn’t fit in the memory\n\nneed to use incremental training method to use only a subsample at a time\n\ndata is wide: so many features, the model is crudely overspecified\n\nneed to build dimension reduction into the objective\n\ndata is nonlinear:\n\nuse nonlinear model (and nonlinear training)\n\ndata is not a simple vector…\n\nsame as nonlinear"
  },
  {
    "objectID": "slides/session_1_2/index.html#long-data",
    "href": "slides/session_1_2/index.html#long-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Long data",
    "text": "Long data\nLong data is characterized by a high number of observations.\n\n\n\n\n\nModern society is gathering a lot of data.\n\nin doesn’t fit in the computer memory so we can’t run a basic regression\n\nIn some cases we would also like to update our model continuously:\n\nincremental regression\n\n\n\nWe need a way to fit a model on a subset of the data at a time."
  },
  {
    "objectID": "slides/session_1_2/index.html#long-data-1",
    "href": "slides/session_1_2/index.html#long-data-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Long data",
    "text": "Long data\n\n\n\nTraditional regression:\n\nfull sample \\(X,Y=(x_i,y_i)_{i=1:N}\\)\nOLS: \\(\\min_{a,b} \\sum_{i=1}^N (a x_i + b - y_i)^2\\)\nclosed-form solution: \\(a = X^{\\prime}X Y\\) and \\(b= ...\\)\nhard to compute if \\(X\\) is very big\n\n\n\n\n\nIncremental learning:\n\ngiven initial \\(a_n\\), \\(b_n\\)\npick \\(N\\) random observations (the batch)\n\nregress them to get new estimate \\(a\\), \\(b\\)\nthis minimizes the square of errors\n\nupdate with learning rate \\(\\beta\\):\n\n\\(a_{n+1} \\leftarrow a_n (1-\\beta_n) + \\beta_n a\\)\n\\(b_{n+1} \\leftarrow b_n (1-\\beta_n) + \\beta_n b\\)\n\nprocess is not biased (that is \\(a\\) converges to the true value) as long as one decreases \\(\\beta\\) sufficiently fast over time (ex: \\(\\beta_n=\\frac{1}{n}\\))"
  },
  {
    "objectID": "slides/session_1_2/index.html#formalisation-a-typical-machine-learning-task",
    "href": "slides/session_1_2/index.html#formalisation-a-typical-machine-learning-task",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Formalisation: a typical machine learning task",
    "text": "Formalisation: a typical machine learning task\n\nvector of unknowns: \\(\\theta=(a,b)\\)\ndataset \\(X,Y=(x_i,y_i)_{i=1:N}\\)\nfor a random draw \\(\\omega = (a_{\\sigma(i)}, b_{\\sigma(i)})_{i=[1,N]} \\subset (X,Y)\\)\n\n\\(\\omega\\) is just a random batch of size \\(N\\)\n\ndefine the empirical risk (or empirical cost) \\[\\xi(\\theta, \\omega) = \\sum_{(x,y) \\in \\omega} (y - (a x + b))^2\\]\nwe want to minimize theoretical risk: \\[\\Xi(\\theta) = \\mathbb{E} \\left[ \\xi(\\theta, \\omega)\\right]\\]"
  },
  {
    "objectID": "slides/session_1_2/index.html#training-gradient-descent",
    "href": "slides/session_1_2/index.html#training-gradient-descent",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Training: Gradient Descent",
    "text": "Training: Gradient Descent\n\n\n\nHow do we minimize a function \\(f(a,b)\\)?\nGradient descent:\n\n\\(a_k, b_k\\) given\ncompute the gradient (slope) \\(\\nabla_{a,b} f = \\begin{bmatrix} \\frac{\\partial f}{\\partial a} \\\\\\\\ \\frac{\\partial f}{\\partial b}\\end{bmatrix}\\)\nfollow the steepest slope: (Newton Algorithm)\n\n\\[ \\begin{bmatrix} a_{k+1} \\\\\\\\ b_{k+1} \\end{bmatrix} \\leftarrow  \\begin{bmatrix} a_k \\\\\\\\ b_k \\end{bmatrix} - \\nabla_{a,b} f\\]\n\nbut not too fast: use learning rate \\(\\lambda\\): \\[ \\begin{bmatrix} a_{k+1} \\\\\\\\ b_{k+1} \\end{bmatrix} \\leftarrow  (1-\\lambda) \\begin{bmatrix} a_k \\\\\\\\ b_k \\end{bmatrix} + \\lambda (- \\nabla_{a,b} f )\\]"
  },
  {
    "objectID": "slides/session_1_2/index.html#not-everything-goes-wrong-all-the-time",
    "href": "slides/session_1_2/index.html#not-everything-goes-wrong-all-the-time",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Not everything goes wrong all the time",
    "text": "Not everything goes wrong all the time\n \n\nIn practice, choosing the right learning rate \\(\\lambda\\) is crucial\n\\(\\lambda\\) is a metaparameter of the model training."
  },
  {
    "objectID": "slides/session_1_2/index.html#wide-data",
    "href": "slides/session_1_2/index.html#wide-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wide data",
    "text": "Wide data\n\nWide Data is characterized by a high number of features compared to the number of observations.\n\n\nProblem:\n\nwith many independent variables \\(x_1, ... x_K\\), \\(K&gt;&gt;N\\) and one dependent variable \\(y\\) the regression \\[y = a_1 x_1 + a_2 x_2 + \\cdots + a_N x_N + b\\] is grossly overidentified."
  },
  {
    "objectID": "slides/session_1_2/index.html#wide-data-regression",
    "href": "slides/session_1_2/index.html#wide-data-regression",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wide data regression",
    "text": "Wide data regression\n\nMain Idea: penalize non-zero coefficients to encourage scarcity\n\nRidge: \\[\\Xi(a,b) = \\min_{a,b} \\sum_{i=1}^N ( \\sum_j a_j x_j + b - y_i)^2 + \\mu \\sum_i |a_i|^2\\]\n\nshrinks parameters towards zero\nclosed form\n\nLasso: \\[\\Xi(a,b) = \\min_{a,b} \\sum_{i=1}^N (\\sum_j a_j x_j + b - y_i)^2 + \\mu \\sum_i |a_i|\\]\n\neliminates zero coefficients\n\nElastic: Ridge + Lasso\n\nRemarks:\n\n\\(\\mu\\) is called a regularization term.\nit is a hyperparameter\n\\(\\mu \\uparrow\\), bias increases, variance decreases"
  },
  {
    "objectID": "slides/session_1_2/index.html#training",
    "href": "slides/session_1_2/index.html#training",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Training",
    "text": "Training\nTo perform Lasso and ridge regression:\n\nAI approach:\n\nminimize objective \\(\\Xi(a,b)\\) directly.\napproach is known as (stochastic) Gradient Descent\n\nUse special algorithms"
  },
  {
    "objectID": "slides/session_1_2/index.html#example-imf-challenge",
    "href": "slides/session_1_2/index.html#example-imf-challenge",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Example: IMF challenge",
    "text": "Example: IMF challenge\n\nAn internal IMF challenge to predict crises in countries\nLots of different approaches\nLots of data:\n\nwhich one is relevant\nmachine must select relevant informations\n\nExample: Lasso Regressions and Forecasting Models in Applied Stress Testing by Jorge A. Chan-Lau\n\nin a given developing country\ntries to predict probability of default in various sectors"
  },
  {
    "objectID": "slides/session_1_2/index.html#nonlinear-regression-1",
    "href": "slides/session_1_2/index.html#nonlinear-regression-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Nonlinear Regression",
    "text": "Nonlinear Regression\n\nSo far, we have assumed,\n\n\\(y_i = a + b x_i\\)\n\\(y_i = a + b x_i + μ_1 (a^2 + b^2) + μ_2 (|a| + |b|)\\)\ndefined \\(\\Xi(a,b)\\) and tried to minimize it\n\nSame approach works for fully nonlinear models\n\n\\(y_i = a x_i + a^2 x_i^2 + c\\)\n\\(y_i = \\varphi(x; \\theta)\\) ()\n\nSpecial case: neural network:\n\nprimer tensor playground"
  },
  {
    "objectID": "slides/session_1_2/index.html#how-to-evaluate-the-machine-learning",
    "href": "slides/session_1_2/index.html#how-to-evaluate-the-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "how to evaluate the machine learning",
    "text": "how to evaluate the machine learning\nIn machine learning we can’t perform statistical inference easily. How do we assess the validity of a model?\n\nBasic idea (independent of how complex the algorithm is)\n\nseparate data in\n\ntraining set (in-sample)\ntest set (out of sample)\n\ntrain using only the training set\nevaluate performance on the test set\n\nPerformance can be:\n\nfitness, number of classification errors (false positive, false negative)"
  },
  {
    "objectID": "slides/session_1_2/index.html#how-to-evaluate-the-machine-learning-1",
    "href": "slides/session_1_2/index.html#how-to-evaluate-the-machine-learning-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "how to evaluate the machine learning",
    "text": "how to evaluate the machine learning\nIn case the training method depends itself on many parameters (the hyperparameters) we make three samples instead:\n\ntraining set (in-sample)\nvalidation set (to update hyperparameters)\ntest set (out of sample)\n\nGolden Rule: the test set should not be used to estimate the model, and should not affect the choice any training parameter (hyperparameter)."
  },
  {
    "objectID": "slides/session_1_2/index.html#section",
    "href": "slides/session_1_2/index.html#section",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "",
    "text": "Traintest\nThe test set reveals that orange model is overfitting."
  },
  {
    "objectID": "slides/session_1_2/index.html#how-to-choose-the-validation-set",
    "href": "slides/session_1_2/index.html#how-to-choose-the-validation-set",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "How to choose the validation set?",
    "text": "How to choose the validation set?\n\nHoldout validation approach:\n\nkeeps x% of the data for the training, (100-x)% for the test\n\nHow to choose the sizes of the subsets?\n\nsmall dataset: 90-10\nbig data set: 70-30 (we can afford to waste more training data for the test)\n\n\n\n\nProblem:\n\nare we sure the validation size is correct? Are the results determined by an (un-) lucky draw?\na problem for smaller datasets"
  },
  {
    "objectID": "slides/session_1_2/index.html#how-to-choose-the-validation-set-1",
    "href": "slides/session_1_2/index.html#how-to-choose-the-validation-set-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "How to choose the validation set?",
    "text": "How to choose the validation set?\nA more robust solution: \\(k\\)-fold validation\n\n\n\nsplit dataset randomly in \\(K\\) subsets of equal size \\(S_1, ... S_K\\)\nuse subset \\(S_i\\) as test set, the rest as training set, compute the score\ncompare the scores obtained for all \\(i\\in[1,K]\\)\n\nthey should be similar (compute standard deviation)\n\naverage them"
  },
  {
    "objectID": "slides/session_1_2/index.html#wait",
    "href": "slides/session_1_2/index.html#wait",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wait",
    "text": "Wait\n\nAnother library to do regression ?\nstatsmodels:\n\nexplanatory analysis\nstatistical tests\nformula interface for many estimation algorithms\n\nstateless approach (model.fit() returns another object)\n\n\nlinearmodels\n\nextends statsmodels (very similar interface)\n\n(panel models, IV, systems…)\n\n\nsklearn:\n\nprediction\nfaster for big datasets\ncommon interface for several machine learning tasks\n\nstateful approach (model is modified by .fit operation)\n\ndefacto standard for machine learning"
  },
  {
    "objectID": "slides/session_1_2/index.html#in-practice",
    "href": "slides/session_1_2/index.html#in-practice",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "In practice",
    "text": "In practice\n\n\nBasic sklearn workflow:\n\n\nimport data\n\nfeatures: a matrix X (2d numpy array)\nlabels: a vector y (1d numpy array)\n\nsplit the data, between training and test datasets\n\nsplit needs to be random to avoid any bias\n\nnormalize the data\n\nmost ML algorithm are sensitive to scale\n\ncreate a model (independent from data)\ntrain the model on training dataset\nevaluate accuracy on test dataset (here \\(R^2\\))\nuse the model to make predictions\n\n\nThe workflow is always the same, no matter what the model is\n\ntry sklearn.linear_model.Lasso instead of LinearRegression\n\n\nfrom sklearn.datasets import load_diabetes\ndataset = load_diabetes()\nX = dataset['data']\ny = dataset['target']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)\n\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\nmodel.score(X_test, y_test)\nmodel.predict(X_new)"
  },
  {
    "objectID": "slides/session_1_2/index.html#k-fold-validation-with-sklearn",
    "href": "slides/session_1_2/index.html#k-fold-validation-with-sklearn",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "\\(k\\)-fold validation with sklearn",
    "text": "\\(k\\)-fold validation with sklearn\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\n\nfor train_index, test_index in kf.split(X):\n   X_train, X_test = X[train_index], X[test_index]\n   y_train, y_test = y[train_index], y[test_index]\n\n   ## train a model in X_train, y_train\n   ## test it on X_test, y_test"
  },
  {
    "objectID": "slides/session_1_3/graphs/Untitled1.html",
    "href": "slides/session_1_3/graphs/Untitled1.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport statsmodels.api as sm\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\ncount\n45.000000\n45.000000\n45.000000\n\n\nmean\n41.866667\n52.555556\n47.688889\n\n\nstd\n24.435072\n29.760831\n31.510332\n\n\nmin\n7.000000\n7.000000\n3.000000\n\n\n25%\n21.000000\n26.000000\n16.000000\n\n\n50%\n42.000000\n45.000000\n41.000000\n\n\n75%\n64.000000\n84.000000\n81.000000\n\n\nmax\n81.000000\n100.000000\n97.000000\n\n\n\n\n\n\n\n\ndf.cov()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\nincome\n597.072727\n526.871212\n645.071212\n\n\neducation\n526.871212\n885.707071\n798.904040\n\n\nprestige\n645.071212\n798.904040\n992.901010\n\n\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(figsize=(8,6))\nplt.plot(df['education'],df['income'],'o')\nplt.grid()\nplt.xlabel(\"x (Education)\")\nplt.ylabel(\"y (Income)\")\nplt.savefig(\"data_description.png\")\n\n\n\n\n\n\n\n\n\nfor i in [1,2,3]:\n    xvec = np.linspace(10,100)\n\n    plt.figure(figsize=(12,8))\n    plt.plot(df['education'],df['income'],'o')\n\n    plt.plot(xvec, xvec * 0 + 50)\n    if i&gt;=2:\n        plt.plot(xvec, xvec )\n    if i&gt;=3:\n        plt.plot(xvec,  90- 0.6*xvec )\n\n    plt.grid()\n    plt.xlabel(\"x (Education)\")\n    plt.ylabel(\"y (Income)\")\n    plt.savefig(f\"which_line_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ipywidgets import interact\n\n\nimport matplotlib.patches as patches\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nplt.vlines(x, y+h, y, color='red')\n\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"error_0.png\")\n\n\n\n\n\n\n\n\n\nplt.vlines?\n\n\nSignature:\nplt.vlines(\n    x,\n    ymin,\n    ymax,\n    colors=None,\n    linestyles='solid',\n    label='',\n    *,\n    data=None,\n    **kwargs,\n)\nDocstring:\nPlot vertical lines.\nPlot vertical lines at each *x* from *ymin* to *ymax*.\nParameters\n----------\nx : float or array-like\n    x-indexes where to plot the lines.\nymin, ymax : float or array-like\n    Respective beginning and end of each line. If scalars are\n    provided, all lines will have same length.\ncolors : list of colors, default: :rc:`lines.color`\nlinestyles : {'solid', 'dashed', 'dashdot', 'dotted'}, optional\nlabel : str, default: ''\nReturns\n-------\n`~matplotlib.collections.LineCollection`\nOther Parameters\n----------------\n**kwargs : `~matplotlib.collections.LineCollection` properties.\nSee Also\n--------\nhlines : horizontal lines\naxvline: vertical line across the axes\nNotes\n-----\n.. note::\n    In addition to the above described arguments, this function can take\n    a *data* keyword argument. If such a *data* argument is given,\n    the following arguments can also be string ``s``, which is\n    interpreted as ``data[s]`` (unless this raises an exception):\n    *x*, *ymin*, *ymax*, *colors*.\n    Objects passed as **data** must support item access (``data[s]``) and\n    membership test (``s in data``).\nFile:      ~/.local/opt/miniconda/lib/python3.8/site-packages/matplotlib/pyplot.py\nType:      function\n\n\n\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nif p-y&gt;0:\n    # Create a Rectangle patch\n    rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n    ax.add_patch(rect)\n    \nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"errors_{1}.png\")\n\n\n\n\n\n\n\n\n\ndef L(a,b):\n    Δ = a + b*df['education'] - df['income']\n    return (Δ**2).sum()\n\n\na = 0.1\nb = 0.8\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_2.png\")\n\n\n\n\n\n\n\n\n\na = 90\nb = -0.6\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_3.png\")\n\n\n\n\n\n\n\n\n\nimport scipy.optimize\n\n\nscipy.optimize.minimize(lambda x: L(x[0], x[1]),np.array([0.5, 0.5]))\n\n      fun: 12480.970174488397\n hess_inv: array([[ 7.14169839e-09, -3.91281920e-09],\n       [-3.91281920e-09,  2.46663613e-09]])\n      jac: array([0.00024414, 0.00012207])\n  message: 'Desired error not necessarily achieved due to precision loss.'\n     nfev: 57\n      nit: 7\n     njev: 19\n   status: 2\n  success: False\n        x: array([10.60350224,  0.59485938])\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_4.png\")\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red', alpha=0.5)\n\nplt.plot(60, a + b*60, 'o', color='red',)\n\nprint(a+b*60)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"prediction.png\")\n\n45.4\n\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  (a + b*df['education'] - df['income'])\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(121)\nplt.plot(approx)\nplt.grid(False)\nplt.title(\"Residuals\")\n\n\nplt.subplot(122)\ndistplot(approx)\nplt.title(\"Distribution of residuals\")\nplt.grid()\n\nplt.savefig(\"residuals.png\")\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\n(a + b*df['education'] - df['income']).std()\n\n16.842782676352154\n\n\n\n\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f\n\n\nf(0.3)\n\nTypeError: _parse_args() missing 1 required positional argument: 'dfd'\n\n\n\nnp.rand\n\n\nK = 100\nxvec = np.linspace(0,1,K)\ne1 = np.random.randn(K)*0.1\nyvec = 0.1 + xvec*0.4 + e1\ne2 = np.random.randn(K)*0.05\nyvec2 = 0.1 + xvec*(xvec-1)/2 + e2\ne3 = np.random.randn(K)*xvec/2\nyvec3 = 0.1 + xvec + e3\n\nyvec4 = 0.1 + np.sin(xvec*6) + np.random.randn(K)*xvec/2\n\n\nfrom dolo.numeric.processes import VAR1\n\n\nsim = VAR1( ρ=0.8, Σ=0.001).simulate(N=1,T=100)\nyvec4 = 0.1 + xvec*0.4 + sim.ravel()\n\n\nplt.figure(figsize=(18,6))\nplt.subplot(241)\nplt.plot(xvec, yvec,'o')\nplt.plot(xvec, 0.1 + xvec*0.4 )\nplt.ylabel(\"Series\")\nplt.title(\"white noise\")\nplt.subplot(242)\nplt.plot(xvec, yvec2, 'o')\nplt.plot(xvec, yvec2*0)\nplt.title('nonlinear')\nplt.subplot(243)\nplt.plot(xvec, yvec3,'o')\nplt.plot(xvec, 0.1 + xvec)\nplt.title('heteroskedastic')\nplt.subplot(244)\nplt.plot(xvec, yvec4,'o')\nplt.plot(xvec, xvec*0.6)\n\nplt.title('correlated')\n\n\nplt.subplot(245)\nplt.plot(xvec, e1,'o')\nplt.ylabel(\"Residuals\")\nplt.subplot(246)\nplt.plot(xvec, yvec2-0.075, 'o')\n\nplt.subplot(247)\nplt.plot(xvec, e3,'o')\nplt.subplot(248)\nplt.plot(xvec, sim.ravel(),'o')\n\nplt.tight_layout()\n\nplt.savefig(\"residuals_circus.png\")"
  },
  {
    "objectID": "slides/session_1_3/index.html#classification-problem",
    "href": "slides/session_1_3/index.html#classification-problem",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Classification problem",
    "text": "Classification problem\n\nBinary Classification\n\nGoal is to make a prediction \\(c_n = f(x_{1,1}, ... x_{k,n})\\) …\n…where \\(c_i\\) is a binary variable (\\(\\in\\{0,1\\}\\))\n… and \\((x_{i,n})_k\\), \\(k\\) different features to predict \\(c_n\\)\n\nMulticategory Classification\n\nThe variable to predict takes values in a non ordered set with \\(p\\) different values"
  },
  {
    "objectID": "slides/session_1_3/index.html#logistic-regression",
    "href": "slides/session_1_3/index.html#logistic-regression",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Logistic regression",
    "text": "Logistic regression\n\n\n\nGiven a regression model (a linear predictor) \\[ a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n \\]\none can build a classification model: \\[ f(x_1, ..., x_n) = \\sigma( a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n )\\] where \\(\\sigma(x)=\\frac{1}{1+\\exp(-x)}\\) is the logistic function a.k.a. sigmoid\nThe loss function to minimize is: \\[L() = \\sum_n (c_n - \\sigma( a_{0} + a_1 x_{1,n} + a_2 x_{2,n} + \\cdots a_k x_{k,n} ) )^2\\]\nThis works for any regression model (LASSO, RIDGE, nonlinear…)"
  },
  {
    "objectID": "slides/session_1_3/index.html#logistic-regression-1",
    "href": "slides/session_1_3/index.html#logistic-regression-1",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nThe linear model predicts an intensity/score (not a category) \\[ f(x_1, ..., x_n) = \\sigma( \\underbrace{a_0 + a_1 x_1 + a_2 x_2 + \\cdots a_n x_n }_{\\text{score}})\\]\nTo make a prediction: round to 0 or 1."
  },
  {
    "objectID": "slides/session_1_3/index.html#multinomial-regression",
    "href": "slides/session_1_3/index.html#multinomial-regression",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Multinomial regression",
    "text": "Multinomial regression\n\n\nIf there are \\(P\\) categories to predict:\n\nbuild a linear predictor \\(f_p\\) for each category \\(p\\)\nlinear predictor is also called score\n\nTo predict:\n\nevaluate the score of all categories\nchoose the one with highest score\n\nTo train the model:\n\ntrain separately all scores (works for any predictor, not just linear)\n… there are more subtle approaches (not here)"
  },
  {
    "objectID": "slides/session_1_3/index.html#common-classification-algorithms",
    "href": "slides/session_1_3/index.html#common-classification-algorithms",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Common classification algorithms",
    "text": "Common classification algorithms\nThere are many:\n\nLogistic Regression\nNaive Bayes Classifier\nNearest Distance\nneural networks (replace score in sigmoid by n.n.)\nDecision Trees\nSupport Vector Machines"
  },
  {
    "objectID": "slides/session_1_3/index.html#nearest-distance",
    "href": "slides/session_1_3/index.html#nearest-distance",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Nearest distance",
    "text": "Nearest distance\n\n\n\nIdea:\n\nin order to predict category \\(c\\) corresponding to \\(x\\) find the closest point \\(x_0\\) in the training set\nAssign to \\(x\\) the same category as \\(x_0\\)\n\nBut this would be very susceptible to noise\nAmended idea: \\(k-nearest\\) neighbours\n\nlook for the \\(k\\) points closest to \\(x\\)\nlabel \\(x\\) with the same category as the majority of them\n\nRemark: this algorithm uses Euclidean distance. This is why it is important to normalize the dataset."
  },
  {
    "objectID": "slides/session_1_3/index.html#decision-tree-random-forests",
    "href": "slides/session_1_3/index.html#decision-tree-random-forests",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Decision Tree / Random Forests",
    "text": "Decision Tree / Random Forests\n\n\n\nDecision Tree\n\nrecursively find simple criteria to subdivide dataset\n\nProblems:\n\nGreedy: algorithm does not simplify branches\neasily overfits\n\nExtension : random tree forest\n\nuses several (randomly generated) trees to generate a prediction\nsolves the overfitting problem"
  },
  {
    "objectID": "slides/session_1_3/index.html#support-vector-classification",
    "href": "slides/session_1_3/index.html#support-vector-classification",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Support Vector Classification",
    "text": "Support Vector Classification\n\n\n\n\nSeparates data by one line (hyperplane).\n\nChooses the largest margin according to support vectors\n\nCan use a nonlinear kernel."
  },
  {
    "objectID": "slides/session_1_3/index.html#all-these-algorithms-are-super-easy-to-use",
    "href": "slides/session_1_3/index.html#all-these-algorithms-are-super-easy-to-use",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "All these algorithms are super easy to use!",
    "text": "All these algorithms are super easy to use!\nExamples:\n\nDecision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\n\n\nSupport Vector\n\nfrom sklearn.svm import SVC\nclf = SVC(random_state=0)\n\n\n\nRidge Regression\n\nfrom sklearn.linear_model import Ridge\nclf = Ridge(random_state=0)"
  },
  {
    "objectID": "slides/session_1_3/index.html#validity-of-a-classification-algorithm",
    "href": "slides/session_1_3/index.html#validity-of-a-classification-algorithm",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Validity of a classification algorithm",
    "text": "Validity of a classification algorithm\n\nIndependently of how the classification is made, its validity can be assessed with a similar procedure as in the regression.\nSeparate training set and test set\n\ndo not touch test set at all during the training\n\nCompute score: number of correctly identified categories\n\nnote that this is not the same as the loss function minimized by the training"
  },
  {
    "objectID": "slides/session_1_3/index.html#classification-matrix",
    "href": "slides/session_1_3/index.html#classification-matrix",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Classification matrix",
    "text": "Classification matrix\n\nFor binary classification, we focus on the classification matrix or confusion matrix.\n\n\n\n\nPredicted\n(0) Actual\n(1) Actual\n\n\n\n\n0\ntrue negatives (TN)\nfalse negatives (FN)\n\n\n1\nfalse positives (FP)\ntrue positives (TP)\n\n\n\n\nWe can then define different measures:\n\nSensitivity aka True Positive Rate (TPR): \\(\\frac{TP}{FP+TP}\\)\nFalse Positive Rate (FPR): \\(\\frac{FP}{TN+FP}\\)\nOverall accuracy: \\(\\frac{\\text{TN}+\\text{TP}}{\\text{total}}\\)\n\n\n\nWhich one to favour depends on the use case"
  },
  {
    "objectID": "slides/session_1_3/index.html#example-london-police",
    "href": "slides/session_1_3/index.html#example-london-police",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Example: London Police",
    "text": "Example: London Police\n\nPolice cameras in LondonAccording to London Police the cameras in London have\n\nTrue Positive Identification rate of over 80% at a fixed number of False Positive Alerts.29 nov. 2022\n\n\nInterpretation? Is failure rate too high?"
  },
  {
    "objectID": "slides/session_1_3/index.html#example",
    "href": "slides/session_1_3/index.html#example",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Example",
    "text": "Example\n\nIn-sample confusion matrixBased on consumer data, an algorithm tries to predict the credit score from.\nCan you calculate: FPR, TPR and overall accuracy?"
  },
  {
    "objectID": "slides/session_1_3/index.html#confusion-matrix-with-sklearn",
    "href": "slides/session_1_3/index.html#confusion-matrix-with-sklearn",
    "title": "Introduction to Machine Learning (2/2)",
    "section": "Confusion matrix with sklearn",
    "text": "Confusion matrix with sklearn\n\nPredict on the test set:\n\ny_pred = model.predict(x_test)\n\nCompute confusion matrix:\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)"
  },
  {
    "objectID": "slides/session_1/index.html#how-to-deal-with-text",
    "href": "slides/session_1/index.html#how-to-deal-with-text",
    "title": "From Text Analysis…",
    "section": "How to deal with text?",
    "text": "How to deal with text?\n\nRecall: big data contains heterogenous data\n\ntext / images / sound"
  },
  {
    "objectID": "slides/session_1/index.html#example-1-fomc-meetings",
    "href": "slides/session_1/index.html#example-1-fomc-meetings",
    "title": "From Text Analysis…",
    "section": "Example 1: FOMC meetings",
    "text": "Example 1: FOMC meetings\nTaking the Fed at its Word: A New Approach to Estimating Central Bank Objectives using Text Analysis, Shapiro and Wilson (2022)\n\nRemember the Taylor rule for central banks?\nGeneralized version: \\(i_t = \\alpha_\\pi (\\pi_t-\\pi^{\\star}) + \\alpha_y (y_t-y)\\)\nIs there a way to measure the preferences of the central bank? (coefficients and inflation target?)\nTraditional way: look at CB decisions ex post + run a regression\nShapiro and Wilson: let’s look at the FOMC meeting transcripts\nExcerpts (there are tons of them: 704,499)\n\n\n\n\nI had several conversations at Jackson Hole with Wall Street economists and journalists, and they said, quite frankly, that they really do not believe that our effective inflation target is 1 to 2 percent. They believe we have morphed into 1+1/2 to 2+1/2 percent, and no one thought that we were really going to do anything over time to bring it down to 1 to 2.\n\nSep 2006 St. Louis Federal Reserve President William Poole\n\n\n\nLike most of you, I am not at all alarmist about inflation. I think the worst that is likely to happen would be 20 or 30 basis points over the next year. But even that amount is a little disconcerting for me. I think it is very important for us to maintain our credibility on inflation and it would be somewhat expensive to bring that additional inflation back down.\n\nMarch 2006 Chairman Ben Bernanke\n\n\n\nWith inflation remaining at such rates, we could begin to lose credibility if markets mistakenly inferred that our comfort zone had drifted higher. When we stop raising rates, we ought to be reasonably confident that policy is restrictive enough to bring inflation back toward the center of our comfort zone, which I believe is 1+1/2 percent…So for today, we should move forward with an increase of 25 basis points…\n\nJan 2006 Chicago Federal Reserve President Michael Moskow"
  },
  {
    "objectID": "slides/session_1/index.html#example-2",
    "href": "slides/session_1/index.html#example-2",
    "title": "From Text Analysis…",
    "section": "Example 2",
    "text": "Example 2\n\n\n\n\n\n\nSuppose you work in the trading floor of a financial institution\nThese kind of tweets have disturbing impact on the markets. You need to react quickly.\nYou need a machine to assess the risk in real time.\nMore generally, tweeter is a quite unique source of real-time data\nHow do you analyse the content of the tweets?\nComment: actually it’s not only the content of the tweets, but who reads, who retweets: graph analysis"
  },
  {
    "objectID": "slides/session_1/index.html#text-mining-what-can-we-extract-from-texts",
    "href": "slides/session_1/index.html#text-mining-what-can-we-extract-from-texts",
    "title": "From Text Analysis…",
    "section": "Text-mining: what can we extract from texts",
    "text": "Text-mining: what can we extract from texts\n\nThe main branches of text analysis are:\n\nsentiment analysis (today)\n\nassociate positivity/negativity score to a text\nprecise meaning of “sentiment” is context dependent\n\n\ntopic modeling\n\nclassify texts as belonging to known categories (supervised)\nfinding likely texts (unsupervised)\n\nnamed-entity recognition\n\nfind who gets mentioned in the text\nexample: A Cross-verified Database of Notable People, 3500BC-2018AD\n\nevent-extraction\n\nrecognize mention of events\n\n…"
  },
  {
    "objectID": "slides/session_1/index.html#clarification",
    "href": "slides/session_1/index.html#clarification",
    "title": "From Text Analysis…",
    "section": "Clarification",
    "text": "Clarification\n\n\nText analysis / text mining are somewhat used interchangeably\nIn general they consist in quantifying information used in a text…\n… so that it can be incorporated in machine learning analysis\nRecently, deep learning (and GPT-3) has changed this state of facts:\n\nsome models get trained direcly on text (intermediary phases are not explicited)"
  },
  {
    "objectID": "slides/session_1/index.html#the-even-less-glamorous-part",
    "href": "slides/session_1/index.html#the-even-less-glamorous-part",
    "title": "From Text Analysis…",
    "section": "The even-less glamorous part",
    "text": "The even-less glamorous part\n\n\nbefore getting started with text analysis, one needs to get hold of the text in the first place\n\nhow to extract\n\nwebscraping: automate a bot to visit website and download text\ndocument extraction: for instance extract the text from pdf docs, get rid of everything irrelevant\n\n\nhow to store it\n\nwhat kind of database?\nimportant problem when database is big"
  },
  {
    "objectID": "slides/session_1/index.html#processing-steps",
    "href": "slides/session_1/index.html#processing-steps",
    "title": "From Text Analysis…",
    "section": "Processing steps",
    "text": "Processing steps\n\nLet’s briefly see how text gets processed.\nGoal is to transform the text into a numerical vector of features\n\nStupid approach: “abc”-&gt;[1,2,3]\nwe need to capture some form of language structure\n\nAll the steps can be done fairly easily with nltk\n\nnltk is comparable to sklearn in terms of widespread adoption"
  },
  {
    "objectID": "slides/session_1/index.html#processing-steps-2",
    "href": "slides/session_1/index.html#processing-steps-2",
    "title": "From Text Analysis…",
    "section": "Processing steps (2)",
    "text": "Processing steps (2)\n\nSteps:\n\ntokenization\nstopwords\nlexicon normalization\n\nstemming\nlemmatization\n\nPOS tagging"
  },
  {
    "objectID": "slides/session_1/index.html#tokenization",
    "href": "slides/session_1/index.html#tokenization",
    "title": "From Text Analysis…",
    "section": "Tokenization",
    "text": "Tokenization\n\n\n\nTokenization: split input into atomic elements.\n\nWe can recognize sentences.\n\nOr words.\n\nIt is enough for some basic analysis:\n\n\nfrom nltk.probability import FreqDist\nfdist = FreqDist(words)\nprint(fdist.most_common(2))\n[('It', 1), (\"'s\", 1)]\n\n\n\n\nfrom nltk.tokenize import sent_tokenize\ntxt = \"\"\"Animal Farm is a short novel by George Orwell. It was\nwritten during World War II and published in 1945. It is about \na group of farm animals who rebel against their farmer. They \nhope to create a place where the animals can be equal, free,\n and happy.\"\"\"\nsentences  = sent_tokenize(txt)\nprint(sentences)\n\n\n['Animal Farm is a short novel by George Orwell.',\n 'It was\\nwritten during World War II and published in 1945.', \n 'It is about \\na group of farm animals who rebel against their farmer.', \n 'They \\nhope to create a place where the animals can be equal, free,\\n and happy.']\n\n\nfrom nltk.tokenize import word_tokenize\ntxt = \"It's a beautiful thing, the destruction of words.\"\nwords  = word_tokenize(txt)\nprint(words)\n['It', \"'s\", 'a', 'beautiful', 'thing', ',', 'the', 'destruction', 'of', 'words', '.']"
  },
  {
    "objectID": "slides/session_1/index.html#part-of-speech-tagging",
    "href": "slides/session_1/index.html#part-of-speech-tagging",
    "title": "From Text Analysis…",
    "section": "Part-of speech tagging",
    "text": "Part-of speech tagging\n\n\n\nSometimes we need information about the kind of tokens that we have\n\nWe can perform part-of-speech tagging (aka grammatical tagging)\n\nThis is useful to refine interpretation of some words\n\n“it’s not a beautiful thing”\nvs “it’s a beautiful thing”\nconnotation of beautiful changes\n\n\n\n\nfrom nltk.tokenize import word_tokenize\ntagged = nltk.pos_tag(words)\ntagged\n[('It', 'PRP'),\n (\"'s\", 'VBZ'),\n ('a', 'DT'),\n ('beautiful', 'JJ'),\n ('thing', 'NN'),\n (',', ','),\n ('the', 'DT'),\n ('destruction', 'NN'),\n ('of', 'IN'),\n ('words', 'NNS'),\n ('.', '.')]"
  },
  {
    "objectID": "slides/session_1/index.html#simplifying-the-text-1-stopwords",
    "href": "slides/session_1/index.html#simplifying-the-text-1-stopwords",
    "title": "From Text Analysis…",
    "section": "Simplifying the text (1): stopwords",
    "text": "Simplifying the text (1): stopwords\n\n\n\nSome words are very frequent and carry no useful meaning\n\n\nThey are called stopwords\n\n\nWe typically remove them from our word list\n\n\n\n\nfrom nltk.corpus import stopwords\nstop_words=set(stopwords.words(\"english\"))\nprint(stop_words)\n{'their', 'then', 'not', 'ma', 'here', ...}\n\n\n\nfiltered_words = [w for w in words if w not in stop_words]\nfiltered_words\n['beautiful', 'thing' 'destruction', 'words']"
  },
  {
    "objectID": "slides/session_1/index.html#simplifying-the-text-2-lexicon-normalization",
    "href": "slides/session_1/index.html#simplifying-the-text-2-lexicon-normalization",
    "title": "From Text Analysis…",
    "section": "Simplifying the text (2): lexicon normalization",
    "text": "Simplifying the text (2): lexicon normalization\n\n\n\nSometimes, there are several variants of a given word\n\ntight, tightening, tighten\n\n\nStemming: keeping the word root\n\nLemmatization: keeps the word base\n\nlinguistically correct contrary to stemming\n\n\n\n\nfrom nltk.stem import PorterStemmer\nps = PorterStemmer()\n\nwords =  [\"tight\", \"tightening\", \"tighten\"]\nstemmed_words=[ps.stem(w) for w in words]\n['tight', 'tighten', 'tighten']\n\n\nfrom nltk.stem.wordnet import WordNetLemmatizer\nlem = WordNetLemmatizer()\n\nwords =  [\"flying\", \"flyers\", \"fly\"]\nstemmed_words=[ps.stem(w) for w in words]\nlemmatized_words=[lem.lemmatize(w) for w in words]\n# lemmatized\n['flying', 'flyer', 'fly']\n# stemmed\n['fli', 'flyer', 'fli']"
  },
  {
    "objectID": "slides/session_1/index.html#sentiment-analysis-1",
    "href": "slides/session_1/index.html#sentiment-analysis-1",
    "title": "From Text Analysis…",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\n\nWhat do we do now that we have reduced a text to a series of word occurrences?\nTwo main approaches:\n\nlexical analysis\nmachine learning"
  },
  {
    "objectID": "slides/session_1/index.html#lexical-analysis",
    "href": "slides/session_1/index.html#lexical-analysis",
    "title": "From Text Analysis…",
    "section": "Lexical analysis",
    "text": "Lexical analysis\n\nUse a “sentiment dictionary” to provide a value (positive or negative) for each word\n\nsum the weights to get positive or negative sentiment\n\n\nExample: \\[\\underbrace{\\text{Sadly}}_{-}\\text{, there wasn't a glimpse of }\\underbrace{\\text{light}}_{+} \\text{ in his } \\text{world } \\text{ of intense }\\underbrace{\\text{suffering.}}_{-}\\]\n\nTotal:\n\n-1+1-1. Sentiment is negative.\n\n\nProblems:\n\nhere, taking grammar into account would change everything\ndoesn’t capture irony\nour dictionary doesn’t have weights for what matters to us \\[ \\text{the central bank forecasts increased }\\underbrace{\\text{inflation}}_{?}\\]"
  },
  {
    "objectID": "slides/session_1/index.html#machine-learning",
    "href": "slides/session_1/index.html#machine-learning",
    "title": "From Text Analysis…",
    "section": "Machine learning",
    "text": "Machine learning\n\nIdea: we would like the weights to be endogenously determined \\[ \\underbrace{\\text{the}}_{x_1} \\underbrace{\\text{ central}}_{x_2} \\underbrace{\\text{ bank}}_{x_3} \\underbrace{\\text{ forecasts}}_{x_4} \\underbrace{\\text{ increased} }_{x_5} \\underbrace{\\text{ inflation}}_{x_6}\\]\nSuppose we had several texts: we can generate features by counting words in each of them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthe\ncentral\nbank\nforecasts\nincreased\ninflation\neconomy\nexchange rate\ncrisis\nsentiment\n\n\n\n\ntext1\n1\n1\n2\n1\n1\n2\n\n\n\n-1\n\n\ntext2\n3\n\n\n\n\n1\n1\n2\n\n+1\n\n\ntext3\n4\n\n1\n\n\n1\n\n1\n1\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can the train the model: \\(y = x_1 f(w_1) + \\cdots x_K f(w_K)\\) where \\(y\\) is the sentiment and \\(w_i\\) is wordcount of word \\(w_i\\)\n\nof course, we need a similar procedure as before (split the training set and evaluation set, …)\nwe can use any model (like naive bayesian updating)\n\nThis approach is called Bag of Words (BOW)"
  },
  {
    "objectID": "slides/session_1/index.html#some-issues",
    "href": "slides/session_1/index.html#some-issues",
    "title": "From Text Analysis…",
    "section": "Some issues",
    "text": "Some issues\n\nBag of words has a few pitfalls:\n\nit requires a big training set with labels\nit overweights long documents\nthere is noise due to the very frequent words that don’t affect sentiment\nordering of words / grammar plays no role\n\nImprovement: TF-IDF\n\nstands for Term-Frequency*Inverse-Distribution-Frequency\nreplace word frequency \\(f(w)\\) by \\[\\text{tf-idf} = f(w)\\frac{\\text{number of documents}}{\\text{number of documents containing $w$}}\\]"
  },
  {
    "objectID": "slides/session_1/index.html#deep-learning",
    "href": "slides/session_1/index.html#deep-learning",
    "title": "From Text Analysis…",
    "section": "Deep learning",
    "text": "Deep learning\n\n\n\n\n\n\nNeural networks have become very popular.\nA classification problem would look like: \\[c = f(x_1, ..., x_n;\n\\theta)\\] where \\(f\\) is a nonlinear function and \\(\\theta\\) is an unknown vector of parameters\nOr even \\[c = f(\\text{full_text};\\theta)\\]\n\nwhich could potentially capture meaning embedded in syntax\nmany possible versions of \\(f\\) (network topologies)\n\nProblem?\n\ndeep parameters require a bigger dataset\n\nPossible remedy: learn from a wider, more general dataset =&gt; transfer learning"
  },
  {
    "objectID": "session_3/index.html#what-went-wrong-last-time",
    "href": "session_3/index.html#what-went-wrong-last-time",
    "title": "Large Language Models in the Wild",
    "section": "What went wrong last time?",
    "text": "What went wrong last time?\n\nTwo bugs prevented flawless execution:\n\npandas datetime\nopenai completion\n\nIn both cases, the problem was a recent change in Application Programming Interface.",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#what-is-an-api",
    "href": "session_3/index.html#what-is-an-api",
    "title": "Large Language Models in the Wild",
    "section": "What is an API?",
    "text": "What is an API?\nDefinition of an API\n\nhow you call a function from a library\nexample: python function pandas.to_datetime(df)\nexample2: REST calls, info from a website (like https://opentdb.com/api.php?amount=1&category=18)\n\nAPIs are:\n\ndocumented online\nspecific to a given version of the libary\n\nExample: where is the doc for the python API of OpenAI? for the REST API?",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#advice-for-writing-code",
    "href": "session_3/index.html#advice-for-writing-code",
    "title": "Large Language Models in the Wild",
    "section": "Advice for writing code",
    "text": "Advice for writing code\n\nCode Hygiene\n\ncomments: in python anything after\ndocstrings: specify the API of your own functions\nversion your code (git, git, git, …) 1\n\nReplicability\n\ndistribute and version data (example)\n\nas raw as possible\n\nspecify running environment\n\nlists the version of the system / all libraries\nconda: conda environment (environment.yml)\n\n\n(Bonus: provide a website with mybinder/shinypython )\n\nthis applies to all writing steps, especially latex documents",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#gpt",
    "href": "session_3/index.html#gpt",
    "title": "Large Language Models in the Wild",
    "section": "GPT",
    "text": "GPT\nLast week we described some elements of a transformer architecture.\n\nMost famous engine developped by OpenAI: Generative Pre-trained Transformer (aka GPT)\n\n\n\n\nGPT1 (1018)\n\n0.1 billion parameters\nhad to be fine-tuned to a particular problem\ntransfer learning (few shots learning)\n\nGPT2:\n\nmultitask\nno mandatory fine tuning\n\nGPT3:\n\nbigger: 175 billions parameters\n\nGPT4:\n\neven bigger: 1000 billions parameters ???\non your harddrive: 1Tb",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#corpus",
    "href": "session_3/index.html#corpus",
    "title": "Large Language Models in the Wild",
    "section": "Corpus",
    "text": "Corpus\n\n\nGPT-3 was trained1 on\n\nCommonCrawl\nWebText (proprietary db, with opensource alternative )\nWikipedia\nmany books\n\n⇒ 45 TB of data\n\ncured into a smaller datasets\n\n⇒ size ???\nDataset (mostly) ends in 2021.\n\n\n\n\nDetailed information about gpt-4 is harder to find.",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#how-is-the-model-trained",
    "href": "session_3/index.html#how-is-the-model-trained",
    "title": "Large Language Models in the Wild",
    "section": "How is the model trained?",
    "text": "How is the model trained?\nSeveral concepts are relevant here:\n\n\nunsupervised learning\n\nautoencoding\n⇒ build a representation of the text\n\nfine tuning\nreinforcement learning",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#what-is-learning",
    "href": "session_3/index.html#what-is-learning",
    "title": "Large Language Models in the Wild",
    "section": "What is learning?",
    "text": "What is learning?\nA machine can perform a task \\(f(x; \\theta)\\) for some input \\(x\\) in a data-generating process \\(\\mathcal{X}\\) and and some parameters \\(\\theta\\).\nA typical learning task consists in optimizing a loss function (aka theoretical risk): \\[\\min _{\\theta} \\mathcal{L}(\\theta) = \\mathbb{E}_{\\theta} f(x; \\theta)\\]\nThe central learning method to minimize the objective is called stochastic gradient descent.\n\n\n\n.\n\n\n\n\nA common issue in ai is that of preference misspecification. (Cf Bostrom or link)",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#learning-set",
    "href": "session_3/index.html#learning-set",
    "title": "Large Language Models in the Wild",
    "section": "Learning Set",
    "text": "Learning Set\nIn practice one has access to a dataset \\((x_n) \\subset \\mathcal{X}\\) and minimizes the “empirical” risk function\n\\[L\\left( (x_n)_{n=1:N}, \\theta \\right) = \\frac{1}{N} \\sum_{n=1}^N f(x; \\theta)\\]\n\nRegular case: in usual cases, we assume that the dataset is generated by the true model (data-generating process)\nTwo important variants:\n\ntransfer learning:\n\ngoal is to use the model \\(\\mathcal{X}\\) but the training dataset is generated from another data-generating process \\(\\mathcal{Y}\\)\n\\(\\mathcal{Y}\\) can be a subset of \\(\\mathcal{X}\\) or (partially) disjoint\ndo you need some data from \\(\\mathcal{Y}\\) (few shots learning) or non at all (zero-shot learning)\n\nreinforcement learning\n\nthe learning algorithm can generate some data to improve learning",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#transfer-learning",
    "href": "session_3/index.html#transfer-learning",
    "title": "Large Language Models in the Wild",
    "section": "Transfer learning",
    "text": "Transfer learning\n\n\nGPT is inherently a transfer learning machine\n\nwhy?\n\nearlier versions (GPT-1, GPT-2) needed some examples before being able to perform any given task:\n\nfine-tuning: retrain some coefficients of the wole NN\n\nnew versions (&gt;GPT-3) can perform zero-shot tasks just by text completion\n\nfine-tuning can be emulated by prompting\nthere is still a fine-tuning API",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#reinforcement-learning",
    "href": "session_3/index.html#reinforcement-learning",
    "title": "Large Language Models in the Wild",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\nA reinforcement learning algorithm can take actions which have two effects:\n\nprovide some reward to the algorithm\ngenerate (more) data to improve the quality of future actions\n\nExample:\n\nchoose a restaurant\ndrive a car\nfamous examples: breakout, hide and seek",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#reinforcement-learning-for-gpt-4",
    "href": "session_3/index.html#reinforcement-learning-for-gpt-4",
    "title": "Large Language Models in the Wild",
    "section": "Reinforcement Learning for GPT-4",
    "text": "Reinforcement Learning for GPT-4\nThe GPT-4 model has been fine-tuned with reinforcement learning. The language model was rewarded for providing the right kind of answer:\n\nthe feedback came from kenyan workers (sic!)\n\nTwo main variants on top of foundation model GPT Base:1\n\ninstructGPT\n\nalignment, non-toxicity, …\nfactual correctness\n\nchatGPT\n\nfollow a conversation\norganization of answer\nnot just a context on top of GPT\n\n\nComing next: assistants.",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#section",
    "href": "session_3/index.html#section",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "There is information about how GPT-3 was trained (check technical paper or summary)",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#the-different-variants-of-gpt",
    "href": "session_3/index.html#the-different-variants-of-gpt",
    "title": "Large Language Models in the Wild",
    "section": "The different variants of GPT",
    "text": "The different variants of GPT\nWhich of the following model should you use?\nLots of options:\n\n\ntext-curie-001\ntext-davinci-003\ntext-babbage-001\ntext-ada-001\n…\n\n\nWhat are the differences between the various engines?\n\narchitecture / model size\ntraining set of foundation model (GPT Base)\ntype of fine-tuning (instruct/chat/code)\n\nIt is not clear whether GPT Base will still be accessible in the future or whether it will be fine-tuned for alignement or not.\n\nconsequences?",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#section-1",
    "href": "session_3/index.html#section-1",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "Checkout the awesome list!",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#section-2",
    "href": "session_3/index.html#section-2",
    "title": "Large Language Models in the Wild",
    "section": "",
    "text": "What are the trends?\n\nmany foundation Models\n\nmove from opensource to closedsource\nbut: opensource is still very alive\n\nresearch to reduce size of models / training time\nmany more versions specialized (fine-tuned) to specific tasks",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#one-common-misconception",
    "href": "session_3/index.html#one-common-misconception",
    "title": "Large Language Models in the Wild",
    "section": "One common misconception",
    "text": "One common misconception\n\nLanguage models hallucinate facts…\n\ntherefore are definitely unreliable for research\n\nThere are possible workarounds\n\navoid tasks where hallucinations occur (like ask for paper citations)\nmore structure in the prompting (like “detail your reasoning”)\n\nAnd research being done…\n\non using fine-tuning for more correctness (e.g. instructGPT)\non developing mixed systems\n\n\nCheck out GPT Assistants and Scite",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "session_3/index.html#how-much-should-we-trust-ai",
    "href": "session_3/index.html#how-much-should-we-trust-ai",
    "title": "Large Language Models in the Wild",
    "section": "How much should we trust AI?",
    "text": "How much should we trust AI?\nAI safety and AI alignment is a very active field right now.\nFor economists, AI behaviour can be characterized in terms of biases:\n\nstatistical bias\npreference misspecification\n\nexplicit\nimplicit\n\nbehavioural biases\n\nFor now we don’t know much.",
    "crumbs": [
      "Large Language Models in the Wild"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI for Research",
    "section": "",
    "text": "Full Syllabus\nThe objective of the course, will be to explore together through lectures and students contributions how GPT-4 in particular and Large Language Models (LLMs) in general can be used for producing research as a substitute to traditional natural language processing techniques (NLP).\nAlso, as Large Language Models become more versatile and are being increasingly used to inform real world decisions, part of the course will be devoted to recent research approaches designed to experimentally evaluate and practically control the behavior of AI as approximated by an LLM . We’ll discuss both structural approaches (affecting the model building) and external approaches (taking AI as a black box and observing its behavior)."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "AI for Research",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nNov 15, 2023\n\n\nFrom Text Analysis…\n\n\n\n\nNov 15, 2023\n\n\n…to Large Language Models\n\n\n\n\nNov 28, 2023\n\n\nLarge Language Models in the Wild\n\n\n\n\nDec 6, 2023\n\n\nBehavior of Large Language Models\n\n\n\n\nDec 13, 2023\n\n\nResearch Frontiers: What’s Next?\n\n\n\n\nNov 14, 2024\n\n\nFrom Text Analysis…\n\n\n\n\nNov 21, 2024\n\n\n…to Large Language Models\n\n\n\n\nNov 29, 2024\n\n\nLarge Language Models in the Wild\n\n\n\n\nDec 6, 2024\n\n\nBehavior of Large Language Models\n\n\n\n\nDec 13, 2024\n\n\nResearch Frontiers: What’s Next?\n\n\n\n\n \n\n\nPython: syntax review\n\n\n\n\n \n\n\nPython Fundamentals\n\n\n\n\n \n\n\nBasics\n\n\n\n\n \n\n\nControl Flow\n\n\n\n\n \n\n\nCollections\n\n\n\n\n \n\n\nFunctions\n\n\n\n\n \n\n\nSentiment analysis\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\nSentiment analysis\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\nSentiment analysis (correction)\n\n\n\n\n \n\n\nSentiment analysis\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\nUsing OpenAI GPT\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\nUsing OpenAI GPT\n\n\n\n\n \n\n\nUsing OpenAI GPT\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html",
    "href": "tutorials/session_2/sentiment_analysis.html",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5.\n\n\n\nWe use the News Sentiment Dataset from Kaggle.\n\ncd tutorials/session_2\n\n/files/tutorials/session_2\n\n\n\npwd\n\n'/files/tutorials/session_2'\n\n\n\nImport Dataset as a pandas dataframe\n\n\nimport pandas\ndf = pandas.read_csv(\"Tweets.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n0\ncb774db0d1\nI`d have responded, if I were going\nI`d have responded, if I were going\nneutral\n\n\n1\n549e992a42\nSooo SAD I will 🦈 miss you here in San Diego!!!\nSooo SAD\nnegative\n\n\n2\n088c60f138\nmy boss is bullying me...\nbullying me\nnegative\n\n\n3\n9642c003ef\nwhat interview! leave me alone\nleave me alone\nnegative\n\n\n4\n358bd9e861\nSons of ****, why couldn`t they put them on t...\nSons of ****,\nnegative\n\n\n...\n...\n...\n...\n...\n\n\n27476\n4eac33d1c0\nwish we could come see u on Denver husband l...\nd lost\nnegative\n\n\n27477\n4f4c4fc327\nI`ve wondered about rake to. The client has ...\n, don`t force\nnegative\n\n\n27478\nf67aae2310\nYay good for both of you. Enjoy the break - y...\nYay good for both of you.\npositive\n\n\n27479\ned167662a5\nBut it was worth it ****.\nBut it was worth it ****.\npositive\n\n\n27480\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\nAll this flirting going on - The ATG smiles. Y...\nneutral\n\n\n\n\n27481 rows × 4 columns\n\n\n\n\ndf.iloc[1200,:]['text']\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?\n\n\n\n\n\nExtract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix.\n\n\n\n\n\nSetup an openai key. Explore openai completion API.\n\n\nimport openai\n\n\n# R\n\n\n# make sure we have the right version\nfrom openai import version\nopenai.version.VERSION\n\n'1.3.5'\n\n\n\napi_key = \"\"\n\n\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer.\n\n\n\n\n\nCompare the various methods on the test set."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html#ai-for-research-2023",
    "href": "tutorials/session_2/sentiment_analysis.html#ai-for-research-2023",
    "title": "Sentiment analysis",
    "section": "",
    "text": "The ultimate goal of this exercise consists performing the same exercise, namely sentiment analysis, using traditional NLP and GPT-3.5."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html#the-dataset",
    "href": "tutorials/session_2/sentiment_analysis.html#the-dataset",
    "title": "Sentiment analysis",
    "section": "",
    "text": "We use the News Sentiment Dataset from Kaggle.\n\ncd tutorials/session_2\n\n/files/tutorials/session_2\n\n\n\npwd\n\n'/files/tutorials/session_2'\n\n\n\nImport Dataset as a pandas dataframe\n\n\nimport pandas\ndf = pandas.read_csv(\"Tweets.csv\")\n\n\ndf\n\n\n\n\n\n\n\n\ntextID\ntext\nselected_text\nsentiment\n\n\n\n\n0\ncb774db0d1\nI`d have responded, if I were going\nI`d have responded, if I were going\nneutral\n\n\n1\n549e992a42\nSooo SAD I will 🦈 miss you here in San Diego!!!\nSooo SAD\nnegative\n\n\n2\n088c60f138\nmy boss is bullying me...\nbullying me\nnegative\n\n\n3\n9642c003ef\nwhat interview! leave me alone\nleave me alone\nnegative\n\n\n4\n358bd9e861\nSons of ****, why couldn`t they put them on t...\nSons of ****,\nnegative\n\n\n...\n...\n...\n...\n...\n\n\n27476\n4eac33d1c0\nwish we could come see u on Denver husband l...\nd lost\nnegative\n\n\n27477\n4f4c4fc327\nI`ve wondered about rake to. The client has ...\n, don`t force\nnegative\n\n\n27478\nf67aae2310\nYay good for both of you. Enjoy the break - y...\nYay good for both of you.\npositive\n\n\n27479\ned167662a5\nBut it was worth it ****.\nBut it was worth it ****.\npositive\n\n\n27480\n6f7127d9d7\nAll this flirting going on - The ATG smiles...\nAll this flirting going on - The ATG smiles. Y...\nneutral\n\n\n\n\n27481 rows × 4 columns\n\n\n\n\ndf.iloc[1200,:]['text']\n\n' hahahah of course  they have such a nasty display picture :`)'\n\n\n\nDescribe Dataset (text and graphs)\nSplit Dataset into training, validation and test set. What is the purpose of the validation set?"
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html#text-mining",
    "href": "tutorials/session_2/sentiment_analysis.html#text-mining",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Extract features from the training dataset. What do you do with non-words / punctuation?\nConvert occurrencies to frequencies. Make another version with tf-idf.\nChoose a classifier to predict the sentiment on the validation set. Compute the confusion matrix."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html#sentiment-analysis-using-gpt-completion",
    "href": "tutorials/session_2/sentiment_analysis.html#sentiment-analysis-using-gpt-completion",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Setup an openai key. Explore openai completion API.\n\n\nimport openai\n\n\n# R\n\n\n# make sure we have the right version\nfrom openai import version\nopenai.version.VERSION\n\n'1.3.5'\n\n\n\napi_key = \"\"\n\n\nDesign a prompt to extract the sentiment from a tweet. Test it on very few tweets from the training dataset. Propose different versions.\nWrite a function which takes in: the prompt template, the tweet text and returns the sentiment as an integer."
  },
  {
    "objectID": "tutorials/session_2/sentiment_analysis.html#performance-shootout",
    "href": "tutorials/session_2/sentiment_analysis.html#performance-shootout",
    "title": "Sentiment analysis",
    "section": "",
    "text": "Compare the various methods on the test set."
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html",
    "href": "tutorials/session_1/python_syntax.html",
    "title": "Python: syntax review",
    "section": "",
    "text": "# integers and floats\n\n\n1\n\n\n1.0\n\n\n# conversion with int() and float()\nfloat( 1 )\n\n\nint(2.9) # floor\n\n\n# no difference between various types of floats (16 bits, 32 bits, 64 bits, ...)\n\n\ntype( 2.2**50 ) # this doesn't fit in 32 bits\n\n\n# usual operations + - *\nprint( 2 + 3 )\nprint( 9 -6 )\nprint( 3 / 2 )\nprint(2304310958*41324)\n\n\n# divisions / and //\nprint(3/4)\nprint(13//4)\n\n\n# exponentiation ** (not ^!)\n# (1.04)^10\n(1.04)**10\n\n\n# comparison operators: &gt;, &lt;, &gt;=, &lt;=, ==\n\nprint((1.0453432)*(0.96)  &gt; 1.001 )\n\nprint(1.001 &gt;= 1.001)\n\n\n# comparison operators can be chained:\nprint(0.2&lt;0.4&lt;0.5)\nprint(0.5&lt;=0.4&lt;=0.5) # equivalent to ((0.5&lt;=0.4) and(0.4&lt;=0.5))\n\n\n\n\nThere are only two booleans: True and False (note uppercase). None is a dummy type, which is used when no other type fits.\n\nprint( False )\nTrue\n\n\n(True, False, None)\n\nDouble equal sign tests for equality. Result should always be a boolean.\n\nTrue==False\n\nLogical operators are not, and and or:\n\n(True or False)\n\n\nnot (True or False)\n\n\n(1.3**1.04 &gt; 1.9) | (1000**1143&gt;1001**1142)\n\nOperators or and and can be replaced by | and & respectively. They are non-greedy, that is terms are not evaluated if the result of the comparison is already known.\n\nFalse and (print(\"Hello\"))\n\n\nprint( (print(\"Hello\")) and False )\n\n\n\n\n\n\nStrings are defined by enclosing characters either by ' (single quotes) or \" (double quote). Single quotes strings can contain double quotes strings and vice-versa.\n\n\"name\"\n\n\n'name'\n\n\n'I say \"hello\"'\n\n\n\"You can 'quote' me\"\n\nStrings spanning over sever lines can be defined with triple quotes (single or double).\n\ns = \"\"\"¿Qué es la vida? Un frenesí.\n¿Qué es la vida? Una ilusión,\nuna sombra, una ficción,\ny el mayor bien es pequeño;\nque toda la vida es sueño,\ny los sueños, sueños son.\n\"\"\"\n\nIt is also possible to use the newline character \\n.\n\n\"La vida es sueño,\\ny los sueños, sueños son.\"\n\n\nprint(\"La vida es sueño,\\ny los sueños, sueños son.\")\n\n\n\n\nStrings can contain any unicode character:\n\ns = \"🎻⽻༽\"\n\nRefresher: ASCII vs unicode\nASCII (or ASCII-US) is an old standard which codes a character with 7 bits (or 8 bits for extended ASCII). This allows to code 128 different characters (256 for ex-ASCII).\nOnly a subset of these characters can be printed regularly.\n\nchr(44)\n\n\n# ASCII: \nfor i in range(32,127):\n    print( chr(i), end=' ')\n\nThe other characters include delete, newline and carriage return among others.\n\ns = 'This is\\na\\nmultiline string.' # note the newline character '\\n'\n\n\n# print(s)\nlen(s)\n\nSome antiquated platforms still use newline + carriage return at the end of each line. This is absolutely not required and causes incompatibilities.\n\ns2 = 'This is\\n\\ra\\n\\rmultiline string.' # note the newline character '\\n' and carriager return '\\r'\n\n\nprint(s2)\nprint(len(s2))\n\nUnicode contains a repertoire of over 137,000 characters with all ASCII characters as subcases\nTo type: copy/paste, ctrl+shift+hexadecimal, latex + tab\nVariable names aka identifiers can contain unicode characters with some restrictions: - they cannot start with a digit - they can’t contain special variables (‘!,#,@,%,$’ and other unicode specials ???) - they can contain underscore\n\n\n\nconcatenation\n\n'abc' + 'def'\n\n\n'abc'*3\n\n\n'abc' + 'abc' + 'abc'\n\n\n\n\n\n# strings can be accessed as arrays (0 based indexing)\ns = \"a b c\"\ns[0]\n\n\n# slice notation (  [min,max[ )\ns = \"a b c d\"\ns[2:5] # 0-based; 2 included, 5 excluded\n\n\n# substrings are easy to check\n\"a\" in s\n\n\n\"b c\" in \"a b c d\"\n\nIt is impossible to modify a substring.\n\n# but are immutable\ns = \"a b c\"\n#s[1] = 0 error\n\nInstead, one can replace a substring:\n\ns\n\n\ns.replace(' ', '🎻')\n\nOr use string interpolation\n\n# string interpolation (old school)\n\"ny name is {name}\".format(name=\"nobody\")\n\n\n\"calculation took {time}s\".format(time=10000)\n\n\n# number format can be tweaked\n\"I am {age:.0f} years old\".format(age=5.65)\n\n\n# formatted strings\nelapsed = 15914884.300292\n\nf\"computations took {elapsed/3600:.2f} hours\"\n\n\nname = \"arnaldur\"\n\n\n\"dasnfnaksujhn {name}\".format(name=\"whatever\")\n\n\n# basic string operations: str.split, str.join, etc...\n# fast regular expressions\n# more on it, with text processing lesson\n\n\nstr.split(\"me,you,others,them\",',')\n\n\nstr.join( \" | \",\n    str.split(\"me,you,others,them\",','),\n)\n\n\n\n\nThe example above used several special characters: \\n which corresponds to only one ascii character and {/} which disappears after the string formatting. If one desires to print these characters precisely one needs to escape them using \\ and { }.\n\nprint(\"This is a one \\\\nline string\")\nprint(\"This string keeps some {{curly}} brackets{}\".format('.'))\n\n\n\n\n(check help(str) or help?)\n\nlen() : length\nstrip() : removes characters at the ends\nsplit() : split strings into several substrings separated by separator\njoin() : opposite of split\n\n\n'others,'\n\n\n',me,others,'.strip(',')\n\n\ns.count(',')\n\n\nhelp(str)"
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#basic-types",
    "href": "tutorials/session_1/python_syntax.html#basic-types",
    "title": "Python: syntax review",
    "section": "",
    "text": "# integers and floats\n\n\n1\n\n\n1.0\n\n\n# conversion with int() and float()\nfloat( 1 )\n\n\nint(2.9) # floor\n\n\n# no difference between various types of floats (16 bits, 32 bits, 64 bits, ...)\n\n\ntype( 2.2**50 ) # this doesn't fit in 32 bits\n\n\n# usual operations + - *\nprint( 2 + 3 )\nprint( 9 -6 )\nprint( 3 / 2 )\nprint(2304310958*41324)\n\n\n# divisions / and //\nprint(3/4)\nprint(13//4)\n\n\n# exponentiation ** (not ^!)\n# (1.04)^10\n(1.04)**10\n\n\n# comparison operators: &gt;, &lt;, &gt;=, &lt;=, ==\n\nprint((1.0453432)*(0.96)  &gt; 1.001 )\n\nprint(1.001 &gt;= 1.001)\n\n\n# comparison operators can be chained:\nprint(0.2&lt;0.4&lt;0.5)\nprint(0.5&lt;=0.4&lt;=0.5) # equivalent to ((0.5&lt;=0.4) and(0.4&lt;=0.5))\n\n\n\n\nThere are only two booleans: True and False (note uppercase). None is a dummy type, which is used when no other type fits.\n\nprint( False )\nTrue\n\n\n(True, False, None)\n\nDouble equal sign tests for equality. Result should always be a boolean.\n\nTrue==False\n\nLogical operators are not, and and or:\n\n(True or False)\n\n\nnot (True or False)\n\n\n(1.3**1.04 &gt; 1.9) | (1000**1143&gt;1001**1142)\n\nOperators or and and can be replaced by | and & respectively. They are non-greedy, that is terms are not evaluated if the result of the comparison is already known.\n\nFalse and (print(\"Hello\"))\n\n\nprint( (print(\"Hello\")) and False )\n\n\n\n\n\n\nStrings are defined by enclosing characters either by ' (single quotes) or \" (double quote). Single quotes strings can contain double quotes strings and vice-versa.\n\n\"name\"\n\n\n'name'\n\n\n'I say \"hello\"'\n\n\n\"You can 'quote' me\"\n\nStrings spanning over sever lines can be defined with triple quotes (single or double).\n\ns = \"\"\"¿Qué es la vida? Un frenesí.\n¿Qué es la vida? Una ilusión,\nuna sombra, una ficción,\ny el mayor bien es pequeño;\nque toda la vida es sueño,\ny los sueños, sueños son.\n\"\"\"\n\nIt is also possible to use the newline character \\n.\n\n\"La vida es sueño,\\ny los sueños, sueños son.\"\n\n\nprint(\"La vida es sueño,\\ny los sueños, sueños son.\")\n\n\n\n\nStrings can contain any unicode character:\n\ns = \"🎻⽻༽\"\n\nRefresher: ASCII vs unicode\nASCII (or ASCII-US) is an old standard which codes a character with 7 bits (or 8 bits for extended ASCII). This allows to code 128 different characters (256 for ex-ASCII).\nOnly a subset of these characters can be printed regularly.\n\nchr(44)\n\n\n# ASCII: \nfor i in range(32,127):\n    print( chr(i), end=' ')\n\nThe other characters include delete, newline and carriage return among others.\n\ns = 'This is\\na\\nmultiline string.' # note the newline character '\\n'\n\n\n# print(s)\nlen(s)\n\nSome antiquated platforms still use newline + carriage return at the end of each line. This is absolutely not required and causes incompatibilities.\n\ns2 = 'This is\\n\\ra\\n\\rmultiline string.' # note the newline character '\\n' and carriager return '\\r'\n\n\nprint(s2)\nprint(len(s2))\n\nUnicode contains a repertoire of over 137,000 characters with all ASCII characters as subcases\nTo type: copy/paste, ctrl+shift+hexadecimal, latex + tab\nVariable names aka identifiers can contain unicode characters with some restrictions: - they cannot start with a digit - they can’t contain special variables (‘!,#,@,%,$’ and other unicode specials ???) - they can contain underscore\n\n\n\nconcatenation\n\n'abc' + 'def'\n\n\n'abc'*3\n\n\n'abc' + 'abc' + 'abc'\n\n\n\n\n\n# strings can be accessed as arrays (0 based indexing)\ns = \"a b c\"\ns[0]\n\n\n# slice notation (  [min,max[ )\ns = \"a b c d\"\ns[2:5] # 0-based; 2 included, 5 excluded\n\n\n# substrings are easy to check\n\"a\" in s\n\n\n\"b c\" in \"a b c d\"\n\nIt is impossible to modify a substring.\n\n# but are immutable\ns = \"a b c\"\n#s[1] = 0 error\n\nInstead, one can replace a substring:\n\ns\n\n\ns.replace(' ', '🎻')\n\nOr use string interpolation\n\n# string interpolation (old school)\n\"ny name is {name}\".format(name=\"nobody\")\n\n\n\"calculation took {time}s\".format(time=10000)\n\n\n# number format can be tweaked\n\"I am {age:.0f} years old\".format(age=5.65)\n\n\n# formatted strings\nelapsed = 15914884.300292\n\nf\"computations took {elapsed/3600:.2f} hours\"\n\n\nname = \"arnaldur\"\n\n\n\"dasnfnaksujhn {name}\".format(name=\"whatever\")\n\n\n# basic string operations: str.split, str.join, etc...\n# fast regular expressions\n# more on it, with text processing lesson\n\n\nstr.split(\"me,you,others,them\",',')\n\n\nstr.join( \" | \",\n    str.split(\"me,you,others,them\",','),\n)\n\n\n\n\nThe example above used several special characters: \\n which corresponds to only one ascii character and {/} which disappears after the string formatting. If one desires to print these characters precisely one needs to escape them using \\ and { }.\n\nprint(\"This is a one \\\\nline string\")\nprint(\"This string keeps some {{curly}} brackets{}\".format('.'))\n\n\n\n\n(check help(str) or help?)\n\nlen() : length\nstrip() : removes characters at the ends\nsplit() : split strings into several substrings separated by separator\njoin() : opposite of split\n\n\n'others,'\n\n\n',me,others,'.strip(',')\n\n\ns.count(',')\n\n\nhelp(str)"
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#assignment",
    "href": "tutorials/session_1/python_syntax.html#assignment",
    "title": "Python: syntax review",
    "section": "Assignment",
    "text": "Assignment\nAny object can be reused by assigning an identifier to it. This is done with assignment operator =.\n\na = 3\na\n\nNote that assignment operator = is different from comparison operator ==. Comparison operator is always True or False, while assignment operator has no value.\n\n(2==2) == True"
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#containers",
    "href": "tutorials/session_1/python_syntax.html#containers",
    "title": "Python: syntax review",
    "section": "Containers",
    "text": "Containers\nAny object created in Python is identified by a unique id. One can think of it approximately as its reference. Object collections, contain arbitrary other python objects, that is they contain references to them.\n\nid(s)\n\n\ntuples\n\nconstruction\n\n(1,2,\"a\" )\n\nSince tuples are immutable, two identical tuples, will always contain the same data.\n\nt1  = (2,23)\nt2  = (2,23)\n\n\n# can contain any data\nt = (1,2,3,4,5,6)\nt1 = (t, \"a\", (1,2))\nt2 = (0,)  # note trailing coma for one element tuple\nt3 = (t, \"a\", (1,2))\n\n\nt[0] = 78\n\nSince tuples never change, they can be compared by hash values (if the data they hold can be hashed). Two tuples are identical if they contain the same data.\nRemark: hash function is any function that can be used to map data of arbitrary size to data of a fixed size. It is such that the probability of two data points of having the same hash is very small even if they are close to each other.\n\nt3 == t1\n\n\nprint(hash(t3))\nprint(hash(t1))\n\n\nid(t3), id(t1)\n\n\n\naccess elements\n\n# elements are accessed with brackets (0-based)\nt[0]\n\n\n# slice notation works too (  [min,max[ )\nt[1:3]\n\n\n# repeat with *\n(3,2)*5\n\n\n(0)*5\n\n\n(0,)*5\n\n\nt2*5\n\n\n# concatenate with +\nt+t1+t2\n\n\n# test for membership\n\n(1 in t)\n\n\n\n\nlists\nlists are enclosed by brackets are mutable ordered collections of elements\n\nl = [1,\"a\",4,5]\n\n\nl[1]\n\n\nl[1:] # if we omit the upper-bound it goes until the last element\n\n\nl[:2]\n\n\n# lists are concatenated with +\nl[:2] + l[2:] == l\n\n\n# test for membership\n(5 in l)\n\n\n# lists can be extended inplace\nll = [1,2,3]\nll.extend([4,5]) # several elements\nll.append(6)\nll\n\nSince lists are mutable, it makes no sense to compute them by hash value (or the hash needs to be recomputed every time the values change).\n\nhash(ll)\n\nSorted lists can be created with sorted (if elements can be ranked)\n\nll = [4,3,5]\n\n\nsorted(ll)\n\n\nll\n\nIt is also possible to sort in place.\n\nll.sort()\nll\n\n\nsorted(ll) # creates a new list\nll.sort()  # does it in place\n\n\n# in python internals:    ll.sort() equivalent sort(ll)\n\n\n\nset\nSets are unordered collections of unique elements.\n\ns1 = set([1,2,3,3,4,3,4])\ns2 = set([3,4,4,6,8])\nprint(s1, s2)\nprint(s1.intersection(s2))\n\n\n{3,4} == {4,3}\n\n\n\ndictionaries\nDictionaries are ordered associative collections of elements. They store values associated to keys.\n\n# construction with curly brackets\nd = {'a':0, 'b':1}\n\n\nd\n\n\n# values can be recovered by indexing the dict with a key\nd['b']\n\n\nd = dict()\n# d['a'] = 42\n# d['b'] = 78\nd\n\n\nd['a'] = 42\n\n\nd['b']\n\nKeys can be any hashable value:\n\nd[('a','b')] = 100\n\n\nd[ ['a','b'] ] = 100 # that won't work\n\nNote: until python 3.5 dictionaries were not ordered. Now the are guaranteed to keep the insertion order"
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#control-flows",
    "href": "tutorials/session_1/python_syntax.html#control-flows",
    "title": "Python: syntax review",
    "section": "Control flows",
    "text": "Control flows\n\nConditional blocks\nConditional blocks are preceeded by if and followed by an indented block. Note that it is advised to indent a block by a fixed set of space (usually 4) rather than use tabs.\n\nif 'sun'&gt;'moon':\n    print('warm')\n\nThey can also be followed by elif and else statements:\n\nx = 0.5\nif (x&lt;0):\n    y = 0.0\nelif (x&lt;1.0):\n    y = x\nelse:\n    y = 1+(x-1)*0.5\n\nRemark that in the conditions, any variable can be used. The following evaluate to False: - 0 - empty collection\n\nif 0: print(\"I won't print this.\")\nif 1: print(\"Maybe I will.\")\nif {}: print(\"Sir, your dictionary is empty\")\nif \"\": print(\"Sir, there is no string to speak of.\")\n\n\n\nWhile\nThe content of the while loop is repeated as long as a certain condition is met. Don’t forget to change that condition or the loop might run forever.\n\npoint_made = False\ni = 0\nwhile not point_made:\n    print(\"A fanatic is one who can't change his mind and won't change the subject.\")\n    i += 1 # this is a quasi-synonym of i = i + 1\n    if i&gt;=20:\n          point_made = True\n\n\n\nLoops\n\n# while loops\ni = 0\nwhile i&lt;=10:\n    print(str(i)+\" \",  end='')\n    i+=1\n\n\n# for loop\nfor i in [0,1,2,3,4,5,6,7,8,9,10]:\n    print(str(i)+\" \",  end='')\n\n\n# this works for any kind of iterable\n# for loop\nfor i in (0,1,2,3,4,5,6,7,8,9,10):\n    print(str(i)+\" \",  end='')\n\n\n# including range generator (note last value)\nfor i in range(11): \n    print(str(i)+\" \",  end='')\n\n\nrange(11)\n\n\n# one can also enumerate elements\ncountries = (\"france\", \"uk\", \"germany\")\nfor i,c in enumerate(countries): \n    print(f\"{i}: {c}\")\n\n\ns = set(c)\n\n\n# conditional blocks are constructed with if, elif, else\nfor i,c in enumerate(countries):\n    if len(set(c).intersection(set(\"brexit\"))):\n        print(c)\n    else:\n        print(c + \" 😢\")\n\nIt is possible to iterate over any iterable. This is true for a list or a generator:\n\nfor i in range(10): # range(10) is a generator\n    print(i)\n\n\nfor i in [0,1,2,3,4,5,6,7,8,9]:\n    print(i)\n\nWe can iterate of dictionary keys or values\n\nd = {1:2, 3:'i'}\nfor k in d.keys():\n    print(k, d[k])\nfor k in d.values():\n    print(k)\n\nor both at the same time:\n\nfor t in d.items():\n    print(t)\n\n# look at automatic unpacking\nfor (k,v) in d.items():\n    print(f\"key: {k}, value: {v}\")\n\n\n\nComprehension and generators\nThere is an easy syntax to construct lists/tuples/dicts: comprehension. Syntax is remminiscent of a for loop.\n\n[i**2 for i in range(10)]\n\n\nset(i-(i//2*2) for i in range(10))\n\n\n{i: i**2 for i in range(10)}\n\nComprehension can be combined with conditions:\n\n[i**2 for i in range(10) if i//3&gt;2]\n\nBehind the comprehension syntax, there is a special object called generator. Its role is to supply objects one by one like any other iterable.\n\n# note the bracket\ngen = (i**2 for i in range(10))\ngen # does nothing\n\n\ngen = (i**2 for i in range(10))\nfor e in gen:\n    print(e)\n\n\ngen = (i**2 for i in range(10))\nprint([e for e in gen])\n\nThere is a shortcut to converte a generator into a list: it’s called unpacking:\n\ngen = (i**2 for i in range(10))\n[*gen]"
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#functions",
    "href": "tutorials/session_1/python_syntax.html#functions",
    "title": "Python: syntax review",
    "section": "Functions",
    "text": "Functions\nWrong approach\n\na1 = 34\nb1 = (1+a1*a1)\nc1 = (a1+b1*b1)\n\na2 = 36\nb2 = (1+a2*a2)\nc2 = (a2+b2*b2)\n\nprint(c1,c2)\n\nBetter approach\n\ndef calc(a):\n    b = 1+a*a\n    c = a+b*b\n    return c\n\n(calc(34), calc(36))\n\nit is equivalent to replace the content of the function by:\n\na = 32\n_a = a          # def calc(a):\n_b = 1+_a*_a    #    b = 1+a*a\n_c = _a+_b*_b   #    c = a+b*b\nres = _c        #    return c\n\nNote that variable names within the function have different names. This is to avoid name conflicts as in:\n\ny = 1\ndef f(x):\n    y = x**2\n    return y+1\ndef g(x):\n    y = x**2+0.1\n    return y+1\nr1 = f(1.4)\nr2 = g(1.4)\nr3 = y\n(r1,r2,r3)\n\n\nl = ['france', 'germany']\ndef fun(i):\n    print(f\"Country: {l[i]}\")\nfun(0)\n\n\nl = ['france', 'germany']\ndef fun(i):\n    l = ['usa', 'japan']\n    l.append('spain')\n    print(f\"Country: {l[i]}\")\nfun(0)\n\n\nl\n\nIn the preceding code block, value of y has not been changed by calling the two functions. Check pythontutor.\n\nCalling conventions\nFunction definitions start with def and a colon indentation. Value are returned by return keyword. Otherwise the return value is None. Functions can have several arguments: def f(x,y) but always one return argument. It is however to return a tuple, and “unpack” it.\n\ndef f(x,y):\n    z1 = x+y\n    z2 = x-y\n    return (z1,z2)      # here brackets are optional:  `return z1,z2` works too\n\nres = f(0.1, 0.2)\nt1, t2 = f(0.2, 0.2)     # t1,t2=res works too\n\n\nres\n\nNamed arguments can be passed in any order and receive default values.\n\ndef problem(why=\"The moon shines.\", what=\"Curiosity killed the cat.\", where=\"Paris\"):\n    print(f\"Is it because {why.lower().strip('.')} that {what.lower().strip('.')}, in {where.strip('.')}?\")\n\n\nproblem(where='Paris')\n\n\nproblem(where=\"ESCP\", why=\"Square root of two is irrational\", what=\"Some regressions never work.\")\n\nPositional arguments and keyword arguments can be combined\n\ndef f(x, y, β=0.9, γ=4.0, δ=0.1):\n    return x*β+y**γ*δ\n\n\nf(0.1, 0.2)\n\n\n\nDocstrings\nFunctions are documented with a special string. Documentation It must follow the function signature immediately and explain what arguments are expected and what the function does\n\ndef f(x, y, β=0.9, γ=4.0, δ=0.1):   # kjhkugku\n    \"\"\"Compute the model residuals\n    \n    Parameters\n    ----------\n    x: (float) marginal propensity to do complicated stuff\n    y: (float) inverse of the elasticity of bifractional risk-neutral substitution\n    β: (float) time discount (default 0.9)\n    γ: (float) time discount (default 4.0)\n    δ: (float) time discount (default 0.1)\n    \n    Result\n    ------\n    res: beta-Hadamard measure of cohesiveness\n    \n    \"\"\"\n    res = x*β+y**γ*δ\n    return res\n\nRemark: Python 3.6 has introduced type indication for functions. They are useful as an element of indication and potentially for type checking. We do not cover them in this tutorial but this is what they look like:\n\ndef f(a: int, b:int)-&gt;int:\n    if a&lt;=1:\n        return 1\n    else:\n        return f(a-1,b) + f(a-2,b)*b\n\n\n\n\nPacking and unpacking\nA common case is when one wants to pass the elements of an iterable as positional argument and/or the elements of a dictionary as keyword arguments. This is espacially the case, when one wants to determine functions that act on a given calibration. Without unpacking all arguments would need to be passed separately.\n\nv = (0.1, 0.2)\np = dict(β=0.9, γ=4.0, δ=0.1)\n\nf(v[0], v[1], β=p['β'], γ=p['γ'], δ=p['δ'])\n\nThere is a special syntax for that: * unpacks positional arguments and ** unpacks keyword arguments. Here is an example:\n\nf(*v, **p)\n\nThe same characters * and ** can actually be used for the reverse operation, that is packing. This is useful to determine functions of a variable number of arguments.\n\ndef fun(**p):\n    β = p['β']\n    return β+1\nfun(β=1.0)\nfun(β=1.0, γ=2.0) # γ is just ignored\n\nInside the function, unpacked objects are lists and dictionaries respectively.\n\ndef fun(*args, **kwargs):\n    print(f\"Positional arguments: {len(args)}\")\n    for a in args:\n        print(f\"- {a}\")\n    print(f\"Keyword arguments: {len(args)}\")\n    for key,value in kwargs.items():\n        print(f\"- {key}: {value}\")\n\n\nfun(0.1, 0.2, a=2, b=3, c=4)\n\n\n\nFunctions are first class objects\nThis means they can be assigned and passed around.\n\ndef f(x): return 2*x*(1-x)\ng = f # now `g` and `f` point to the same function\ng(0.4)\n\n\ndef sumsfun(l, f):\n    return [f(e) for e in l]\n\n\nsumsfun([0.0, 0.1, 0.2], f)\n\n\ndef compute_recursive_series(x0, fun, T=50):\n    a = [x0]\n    for t in range(T):\n        x0 = a[-1]\n        x = fun(x0)\n        a.append(x)\n    return a\n\ncompute_recursive_series(0.3, f, T=5)\n\nThere is another syntax to define a function, without giving it a name first: lambda functions. It is useful when passing a function as argument.\n\nsorted(range(6), key=lambda x: (-2)**x)\n\nLambda functions are also useful to reduce quickly the number of arguments of a function (aka curryfication)\n\ndef logistic(μ,x): return μ*x*(1-x)\n# def chaotic(x): return logistic(3.7, x)\n# def convergent(x): return logistic(2.5, x)\nchaotic = lambda x: logistic(3.7, x)\nconvergent = lambda x: logistic(2.5, x)\n\n\nl = [compute_recursive_series(0.3,fun, T=20) for fun in [convergent, chaotic]]\n[*zip(*l)]\n\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\ntab = np.array(l)\nplt.plot(tab[0,:-1],tab[0,1:])\ntab = np.array(l)\nplt.plot(tab[1,:-1],tab[1,1:])\nplt.plot(np.linspace(0,1),np.linspace(0,1))\nplt.xlabel(\"$x_n$\")\nplt.ylabel(\"$x_{n+1}$\")\nplt.grid()\n\n\n\nFunctions pass arguments by reference\nMost of the time, variable affectation just create a reference.\n\na = [1,2,3]\nb = a\na[1] = 0\n(a, b)\n\nTo get a copy instead, one needs to specify it explicitly.\n\nimport copy\na = [1,2,3]\nb = copy.copy(a)\na[1] = 0\n(a, b)\n\nNot that copy follows only one level of references. Use deepcopy for more safety.\n\na0 = ['a','b']\na = [a0, 1, 2]\nb = copy.copy(a)\na[0][0] = 'ξ'\na, b\n\n\na0 = ['a','b']\na = [a0, 1, 2]\nb = copy.deepcopy(a)\na[0][0] = 'ξ'\na, b\n\nArguments in a function are references towards the original object. No data is copied. It is then easy to construct functions with side-effects.\n\ndef append_inplace(l1, obs):\n    l1.append(obs)\n    return l1\nl1, obs = ([1,2,3], 1.5)\nl2 = append_inplace(l1,obs)\nprint(l2, l1)\n# note that l1 and l2 point to the same object\nl1[0] = 'hey'\nprint(l2, l1)\n\nThis behaviour might feel unnatural but is very sensible. For instance if the argument is a database of several gigabytes and one wants to write a function which will modify a few of its elements, it is not reasonable to copy the db in full."
  },
  {
    "objectID": "tutorials/session_1/python_syntax.html#objects",
    "href": "tutorials/session_1/python_syntax.html#objects",
    "title": "Python: syntax review",
    "section": "Objects",
    "text": "Objects\nObjects ?\n\ncan be passed around / referred too\nhave properties (data) and methods (functions) attached to them\ninherit properties/methods from other objects\n\nObjects are defined by a class definition. By convention, classes names start with uppercase . To create an object, one calls the class name, possibly with additional arguments.\n\nclass Dog:\n    name = \"May\" # class property\n\nd1 = Dog()\nd2 = Dog()\n\nprint(f\"Class: d1-&gt;{type(d1)}, d2-&gt;{type(d2)}\")\nprint(f\"Instance address: d2-&gt;{d1},{d2}\")\n\nNow, d1 and d2 are two different instances of the same class Dog. Since properties are mutable, instances can have different data attached to it.\n\nd1.name = \"Boris\"\nprint([e.name for e in [d1,d2]])\n\nMethods are functions attached to a class / an instance. Their first argument is always an instance. The first argument can be used to acess data held by the instance.\n\nclass Dog:\n    name = None # default value\n    def bark(self):\n        print(\"Wouf\")\n    def converse(self):\n        n = self.name\n        print(f\"Hi, my name is {n}. I'm committed to a strong and stable government.\")\n        \nd = Dog()\nd.bark()   # bark(d)\nd.converse()\n\n\nConstructor\nThere is also a special method __init__ called the constructor. When an object is created, it is called on the instance. This is useful in order to initialize parameters of the instance.\n\nclass Calibration:\n    \n    def __init__(self, x=0.1, y=0.1, β=0.0):\n        if not (β&gt;0) and (β&lt;1):\n            raise Exception(\"Incorrect calibration\"})\n        self.x = x\n        self.y = y\n        self.β = β\n\n\nc1 = Calibration()\nc2 = Calibration(x=3, y=4)\n\nTwo instances of the same class have the same method, but can hold different data. This can change the behaviour of these methods.\n\n# class Dog:\n    \n#     state = 'ok'\n    \n#     def bark(self):\n#         if self.state == 'ok':\n#             print(\"Wouf!\")\n#         else:\n#             print(\"Ahouuu!\")\n        \n# d = Dog()\n# d1 = Dog()\n# d1.state = 'hungry'\n\n# d.bark()\n# d1.bark()\n\nTo write a function which will manipulate properties and methods of an object, it is not required to know its type in advance. The function will succeed as long as the required method exist, fail other wise. This is called “Duck Typing”: if it walks like a duck, it must be a duck…\n\nclass Duck:\n    def walk(self): print(\"/-\\_/-\\_/\")\n        \nclass Dog:\n    def walk(self): print(\"/-\\_/*\\_/\")\n    def bark(self): print(\"Wouf\")\n\n\nanimals = [C() for C in (Duck,Dog)]\ndef go_in_the_park(animal):\n    for i in range(3): animal.walk()\nfor a in animals:\n    go_in_the_park(a)\n\n\nInheritance\nThe whole point of classes, is that one can construct hierarchies of classes to avoid redefining the same methods many times. This is done by using inheritance.\n\nclass Animal:\n    \n    def run(self): print(\"👣\"*4)\n\nclass Dog(Animal):\n    def bark(self): print(\"Wouf\")\n        \nclass Rabbit(Animal):\n    def run(self):\n        super().run() ; print( \"🐇\" )\n\n\nAnimal().run()\ndog = Dog()\ndog.run()\ndog.bark()\nRabbit().run()\n\nIn the above example, the Dog class inherits from inherits the method run from the Animal class: it doesn’t need to be redefined again. Essentially, when run(dog) is called, since the method is not defined for a dog, python looks for the first ancestor of dog and applies the method of the ancestor.\n\n\nSpecial methods\nBy conventions methods starting with double lowercase __ are hidden. They don’t appear in tab completion. Several special methods can be reimplemented that way.\n\nclass Calibration:\n    \n    def __init__(self, x=0.1, y=0.1, β=0.1):\n        if not (β&gt;0) and (β&lt;1):\n            raise Exception(\"Incorrect calibration\")\n        self.x = x\n        self.y = y\n        self.β = β\n    \n    def __str__(self):\n        return f\"Calibration(x={self.x},y={self.y}, β={self.β})\"\n\n\nstr(Calibration() )\n\n\n\ncomplement\nPython is not 100% object oriented. - some objects cannot be subclassed - basic types behave sometimes funny (interning strings)\nmindfuck: Something that destabilizes, confuses, or manipulates a person’s mind.\n\na = 'a'*4192\nb = 'a'*4192\na is b\n\n\na = 'a'*512\nb = 'a'*512\na is b"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html",
    "href": "tutorials/session_1/python_fundamentals/basics.html",
    "title": "Basics",
    "section": "",
    "text": "Prerequisites\n\nGetting Started\n\nOutcomes\n\nProgramming concepts\n\nUnderstand variable assignment\n\nKnow what a function is and how to figure out what it does\n\nBe able to use tab completion\n\n\nNumbers in Python\n\nUnderstand how Python represents numbers\n\nKnow the distinction between int and float\n\nBe familiar with various binary operators for numbers\n\nIntroduction to the math library\n\n\nText (strings) in Python\n\nUnderstand what a string is and when it is useful\n\nLearn some of the methods associated with strings\n\nCombining strings and output\n\n\nTrue and False (booleans) in Python\n\nUnderstand what a boolean is\n\nBecome familiar with all binary operators that return booleans\n\n\n\n\nWe are ready to begin writing code!\nIn this section, we will teach you some basic concepts of programming and where to search for help.\n\n\nThe first thing we will learn is the idea of variable assignment.\nVariable assignment associates a value to a variable.\nBelow, we assign the value “Hello World” to the variable x\n\nx = \"Hello World\"\nprint(x)\n\nHello World\n\n\nOnce we have assigned a value to a variable, Python will remember this variable as long as the current session of Python is still running. \\(\\sqrt{x^ 2+1}\\) Notice how writing x into the prompt below outputs the value “Hello World”.\n\nx\n\nHowever, Python returns an error if we ask it about variables that have not yet been created.\n\n# uncomment (delete the # and the space) the line below and run\n# y\n\nIt is also useful to understand the order in which operations happen.\nFirst, the right side of the equal sign is computed.\nThen, that computed value is stored as the variable to the left of the equal sign.\n\n\n\nSee exercise 1 in the exercise list.\nKeep in mind that the variable binds a name to something stored in memory.\nThe name can even be bound to a value of a completely different type.\n\nx = 2\nprint(x)\nx = \"something else\"\nprint(x)\n\n\n\n\nComments are short notes that you leave for yourself and for others who read your code.\nThey should be used to explain what the code does.\nA comment is made with the #. Python ignores everything in a line that follows a #.\nLet’s practice making some comments.\n\ni = 1  # Assign the value 1 to variable i\nj = 2  # Assign the value 2 to variable j\n\n# We add i and j below this line\ni + j\n\n\n\n\n\nFunctions are processes that take an input (or inputs) and produce an output.\nIf we had a function called f that took two arguments x and y, we would write f(x, y) to use the function.\nFor example, the function print simply prints whatever it is given. Recall the variable we created called x.\n\nprint(x)\n\n\n\nWe can figure out what a function does by asking for help.\nIn Jupyter notebooks, this is done by placing a ? after the function name (without using parenthesis) and evaluating the cell.\nFor example, we can ask for help on the print function by writing print?.\nDepending on how you launched Jupyter, this will either launch\n\nJupyterLab: display the help in text below the cell.\n\nClassic Jupyter Notebooks: display a new panel at the bottom of your screen. You can exit this panel by hitting the escape key or clicking the x at the top right of the panel.\n\n\n# print? # remove the comment and &lt;Shift-Enter&gt;\n\n\n\n\nSee exercise 2 in the exercise list.\nJupyterLab also has a “Contextual Help” (previously called “Inspector”) window. To use,\n\nGo to the Commands and choose Contextual Help (or Inspector), or select &lt;Ctrl-I&gt; (&lt;Cmd-I&gt; for OSX users).\n\nDrag the new inspector pain to dock in the screen next to your code.\n\nThen, type print or any other function into a cell and see the help.\n\n\n# len? # remove the comment and &lt;Shift-Enter&gt;\n\nWe will learn much more about functions, including how to write our own, in a future lecture.\n\n\n\n\nEverything in Python is an object.\nObjects are “things” that contain 1) data and 2) functions that can operate on the data.\nSometimes we refer to the functions inside an object as methods.\nWe can investigate what data is inside an object and which methods it supports by typing . after that particular variable, then hitting TAB.\nIt should then list data and method names to the right of the variable name like this:\n\n\n\nhttps://datascience.quantecon.org/_static/introspection.png\n\n\nYou can scroll through this list by using the up and down arrows.\nWe often refer to this as “tab completion” or “introspection”.\nLet’s do this together below. Keep going down until you find the method split.\n\n# Type a period after `x` and then press TAB.\nx\n\nOnce you have found the method split, you can use the method by adding parenthesis after it.\nLet’s call the split method, which doesn’t have any other required parameters. (Quiz: how would we check that?)\n\nx.split()\n\nWe often want to identify what kind of object some value is– called its “type”.\nA “type” is an abstraction which defines a set of behavior for any “instance” of that type i.e. 2.0 and 3.0 are instances of float, where float has a set of particular common behaviors.\nIn particular, the type determines:\n\nthe available data for any “instance” of the type (where each instance may have different values of the data).\n\nthe methods that can be applied on the object and its data.\n\nWe can figure this out by using the type function.\nThe type function takes a single argument and outputs the type of that argument.\n\ntype(3)\n\n\ntype(\"Hello World\")\n\n\ntype([1, 2, 3])\n\nWe will learn more about each of these types (and others!) and how to use them soon, so stay tuned!\n\n\n\n\nPython takes a modular approach to tools.\nBy this we mean that sets of related tools are bundled together into packages. (You may also hear the term modules to describe the same thing.)\nFor example:\n\npandas is a package that implements the tools necessary to do scalable data analysis.\n\nmatplotlib is a package that implements visualization tools.\n\nrequests and urllib are packages that allow Python to interface with the internet.\n\nAs we move further into the class, being able to access these packages will become very important.\nWe can bring a package’s functionality into our current Python session by writing\n\nimport package\n\nOnce we have done this, any function or object from that package can be accessed by using package.name.\nHere’s an example.\n\nimport sys   # for dealing with your computer's system\nsys.version  # information about the Python version in use\n\n\n\n\nSee exercise 3 in the exercise list.\n\n\nSome packages have long names (see matplotlib, for example) which makes accessing the package functionality somewhat inconvenient.\nTo ease this burden, Python allows us to give aliases or “nicknames” to packages.\nFor example we can write:\n\nimport package as p\n\nThis statement allows us to access the packages functionality as p.function_name rather than package.function_name.\nSome common aliases for packages are\n\nimport pandas as pd\n\nimport numpy as np\n\nimport matplotlib as mpl\n\nimport datetime as dt\n\nWhile you can choose any name for an alias, we suggest that you stick to the common ones.\nYou will learn what these common ones are over time.\n\n\n\nSee exercise 4 in the exercise list.\n\n\n\n\nA common saying in the software engineering world is:\n\nAlways code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live. Code for readability.\n\nThis might be a dramatic take, but the most important feature of your code after correctness is readability.\nWe encourage you to do everything in your power to make your code as readable as possible.\nHere are some suggestions for how to do so:\n\nComment frequently. Leaving short notes not only will help others who use your code, but will also help you interpret your code after some time has passed.\n\nAnytime you use a comma, place a space immediately afterwards.\n\nWhitespace is your friend. Don’t write line after line of code – use blank lines to break it up.\n\nDon’t let your lines run too long. Some people reading your code will be on a laptop, so you want to ensure that they don’t need to scroll horizontally and right to read your code. We recommend no more than 80 characters per line.\n\n\n\n\nPython has two types of numbers.\n\nInteger (int): These can only take the values of the integers i.e. $ {, -2, -1, 0, 1, 2, } $\n\nFloating Point Number (float): Think of these as any real number such as $ 1.0 $, $ 3.1415 $, or $ -100.022358923223 $…\n\nThe easiest way to differentiate these types of numbers is to find a decimal place after the number.\nA float will have a decimal place, but an integer will not.\nBelow, we assign integers to the variables xi and zi and assign floating point numbers to the variables xf and zf.\n\nxi = 1\nxf = 1.0\nzi = 123\nzf = 1230.5  # Notice -- There are no commas!\nzf2 = 1_230.5  # If needed, we use `_` to separate numbers for readability\n\n\n\n\nSee exercise 5 in the exercise list.\n\n\nYou can use Python to perform mathematical calculations.\n\na = 4\nb = 2\n\nprint(\"a + b is\", a + b)\nprint(\"a - b is\", a - b)\nprint(\"a * b is\", a * b)\nprint(\"a / b is\", a / b)\nprint(\"a ** b is\", a**b)\nprint(\"a ^ b is\", a^b)\n\nYou likely could have guessed all except the last two.\nPython uses **, not ^, for exponentiation (raising a number to a power)!\nNotice also that above +, - and ** all returned an integer type, but / converted the result to a float.\nWhen possible, operations between integers return an integer type.\nAll operations involving a float will result in a float.\n\na = 4\nb = 2.0\n\nprint(\"a + b is\", a + b)\nprint(\"a - b is\", a - b)\nprint(\"a * b is\", a * b)\nprint(\"a / b is\", a / b)\nprint(\"a ** b is\", a**b)\n\nWe can also chain together operations.\nWhen doing this, Python follows the standard order of operations — parenthesis, exponents, multiplication and division, followed by addition and subtraction.\nFor example,\n\nx = 2.0\ny = 3.0\nz1 = x + y * x\nz2 = (x + y) * x\n\nWhat do you think z1 is?\nHow about z2?\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nWe often want to use other math functions on our numbers. Let’s try to calculate sin(2.5).\n\nsin(2.5)\n\nAs seen above, Python complains that sin isn’t defined.\nThe problem here is that the sin function – as well as many other standard math functions – are contained in the math package.\nWe must begin by importing the math package.\n\nimport math\n\nNow, we can use math.[TAB] to see what functions are available to us.\n\n# uncomment, add a period (`.`) and pres TAB\n# math\n\n\n# found math.sin!\nmath.sin(2.5)\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\nYou are less likely to run into the following operators, but understanding that they exist is useful.\nFor two numbers assigned to the variables x and y,\n\nFloor division: x // y\n\nModulus division: x % y\n\nRemember when you first learned how to do division and you were asked to talk about the quotient and the remainder?\nThat’s what these operators correspond to…\nFloor division returns the number of times the divisor goes into the dividend (the quotient) and modulus division returns the remainder.\nAn example would be 37 divided by 7:\n\nFloor division would return 5 (7 * 5 = 35)\n\nModulus division would return 2 (2 + 35 = 37)\n\nTry it!\n\n37 // 7\n\n\n37 % 7\n\n\n\n\n\n\nTextual information is stored in a data type called a string.\nTo denote that you would like something to be stored as a string, you place it inside of quotation marks.\nFor example,\n\n\"this is a string\"  # Notice the quotation marks\n'this is a string'  # Notice the quotation marks\nthis is not a string  # No quotation marks\n\nYou can use either \" or ' to create a string. Just make sure that you start and end the string with the same one!\nNotice that if we ask Python to tell us the type of a string, it abbreviates its answer to str.\n\ntype(\"this is a string\")\n\n\n\n\nSee exercise 8 in the exercise list.\n\n\nSome of the arithmetic operators we saw in the numbers lecture also work on strings:\n\nPut two strings together: x + y.\n\nRepeat the string x a total of n times: n * x (or x * n).\n\n\nx = \"Hello\"\ny = \"World\"\n\n\nx + y\n\n\n3 * x\n\nWhat happens if we try * with two strings, or - or /?\nThe best way to find out is to try it!\n\na = \"1\"\nb = \"2\"\na * b\n\n\na - b\n\n\n\n\nSee exercise 9 in the exercise list.\n\n\n\nWe can use many methods to manipulate strings.\nWe will not be able to cover all of them here, but let’s take a look at some of the most useful ones.\n\nx\n\n\nx.lower()  # Makes all letters lower case\n\n\nx.upper()  # Makes all letters upper case\n\n\nx.count(\"l\")  # Counts number of a particular string\n\n\nx.count(\"ll\")\n\n\n\n\nSee exercise 10 in the exercise list.\n\n\n\nSee exercise 11 in the exercise list.\n\n\n\nSometimes we’d like to reuse some portion of a string repeatedly, but still make some relatively small changes at each usage.\nWe can do this with string formatting, which done by using {} as a placeholder where we’d like to change the string, with a variable name or expression.\nLet’s look at an example.\n\ncountry = \"Vietnam\"\nGDP = 223.9\nyear = 2017\nmy_string = f\"{country} had ${GDP} billion GDP in {year}\"\nprint(my_string)\n\nRather than just substituting a variable name, you can use a calculation or expression.\n\nprint(f\"{5}**2 = {5**2}\")\n\nOr, using our previous example\n\nmy_string = f\"{country} had ${GDP * 1_000_000} GDP in {year}\"\nprint(my_string)\n\nIn these cases, the f in front of the string causes Python interpolate any valid expression within the {} braces.\n\n\n\nSee exercise 12 in the exercise list.\nAlternatively, to reuse a formatted string, you can call the format method (noting that you do not put f in front).\n\ngdp_string = \"{country} had ${GDP} billion in {year}\"\n\ngdp_string.format(country = \"Vietnam\", GDP = 223.9, year = 2017)\n\n\n\n\nSee exercise 13 in the exercise list.\n\n\n\nSee exercise 14 in the exercise list.\nFor more information on what you can do with string formatting (there is a lot that can be done…), see the official Python documentation on the subject.\n\n\n\n\nA boolean is a type that denotes true or false.\nAs you will soon see in the control flow chapter, using boolean values allows you to perform or skip operations depending on whether or not a condition is met.\nLet’s start by creating some booleans and looking at them.\n\nx = True\ny = False\n\ntype(x)\n\n\nx\n\n\ny\n\n\n\nRather than directly write True or False, you will usually create booleans by making a comparison.\nFor example, you might want to evaluate whether the price of a particular asset is greater than or less than some price.\nFor two variables x and y, we can do the following comparisons:\n\nGreater than: x &gt; y\n\nLess than: x &lt; y\n\nEqual to: ==\n\nGreater than or equal to: x &gt;= y\n\nLess than or equal to: x &lt;= y\n\nWe demonstrate these below.\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\n\n\n\nOccasionally, determining whether a statement is “not true” or “not false” is more convenient than simply “true” or “false”.\nThis is known as negating a statement.\nIn Python, we can negate a boolean using the word not.\n\nnot False\n\n\nnot True\n\n\n\n\nSometimes we need to evaluate multiple comparisons at once.\nThis is done by using the words and and or.\nHowever, these are the “mathematical” ands and ors – so they don’t carry the same meaning as you’d use them in colloquial English.\n\na and b is true only when both a and b are true.\n\na or b is true whenever at least one of a or b is true.\n\nFor example\n\nThe statement “I will accept the new job if the salary is higher and I receive more vacation days” means that you would only accept the new job if you both receive a higher salary and are given more vacation days.\n\nThe statement “I will accept the new job if the salary is higher or I receive more vacation days” means that you would accept the job if\n\nthey raised your salary, (2) you are given more vacation days, or\nthey raise your salary and give you more vacation days.\n\n\nLet’s see some examples.\n\nTrue and False\n\n\nTrue and True\n\n\nTrue or False\n\n\nFalse or False\n\n\n# Can chain multiple comparisons together.\nTrue and (False or True)\n\n\n\n\nSee exercise 15 in the exercise list.\n\n\n\nWe have seen how we can use the words and and or to process two booleans at a time.\nThe functions all and any allow us to process an unlimited number of booleans at once.\nall(bools) will return True if and only if all the booleans in bools is True and returns False otherwise.\nany(bools) returns True whenever one or more of bools is True.\nThe exercise below will give you a chance to practice.\n\n\n\nSee exercise 16 in the exercise list.\n\n\n\n\n\n\n\nWhat do you think the value of z is after running the code below?\n\nz = 3\nz = z + 4\nprint(\"z is\", z)\n\n(back to text)\n\n\n\nRead about out what the len function does (by writing len?).\nWhat will it produce if we give it the variable x?\nCheck whether you were right by running the code len(x).\n(back to text)\n\n\n\nWe can use our introspection skills to investigate a package’s contents.\nIn the cell below, use tab completion to find a function from the time module that will display the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the function you found) to see information about that function and then call the function.\nLook for something to do with the word local\n\nimport time\n# your code here -- notice the comment!\n\n(back to text)\n\n\n\nTry running import time as t in the cell below, then see if you can call the function you identified above.\nDoes it work?\n(back to text)\n\n\n\nCreate the following variables:\n\nD: A floating point number with the value 10,000\n\nr: A floating point number with value 0.025\n\nT: An integer with value 30\n\nWe will use them in a later exercise.\n\n# your code here!\n\n(back to text)\n\n\n\nRemember the variables we created earlier?\nLet’s compute the present discounted value of a payment ($ D $) made in $ T $ years assuming an interest rate of 2.5%. Save this value to a new variable called PDV and print your output.\nThe formula is\n\\[\n\\text{PDV} = \\frac{D}{(1 + r)^T}\n\\]\n\n# your code here\n\n(back to text)\n\n\n\nVerify the “trick” where the percent difference ($ \\()\nbetween two numbers close to 1 can be well approximated by the difference\nbetween the log of the two numbers (\\) (x) - (y) $).\nUse the numbers x and y below.\nyou will want to use the math.log function\n\nx = 1.05\ny = 1.02\n\n(back to text)\n\n\n\nThe code below is invalid Python code\n\nx = 'What's wrong with this string'\n\nCan you fix it?\nTry creating a code cell below and testing things out until you find a solution.\n(back to text)\n\n\n\nUsing the variables x and y, how could you create the sentence Hello World?\nThink about how to represent a space as a string.\n(back to text)\n\n\n\nOne of our favorite (and most frequently used) string methods is replace.\nIt substitutes all occurrences of a particular pattern with a different pattern.\nFor the variable test below, use the replace method to change the c to a d.\nType test.replace? to get some help for how to use the method replace.\n\ntest = \"abc\"\n\n(back to text)\n\n\n\nSuppose you are working with price data and encounter the value \"\\$6.50\".\nWe recognize this as being a number representing the quantity “six dollars and fifty cents.”\nHowever, Python interprets the value as the string \"\\$6.50\". (Quiz: why is this a problem? Think about the examples above.)\nIn this exercise, your task is to convert the variable price below into a number.\nOnce the string is in a suitable format, you can call write float(clean_price) to make it a number.\n\nprice = \"$6.50\"\n\n(back to text)\n\n\n\nLookup a country in World Bank database, and format a string showing the growth rate of GDP over the last 2 years.\n(back to text)\n\n\n\nInstead of hard-coding the values above, try to use the country, GDP and year variables you previously defined.\n(back to text)\n\n\n\nCreate a new string and use formatting to produce each of the following statements\n\n“The 1st quarter revenue was 110M”\n\n“The 2nd quarter revenue was 95M”\n\n“The 3rd quarter revenue was 100M”\n\n“The 4th quarter revenue was 130M”\n\n(back to text)\n\n\n\nWithout typing the commands, determine whether the following statements are true or false.\nOnce you have evaluated whether the command is True or False, run the code in Python.\n\nx = 2\ny = 2\nz = 4\n\n# Statement 1\nx &gt; z\n\n# Statement 1\nx == y\n\n# Statement 3\n(x &lt; y) and (x &gt; y)\n\n# Statement 4\n(x &lt; y) or (x &gt; y)\n\n# Statement 5\n(x &lt;= y) and (x &gt;= y)\n\n# Statement 6\nTrue and ((x &lt; z) or (x &lt; y))\n\n\n# code here!\n\n(back to text)\n\n\n\nFor each of the code cells below, think carefully about what you expect to be returned before evaluating the cell.\nThen evaluate the cell to check your intuitions.\nNOTE: For now, do not worry about what the [ and ] mean – they allow us to create lists which we will learn about in an upcoming lecture.\n\nall([True, True, True])\n\n\nall([False, True, False])\n\n\nall([False, False, False])\n\n\nany([True, True, True])\n\n\nany([False, True, False])\n\n\nany([False, False, False])\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#first-steps",
    "href": "tutorials/session_1/python_fundamentals/basics.html#first-steps",
    "title": "Basics",
    "section": "",
    "text": "We are ready to begin writing code!\nIn this section, we will teach you some basic concepts of programming and where to search for help.\n\n\nThe first thing we will learn is the idea of variable assignment.\nVariable assignment associates a value to a variable.\nBelow, we assign the value “Hello World” to the variable x\n\nx = \"Hello World\"\nprint(x)\n\nHello World\n\n\nOnce we have assigned a value to a variable, Python will remember this variable as long as the current session of Python is still running. \\(\\sqrt{x^ 2+1}\\) Notice how writing x into the prompt below outputs the value “Hello World”.\n\nx\n\nHowever, Python returns an error if we ask it about variables that have not yet been created.\n\n# uncomment (delete the # and the space) the line below and run\n# y\n\nIt is also useful to understand the order in which operations happen.\nFirst, the right side of the equal sign is computed.\nThen, that computed value is stored as the variable to the left of the equal sign.\n\n\n\nSee exercise 1 in the exercise list.\nKeep in mind that the variable binds a name to something stored in memory.\nThe name can even be bound to a value of a completely different type.\n\nx = 2\nprint(x)\nx = \"something else\"\nprint(x)\n\n\n\n\nComments are short notes that you leave for yourself and for others who read your code.\nThey should be used to explain what the code does.\nA comment is made with the #. Python ignores everything in a line that follows a #.\nLet’s practice making some comments.\n\ni = 1  # Assign the value 1 to variable i\nj = 2  # Assign the value 2 to variable j\n\n# We add i and j below this line\ni + j"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#functions",
    "href": "tutorials/session_1/python_fundamentals/basics.html#functions",
    "title": "Basics",
    "section": "",
    "text": "Functions are processes that take an input (or inputs) and produce an output.\nIf we had a function called f that took two arguments x and y, we would write f(x, y) to use the function.\nFor example, the function print simply prints whatever it is given. Recall the variable we created called x.\n\nprint(x)\n\n\n\nWe can figure out what a function does by asking for help.\nIn Jupyter notebooks, this is done by placing a ? after the function name (without using parenthesis) and evaluating the cell.\nFor example, we can ask for help on the print function by writing print?.\nDepending on how you launched Jupyter, this will either launch\n\nJupyterLab: display the help in text below the cell.\n\nClassic Jupyter Notebooks: display a new panel at the bottom of your screen. You can exit this panel by hitting the escape key or clicking the x at the top right of the panel.\n\n\n# print? # remove the comment and &lt;Shift-Enter&gt;\n\n\n\n\nSee exercise 2 in the exercise list.\nJupyterLab also has a “Contextual Help” (previously called “Inspector”) window. To use,\n\nGo to the Commands and choose Contextual Help (or Inspector), or select &lt;Ctrl-I&gt; (&lt;Cmd-I&gt; for OSX users).\n\nDrag the new inspector pain to dock in the screen next to your code.\n\nThen, type print or any other function into a cell and see the help.\n\n\n# len? # remove the comment and &lt;Shift-Enter&gt;\n\nWe will learn much more about functions, including how to write our own, in a future lecture."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#objects-and-types",
    "href": "tutorials/session_1/python_fundamentals/basics.html#objects-and-types",
    "title": "Basics",
    "section": "",
    "text": "Everything in Python is an object.\nObjects are “things” that contain 1) data and 2) functions that can operate on the data.\nSometimes we refer to the functions inside an object as methods.\nWe can investigate what data is inside an object and which methods it supports by typing . after that particular variable, then hitting TAB.\nIt should then list data and method names to the right of the variable name like this:\n\n\n\nhttps://datascience.quantecon.org/_static/introspection.png\n\n\nYou can scroll through this list by using the up and down arrows.\nWe often refer to this as “tab completion” or “introspection”.\nLet’s do this together below. Keep going down until you find the method split.\n\n# Type a period after `x` and then press TAB.\nx\n\nOnce you have found the method split, you can use the method by adding parenthesis after it.\nLet’s call the split method, which doesn’t have any other required parameters. (Quiz: how would we check that?)\n\nx.split()\n\nWe often want to identify what kind of object some value is– called its “type”.\nA “type” is an abstraction which defines a set of behavior for any “instance” of that type i.e. 2.0 and 3.0 are instances of float, where float has a set of particular common behaviors.\nIn particular, the type determines:\n\nthe available data for any “instance” of the type (where each instance may have different values of the data).\n\nthe methods that can be applied on the object and its data.\n\nWe can figure this out by using the type function.\nThe type function takes a single argument and outputs the type of that argument.\n\ntype(3)\n\n\ntype(\"Hello World\")\n\n\ntype([1, 2, 3])\n\nWe will learn more about each of these types (and others!) and how to use them soon, so stay tuned!"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#modules",
    "href": "tutorials/session_1/python_fundamentals/basics.html#modules",
    "title": "Basics",
    "section": "",
    "text": "Python takes a modular approach to tools.\nBy this we mean that sets of related tools are bundled together into packages. (You may also hear the term modules to describe the same thing.)\nFor example:\n\npandas is a package that implements the tools necessary to do scalable data analysis.\n\nmatplotlib is a package that implements visualization tools.\n\nrequests and urllib are packages that allow Python to interface with the internet.\n\nAs we move further into the class, being able to access these packages will become very important.\nWe can bring a package’s functionality into our current Python session by writing\n\nimport package\n\nOnce we have done this, any function or object from that package can be accessed by using package.name.\nHere’s an example.\n\nimport sys   # for dealing with your computer's system\nsys.version  # information about the Python version in use"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#exercise-2",
    "href": "tutorials/session_1/python_fundamentals/basics.html#exercise-2",
    "title": "Basics",
    "section": "",
    "text": "See exercise 3 in the exercise list.\n\n\nSome packages have long names (see matplotlib, for example) which makes accessing the package functionality somewhat inconvenient.\nTo ease this burden, Python allows us to give aliases or “nicknames” to packages.\nFor example we can write:\n\nimport package as p\n\nThis statement allows us to access the packages functionality as p.function_name rather than package.function_name.\nSome common aliases for packages are\n\nimport pandas as pd\n\nimport numpy as np\n\nimport matplotlib as mpl\n\nimport datetime as dt\n\nWhile you can choose any name for an alias, we suggest that you stick to the common ones.\nYou will learn what these common ones are over time.\n\n\n\nSee exercise 4 in the exercise list."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#good-code-habits",
    "href": "tutorials/session_1/python_fundamentals/basics.html#good-code-habits",
    "title": "Basics",
    "section": "",
    "text": "A common saying in the software engineering world is:\n\nAlways code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live. Code for readability.\n\nThis might be a dramatic take, but the most important feature of your code after correctness is readability.\nWe encourage you to do everything in your power to make your code as readable as possible.\nHere are some suggestions for how to do so:\n\nComment frequently. Leaving short notes not only will help others who use your code, but will also help you interpret your code after some time has passed.\n\nAnytime you use a comma, place a space immediately afterwards.\n\nWhitespace is your friend. Don’t write line after line of code – use blank lines to break it up.\n\nDon’t let your lines run too long. Some people reading your code will be on a laptop, so you want to ensure that they don’t need to scroll horizontally and right to read your code. We recommend no more than 80 characters per line."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#numbers",
    "href": "tutorials/session_1/python_fundamentals/basics.html#numbers",
    "title": "Basics",
    "section": "",
    "text": "Python has two types of numbers.\n\nInteger (int): These can only take the values of the integers i.e. $ {, -2, -1, 0, 1, 2, } $\n\nFloating Point Number (float): Think of these as any real number such as $ 1.0 $, $ 3.1415 $, or $ -100.022358923223 $…\n\nThe easiest way to differentiate these types of numbers is to find a decimal place after the number.\nA float will have a decimal place, but an integer will not.\nBelow, we assign integers to the variables xi and zi and assign floating point numbers to the variables xf and zf.\n\nxi = 1\nxf = 1.0\nzi = 123\nzf = 1230.5  # Notice -- There are no commas!\nzf2 = 1_230.5  # If needed, we use `_` to separate numbers for readability"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#exercise-4",
    "href": "tutorials/session_1/python_fundamentals/basics.html#exercise-4",
    "title": "Basics",
    "section": "",
    "text": "See exercise 5 in the exercise list.\n\n\nYou can use Python to perform mathematical calculations.\n\na = 4\nb = 2\n\nprint(\"a + b is\", a + b)\nprint(\"a - b is\", a - b)\nprint(\"a * b is\", a * b)\nprint(\"a / b is\", a / b)\nprint(\"a ** b is\", a**b)\nprint(\"a ^ b is\", a^b)\n\nYou likely could have guessed all except the last two.\nPython uses **, not ^, for exponentiation (raising a number to a power)!\nNotice also that above +, - and ** all returned an integer type, but / converted the result to a float.\nWhen possible, operations between integers return an integer type.\nAll operations involving a float will result in a float.\n\na = 4\nb = 2.0\n\nprint(\"a + b is\", a + b)\nprint(\"a - b is\", a - b)\nprint(\"a * b is\", a * b)\nprint(\"a / b is\", a / b)\nprint(\"a ** b is\", a**b)\n\nWe can also chain together operations.\nWhen doing this, Python follows the standard order of operations — parenthesis, exponents, multiplication and division, followed by addition and subtraction.\nFor example,\n\nx = 2.0\ny = 3.0\nz1 = x + y * x\nz2 = (x + y) * x\n\nWhat do you think z1 is?\nHow about z2?\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nWe often want to use other math functions on our numbers. Let’s try to calculate sin(2.5).\n\nsin(2.5)\n\nAs seen above, Python complains that sin isn’t defined.\nThe problem here is that the sin function – as well as many other standard math functions – are contained in the math package.\nWe must begin by importing the math package.\n\nimport math\n\nNow, we can use math.[TAB] to see what functions are available to us.\n\n# uncomment, add a period (`.`) and pres TAB\n# math\n\n\n# found math.sin!\nmath.sin(2.5)\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\nYou are less likely to run into the following operators, but understanding that they exist is useful.\nFor two numbers assigned to the variables x and y,\n\nFloor division: x // y\n\nModulus division: x % y\n\nRemember when you first learned how to do division and you were asked to talk about the quotient and the remainder?\nThat’s what these operators correspond to…\nFloor division returns the number of times the divisor goes into the dividend (the quotient) and modulus division returns the remainder.\nAn example would be 37 divided by 7:\n\nFloor division would return 5 (7 * 5 = 35)\n\nModulus division would return 2 (2 + 35 = 37)\n\nTry it!\n\n37 // 7\n\n\n37 % 7"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#strings",
    "href": "tutorials/session_1/python_fundamentals/basics.html#strings",
    "title": "Basics",
    "section": "",
    "text": "Textual information is stored in a data type called a string.\nTo denote that you would like something to be stored as a string, you place it inside of quotation marks.\nFor example,\n\n\"this is a string\"  # Notice the quotation marks\n'this is a string'  # Notice the quotation marks\nthis is not a string  # No quotation marks\n\nYou can use either \" or ' to create a string. Just make sure that you start and end the string with the same one!\nNotice that if we ask Python to tell us the type of a string, it abbreviates its answer to str.\n\ntype(\"this is a string\")"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#exercise-7",
    "href": "tutorials/session_1/python_fundamentals/basics.html#exercise-7",
    "title": "Basics",
    "section": "",
    "text": "See exercise 8 in the exercise list.\n\n\nSome of the arithmetic operators we saw in the numbers lecture also work on strings:\n\nPut two strings together: x + y.\n\nRepeat the string x a total of n times: n * x (or x * n).\n\n\nx = \"Hello\"\ny = \"World\"\n\n\nx + y\n\n\n3 * x\n\nWhat happens if we try * with two strings, or - or /?\nThe best way to find out is to try it!\n\na = \"1\"\nb = \"2\"\na * b\n\n\na - b\n\n\n\n\nSee exercise 9 in the exercise list.\n\n\n\nWe can use many methods to manipulate strings.\nWe will not be able to cover all of them here, but let’s take a look at some of the most useful ones.\n\nx\n\n\nx.lower()  # Makes all letters lower case\n\n\nx.upper()  # Makes all letters upper case\n\n\nx.count(\"l\")  # Counts number of a particular string\n\n\nx.count(\"ll\")\n\n\n\n\nSee exercise 10 in the exercise list.\n\n\n\nSee exercise 11 in the exercise list.\n\n\n\nSometimes we’d like to reuse some portion of a string repeatedly, but still make some relatively small changes at each usage.\nWe can do this with string formatting, which done by using {} as a placeholder where we’d like to change the string, with a variable name or expression.\nLet’s look at an example.\n\ncountry = \"Vietnam\"\nGDP = 223.9\nyear = 2017\nmy_string = f\"{country} had ${GDP} billion GDP in {year}\"\nprint(my_string)\n\nRather than just substituting a variable name, you can use a calculation or expression.\n\nprint(f\"{5}**2 = {5**2}\")\n\nOr, using our previous example\n\nmy_string = f\"{country} had ${GDP * 1_000_000} GDP in {year}\"\nprint(my_string)\n\nIn these cases, the f in front of the string causes Python interpolate any valid expression within the {} braces.\n\n\n\nSee exercise 12 in the exercise list.\nAlternatively, to reuse a formatted string, you can call the format method (noting that you do not put f in front).\n\ngdp_string = \"{country} had ${GDP} billion in {year}\"\n\ngdp_string.format(country = \"Vietnam\", GDP = 223.9, year = 2017)\n\n\n\n\nSee exercise 13 in the exercise list.\n\n\n\nSee exercise 14 in the exercise list.\nFor more information on what you can do with string formatting (there is a lot that can be done…), see the official Python documentation on the subject."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#booleans",
    "href": "tutorials/session_1/python_fundamentals/basics.html#booleans",
    "title": "Basics",
    "section": "",
    "text": "A boolean is a type that denotes true or false.\nAs you will soon see in the control flow chapter, using boolean values allows you to perform or skip operations depending on whether or not a condition is met.\nLet’s start by creating some booleans and looking at them.\n\nx = True\ny = False\n\ntype(x)\n\n\nx\n\n\ny\n\n\n\nRather than directly write True or False, you will usually create booleans by making a comparison.\nFor example, you might want to evaluate whether the price of a particular asset is greater than or less than some price.\nFor two variables x and y, we can do the following comparisons:\n\nGreater than: x &gt; y\n\nLess than: x &lt; y\n\nEqual to: ==\n\nGreater than or equal to: x &gt;= y\n\nLess than or equal to: x &lt;= y\n\nWe demonstrate these below.\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\n\n\n\nOccasionally, determining whether a statement is “not true” or “not false” is more convenient than simply “true” or “false”.\nThis is known as negating a statement.\nIn Python, we can negate a boolean using the word not.\n\nnot False\n\n\nnot True\n\n\n\n\nSometimes we need to evaluate multiple comparisons at once.\nThis is done by using the words and and or.\nHowever, these are the “mathematical” ands and ors – so they don’t carry the same meaning as you’d use them in colloquial English.\n\na and b is true only when both a and b are true.\n\na or b is true whenever at least one of a or b is true.\n\nFor example\n\nThe statement “I will accept the new job if the salary is higher and I receive more vacation days” means that you would only accept the new job if you both receive a higher salary and are given more vacation days.\n\nThe statement “I will accept the new job if the salary is higher or I receive more vacation days” means that you would accept the job if\n\nthey raised your salary, (2) you are given more vacation days, or\nthey raise your salary and give you more vacation days.\n\n\nLet’s see some examples.\n\nTrue and False\n\n\nTrue and True\n\n\nTrue or False\n\n\nFalse or False\n\n\n# Can chain multiple comparisons together.\nTrue and (False or True)\n\n\n\n\nSee exercise 15 in the exercise list.\n\n\n\nWe have seen how we can use the words and and or to process two booleans at a time.\nThe functions all and any allow us to process an unlimited number of booleans at once.\nall(bools) will return True if and only if all the booleans in bools is True and returns False otherwise.\nany(bools) returns True whenever one or more of bools is True.\nThe exercise below will give you a chance to practice.\n\n\n\nSee exercise 16 in the exercise list."
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/basics.html#exercises",
    "href": "tutorials/session_1/python_fundamentals/basics.html#exercises",
    "title": "Basics",
    "section": "",
    "text": "What do you think the value of z is after running the code below?\n\nz = 3\nz = z + 4\nprint(\"z is\", z)\n\n(back to text)\n\n\n\nRead about out what the len function does (by writing len?).\nWhat will it produce if we give it the variable x?\nCheck whether you were right by running the code len(x).\n(back to text)\n\n\n\nWe can use our introspection skills to investigate a package’s contents.\nIn the cell below, use tab completion to find a function from the time module that will display the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the function you found) to see information about that function and then call the function.\nLook for something to do with the word local\n\nimport time\n# your code here -- notice the comment!\n\n(back to text)\n\n\n\nTry running import time as t in the cell below, then see if you can call the function you identified above.\nDoes it work?\n(back to text)\n\n\n\nCreate the following variables:\n\nD: A floating point number with the value 10,000\n\nr: A floating point number with value 0.025\n\nT: An integer with value 30\n\nWe will use them in a later exercise.\n\n# your code here!\n\n(back to text)\n\n\n\nRemember the variables we created earlier?\nLet’s compute the present discounted value of a payment ($ D $) made in $ T $ years assuming an interest rate of 2.5%. Save this value to a new variable called PDV and print your output.\nThe formula is\n\\[\n\\text{PDV} = \\frac{D}{(1 + r)^T}\n\\]\n\n# your code here\n\n(back to text)\n\n\n\nVerify the “trick” where the percent difference ($ \\()\nbetween two numbers close to 1 can be well approximated by the difference\nbetween the log of the two numbers (\\) (x) - (y) $).\nUse the numbers x and y below.\nyou will want to use the math.log function\n\nx = 1.05\ny = 1.02\n\n(back to text)\n\n\n\nThe code below is invalid Python code\n\nx = 'What's wrong with this string'\n\nCan you fix it?\nTry creating a code cell below and testing things out until you find a solution.\n(back to text)\n\n\n\nUsing the variables x and y, how could you create the sentence Hello World?\nThink about how to represent a space as a string.\n(back to text)\n\n\n\nOne of our favorite (and most frequently used) string methods is replace.\nIt substitutes all occurrences of a particular pattern with a different pattern.\nFor the variable test below, use the replace method to change the c to a d.\nType test.replace? to get some help for how to use the method replace.\n\ntest = \"abc\"\n\n(back to text)\n\n\n\nSuppose you are working with price data and encounter the value \"\\$6.50\".\nWe recognize this as being a number representing the quantity “six dollars and fifty cents.”\nHowever, Python interprets the value as the string \"\\$6.50\". (Quiz: why is this a problem? Think about the examples above.)\nIn this exercise, your task is to convert the variable price below into a number.\nOnce the string is in a suitable format, you can call write float(clean_price) to make it a number.\n\nprice = \"$6.50\"\n\n(back to text)\n\n\n\nLookup a country in World Bank database, and format a string showing the growth rate of GDP over the last 2 years.\n(back to text)\n\n\n\nInstead of hard-coding the values above, try to use the country, GDP and year variables you previously defined.\n(back to text)\n\n\n\nCreate a new string and use formatting to produce each of the following statements\n\n“The 1st quarter revenue was 110M”\n\n“The 2nd quarter revenue was 95M”\n\n“The 3rd quarter revenue was 100M”\n\n“The 4th quarter revenue was 130M”\n\n(back to text)\n\n\n\nWithout typing the commands, determine whether the following statements are true or false.\nOnce you have evaluated whether the command is True or False, run the code in Python.\n\nx = 2\ny = 2\nz = 4\n\n# Statement 1\nx &gt; z\n\n# Statement 1\nx == y\n\n# Statement 3\n(x &lt; y) and (x &gt; y)\n\n# Statement 4\n(x &lt; y) or (x &gt; y)\n\n# Statement 5\n(x &lt;= y) and (x &gt;= y)\n\n# Statement 6\nTrue and ((x &lt; z) or (x &lt; y))\n\n\n# code here!\n\n(back to text)\n\n\n\nFor each of the code cells below, think carefully about what you expect to be returned before evaluating the cell.\nThen evaluate the cell to check your intuitions.\nNOTE: For now, do not worry about what the [ and ] mean – they allow us to create lists which we will learn about in an upcoming lecture.\n\nall([True, True, True])\n\n\nall([False, True, False])\n\n\nall([False, False, False])\n\n\nany([True, True, True])\n\n\nany([False, True, False])\n\n\nany([False, False, False])\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/collections.html",
    "href": "tutorials/session_1/python_fundamentals/collections.html",
    "title": "Collections",
    "section": "",
    "text": "Prerequisites\n\nCore data types\n\nOutcomes\n\nOrdered Collections\n\nKnow what a list is and a tuple is\n\nKnow how to tell a list from a tuple\n\nUnderstand the range, zip and enumerate functions\n\nBe able to use common list methods like append, sort, and reverse\n\n\nAssociative Collections\n\nUnderstand what a dict is\n\nKnow the distinction between a dicts keys and values\n\nUnderstand when dicts are useful\n\nBe familiar with common dict methods\n\n\nSets (optional)\n\nKnow what a set is\n\nUnderstand how a set differs from a list and a tuple\n\nKnow when to use a set vs a list or a tuple\n\n\n\n\n\n\nA Python list is an ordered collection of items.\nWe can create lists using the following syntax\n\n[item1, item2, ...,  itemN]\n\nwhere the ... represents any number of additional items.\nEach item can be of any type.\nLet’s create some lists.\n\n# created, but not assigned to a variable\n[2.0, 9.1, 12.5]\n\n\n# stored as the variable `x`\nx = [2.0, 9.1, 12.5]\nprint(\"x has type\", type(x))\nx\n\n\n\nWe can access items in a list called mylist using mylist[N] where N is an integer.\nNote: Anytime that we use the syntax x[i] we are doing what is called indexing – it means that we are selecting a particular element of a collection x.\n\nx[1]\n\nWait? Why did x[1] return 9.1 when the first element in x is actually 2.0?\nThis happened because Python starts counting at zero!\nLets repeat that one more time for emphasis Python starts counting at zero!\nTo access the first element of x we must use x[0]:\n\nx[0]\n\nWe can also determine how many items are in a list using the len function.\n\nlen(x)\n\nWhat happens if we try to index with a number higher than the number of items in a list?\n\n# uncomment the line below and run\n# x[4]\n\nWe can check if a list contains an element using the in keyword.\n\n2.0 in x\n\n\n1.5 in x\n\nFor our list x, other common operations we might want to do are…\n\nx.reverse()\nx\n\n\nnumber_list = [10, 25, 42, 1.0]\nprint(number_list)\nnumber_list.sort()\nprint(number_list)\n\nNote that in order to sort, we had to have all elements in our list be numbers (int and float), more on this below.\nWe could actually do the same with a list of strings. In this case, sort will put the items in alphabetical order.\n\nstr_list = [\"NY\", \"AZ\", \"TX\"]\nprint(str_list)\nstr_list.sort()\nprint(str_list)\n\nThe append method adds an element to the end of existing list.\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.append(10)\nprint(num_list)\n\nHowever, if you call append with a list, it adds a list to the end, rather than the numbers in that list.\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.append([20, 4])\nprint(num_list)\n\nTo combine the lists instead…\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.extend([20, 4])\nprint(num_list)\n\n\n\n\nSee exercise 1 in the exercise list.\n\n\n\n\n\nWhile most examples above have all used a list with a single type of variable, this is not required.\nLet’s carefully make a small change to the first example: replace 2.0 with 2\n\nx = [2, 9.1, 12.5]\n\nThis behavior is identical for many operations you might apply to a list.\n\nimport numpy as np\nx = [2, 9.1, 12.5]\nnp.mean(x) == sum(x)/len(x)\n\nHere we have also introduced a new module, Numpy, which provides many functions for working with numeric data.\nTaking this further, we can put completely different types of elements inside of a list.\n\n# stored as the variable `x`\nx = [2, \"hello\", 3.0]\nprint(\"x has type\", type(x))\nx\n\nTo see the types of individual elements in the list:\n\nprint(f\"type(x[0]) = {type(x[0])}, type(x[1]) = {type(x[1])}, type(x[2]) = {type(x[2])}\")\n\nWhile no programming limitations prevent this, you should be careful if you write code with different numeric and non-numeric types in the same list.\nFor example, if the types within the list cannot be compared, then how could you sort the elements of the list? (i.e. How do you determine whether the string “hello” is less than the integer 2, “hello” &lt; 2?)\n\nx = [2, \"hello\", 3.0]\n# uncomment the line below and see what happens!\n# x.sort()\n\nA few key exceptions to this general rule are:\n\nLists with both integers and floating points are less error-prone (since mathematical code using the list would work with both types).\n\nWhen working with lists and data, you may want to represent missing values with a different type than the existing values.\n\n\n\n\nOne function you will see often in Python is the range function.\nIt has three versions:\n\nrange(N): goes from 0 to N-1\n\nrange(a, N): goes from a to N-1\n\nrange(a, N, d): goes from a to N-1, counting by d\n\nWhen we call the range function, we get back something that has type range:\n\nr = range(5)\nprint(\"type(r)\", type(r))\n\nTo turn the range into a list:\n\nlist(r)\n\n\n\n\nSee exercise 2 in the exercise list.\n\n\n\nTuples are very similar to lists and hold ordered collections of items.\nHowever, tuples and lists have three main differences:\n\nTuples are created using parenthesis — ( and ) — instead of square brackets — [ and ].\n\nTuples are immutable, which is a fancy computer science word meaning that they can’t be changed or altered after they are created.\n\nTuples and multiple return values from functions are tightly connected, as we will see in functions.\n\n\nt = (1, \"hello\", 3.0)\nprint(\"t is a\", type(t))\nt\n\nWe can convert a list to a tuple by calling the tuple function on a list.\n\nprint(\"x is a\", type(x))\nprint(\"tuple(x) is a\", type(tuple(x)))\ntuple(x)\n\nWe can also convert a tuple to a list using the list function.\n\nlist(t)\n\nAs with a list, we access items in a tuple t using t[N] where N is an int.\n\nt[0]  # still start counting at 0\n\n\nt[2]\n\n\n\n\nSee exercise 3 in the exercise list.\nTuples (and lists) can be unpacked directly into variables.\n\nx, y = (1, \"test\")\nprint(f\"x = {x}, y = {y}\")\n\nThis will be a convenient way to work with functions returning multiple values, as well as within comprehensions and loops.\n\n\n\nShould you use a list or tuple?\nThis depends on what you are storing, whether you might need to reorder the elements, or whether you’d add new elements without a complete reinterpretation of the underlying data.\nFor example, take data representing the GDP (in trillions) and population (in billions) for China in 2015.\n\nchina_data_2015 = (\"China\", 2015, 11.06, 1.371)\n\nprint(china_data_2015)\n\nIn this case, we have used a tuple since: (a) ordering would be meaningless; and (b) adding more data would require a reinterpretation of the whole data structure.\nOn the other hand, consider a list of GDP in China between 2013 and 2015.\n\ngdp_data = [9.607, 10.48, 11.06]\nprint(gdp_data)\n\nIn this case, we have used a list, since adding on a new element to the end of the list for GDP in 2016 would make complete sense.\nAlong these lines, collecting data on China for different years may make sense as a list of tuples (e.g. year, GDP, and population – although we will see better ways to store this sort of data in the Pandas section).\n\nchina_data = [(2015, 11.06, 1.371), (2014, 10.48, 1.364), (2013, 9.607, 1.357)]\nprint(china_data)\n\nIn general, a rule of thumb is to use a list unless you need to use a tuple.\nKey criteria for tuple use are when you want to:\n\nensure the order of elements can’t change\n\nensure the actual values of the elements can’t change\n\nuse the collection as a key in a dict (we will learn what this means soon)\n\n\n\n\nTwo functions that can be extremely useful are zip and enumerate.\nBoth of these functions are best understood by example, so let’s see them in action and then talk about what they do.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nz = zip(years, gdp_data)\nprint(\"type(z)\", type(z))\n\nTo see what is inside z, let’s convert it to a list.\n\nlist(z)\n\nNotice that we now have a list where each item is a tuple.\nWithin each tuple, we have one item from each of the collections we passed to the zip function.\nIn particular, the first item in z contains the first item from [2013, 2014, 2015] and the first item from [9.607, 10.48, 11.06].\nThe second item in z contains the second item from each collection and so on.\nWe can access an element in this and then unpack the resulting tuple directly into variables.\n\nl = list(zip(years, gdp_data))\nx, y = l[0]\nprint(f\"year = {x}, GDP = {y}\")\n\nNow let’s experiment with enumerate.\n\ne = enumerate([\"a\", \"b\", \"c\"])\nprint(\"type(e)\", type(e))\ne\n\nAgain, we call list(e) to see what is inside.\n\nlist(e)\n\nWe again have a list of tuples, but this time, the first element in each tuple is the index of the second tuple element in the initial collection.\nNotice that the third item is (2, 'c') because [\"a\", \"b\", \"c\"][2] is 'c'\n\n\n\nSee exercise 4 in the exercise list.\nAn important quirk of some iterable types that are not lists (such as the above zip) is that you cannot convert the same type to a list twice.\nThis is because zip, enumerate, and range produce what is called a generator.\nA generator will only produce each of its elements a single time, so if you call list on the same generator a second time, it will not have any elements to iterate over anymore.\nFor more information, refer to the Python documentation.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nz = zip(years, gdp_data)\nl = list(z)\nprint(l)\nm = list(z)\nprint(m)\n\n\n\n\n\n\n\n\nA dictionary (or dict) associates keys with values.\nIt will feel similar to a dictionary for words, where the keys are words and the values are the associated definitions.\nThe most common way to create a dict is to use curly braces — { and } — like this:\n\n{\"key1\": value1, \"key2\": value2, ..., \"keyN\": valueN}\n\nwhere the ... indicates that we can have any number of additional terms.\nThe crucial part of the syntax is that each key-value pair is written key: value and that these pairs are separated by commas — ,.\nLet’s see an example using our aggregate data on China in 2015.\n\nchina_data = {\"country\": \"China\", \"year\": 2015, \"GDP\" : 11.06, \"population\": 1.371}\nprint(china_data)\n\nUnlike our above example using a tuple, a dict allows us to associate a name with each field, rather than having to remember the order within the tuple.\nOften, code that makes a dict is easier to read if we put each key: value pair on its own line. (Recall our earlier comment on using whitespace effectively to improve readability!)\nThe code below is equivalent to what we saw above.\n\nchina_data = {\n    \"country\": \"China\",\n    \"year\": 2015,\n    \"GDP\" : 11.06,\n    \"population\": 1.371\n}\n\nMost often, the keys (e.g. “country”, “year”, “GDP”, and “population”) will be strings, but we could also use numbers (int, or float) or even tuples (or, rarely, a combination of types).\nThe values can be any type and different from each other.\n\n\n\nSee exercise 5 in the exercise list.\nThis next example is meant to emphasize how values can be anything – including another dictionary.\n\ncompanies = {\"AAPL\": {\"bid\": 175.96, \"ask\": 175.98},\n             \"GE\": {\"bid\": 1047.03, \"ask\": 1048.40},\n             \"TVIX\": {\"bid\": 8.38, \"ask\": 8.40}}\nprint(companies)\n\n\n\nWe can now ask Python to tell us the value for a particular key by using the syntax d[k], where d is our dict and k is the key for which we want to find the value.\nFor example,\n\nprint(china_data[\"year\"])\nprint(f\"country = {china_data['country']}, population = {china_data['population']}\")\n\nNote: when inside of a formatting string, you can use ' instead of \" as above to ensure the formatting still works with the embedded code.\nIf we ask for the value of a key that is not in the dict, we will get an error.\n\n# uncomment the line below to see the error\n# china_data[\"inflation\"]\n\nWe can also add new items to a dict using the syntax d[new_key] = new_value.\nLet’s see some examples.\n\nprint(china_data)\nchina_data[\"unemployment\"] = \"4.05%\"\nprint(china_data)\n\nTo update the value, we use assignment in the same way (which will create the key and value as required).\n\nprint(china_data)\nchina_data[\"unemployment\"] = \"4.051%\"\nprint(china_data)\n\nOr we could change the type.\n\nchina_data[\"unemployment\"] = 4.051\nprint(china_data)\n\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nWe can do some common things with dicts.\nWe will demonstrate them with examples below.\n\n# number of key-value pairs in a dict\nlen(china_data)\n\n\n# get a list of all the keys\nlist(china_data.keys())\n\n\n# get a list of all the values\nlist(china_data.values())\n\n\nmore_china_data = {\"irrigated_land\": 690_070, \"top_religions\": {\"buddhist\": 18.2, \"christian\" : 5.1, \"muslim\": 1.8}}\n\n# Add all key-value pairs in mydict2 to mydict.\n# if the key already appears in mydict, overwrite the\n# value with the value in mydict2\nchina_data.update(more_china_data)\nchina_data\n\n\n# Get the value associated with a key or return a default value\n# use this to avoid the NameError we saw above if you have a reasonable\n# default value\nchina_data.get(\"irrigated_land\", \"Data Not Available\")\n\n\nchina_data.get(\"death_rate\", \"Data Not Available\")\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\n\nSee exercise 8 in the exercise list.\n\n\n\n\nPython has an additional way to represent collections of items: sets.\nSets come up infrequently, but you should be aware of them.\nIf you are familiar with the mathematical concept of sets, then you will understand the majority of Python sets already.\nIf you don’t know the math behind sets, don’t worry: we’ll cover the basics of Python’s sets here.\nA set is an unordered collection of unique elements.\nThe syntax for creating a set uses curly bracket { and }.\n\n{item1, item2, ..., itemN}\n\nHere is an example.\n\ns = {1, \"hello\", 3.0}\nprint(\"s has type\", type(s))\ns\n\n\n\n\nSee exercise 9 in the exercise list.\nAs with lists and tuples, we can check if something is in the set and check the set’s length:\n\nprint(\"len(s) =\", len(s))\n\"hello\" in s\n\nUnlike lists and tuples, we can’t extract elements of a set s using s[N] where N is a number.\n\n# Uncomment the line below to see what happens\n# s[1]\n\nThis is because sets are not ordered, so the notion of getting the second element (s[1]) is not well defined.\nWe add elements to a set s using s.add.\n\ns.add(100)\ns\n\n\ns.add(\"hello\") # nothing happens, why?\ns\n\nWe can also do set operations.\nConsider the set s from above and the set s2 = {\"hello\", \"world\"}.\n\ns.union(s2): returns a set with all elements in either s or s2\n\ns.intersection(s2): returns a set with all elements in both s and s2\n\ns.difference(s2): returns a set with all elements in s that aren’t in s2\n\ns.symmetric_difference(s2): returns a set with all elements in only one of s and s2\n\n\n\n\nSee exercise 10 in the exercise list.\nAs with tuples and lists, a set function can convert other collections to sets.\n\nx = [1, 2, 3, 1]\nset(x)\n\n\nt = (1, 2, 3, 1)\nset(t)\n\nLikewise, we can convert sets to lists and tuples.\n\nlist(s)\n\n\ntuple(s)\n\n\n\n\n\n\n\n\nIn the first cell, try y.append(z).\nIn the second cell try y.extend(z).\nExplain the behavior.\nWhen you are trying to explain use y.append? and y.extend? to see a description of what these methods are supposed to do.\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# your code here\nprint(y)\n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# your code here\nprint(y)\n\n(back to text)\n\n\n\nExperiment with the other two versions of the range function.\n\n# try list(range(a, N)) -- you pick `a` and `N`\n\n\n# try list(range(a, N, d)) -- you pick `a`, `N`, and `d`\n\n(back to text)\n\n\n\nVerify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\n# change first element of t\n\n\n# appending to t\n\n\n# sorting t\n\n\n# reversing t\n\n(back to text)\n\n\n\nChallenging For the tuple foo below, use a combination of zip, range, and len to mimic enumerate(foo).\nVerify that your proposed solution is correct by converting each to a list and checking equality with ==.\nYou can see what the answer should look like by starting with list(enumerate(foo)).\n\nfoo = (\"good\", \"luck!\")\n\n(back to text)\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n\n(back to text)\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\n\n(back to text)\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\n#china_data.pop()\n\n(back to text)\n\n\n\nExplain what happens to the value you popped.\nExperiment with calling pop twice.\n\n# your code here\n\n(back to text)\n\n\n\nTry creating a set with repeated elements (e.g. {1, 2, 1, 2, 1, 2}).\nWhat happens?\nWhy?\n\n# your code here\n\n(back to text)\n\n\n\nTest out two of the operations described above using the original set we created, s, and the set created below s2.\n\ns2 = {\"hello\", \"world\"}\n\n\n# Operation 1\n\n\n# Operation 2\n\n(back to text)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/collections.html#ordered-collections",
    "href": "tutorials/session_1/python_fundamentals/collections.html#ordered-collections",
    "title": "Collections",
    "section": "",
    "text": "A Python list is an ordered collection of items.\nWe can create lists using the following syntax\n\n[item1, item2, ...,  itemN]\n\nwhere the ... represents any number of additional items.\nEach item can be of any type.\nLet’s create some lists.\n\n# created, but not assigned to a variable\n[2.0, 9.1, 12.5]\n\n\n# stored as the variable `x`\nx = [2.0, 9.1, 12.5]\nprint(\"x has type\", type(x))\nx\n\n\n\nWe can access items in a list called mylist using mylist[N] where N is an integer.\nNote: Anytime that we use the syntax x[i] we are doing what is called indexing – it means that we are selecting a particular element of a collection x.\n\nx[1]\n\nWait? Why did x[1] return 9.1 when the first element in x is actually 2.0?\nThis happened because Python starts counting at zero!\nLets repeat that one more time for emphasis Python starts counting at zero!\nTo access the first element of x we must use x[0]:\n\nx[0]\n\nWe can also determine how many items are in a list using the len function.\n\nlen(x)\n\nWhat happens if we try to index with a number higher than the number of items in a list?\n\n# uncomment the line below and run\n# x[4]\n\nWe can check if a list contains an element using the in keyword.\n\n2.0 in x\n\n\n1.5 in x\n\nFor our list x, other common operations we might want to do are…\n\nx.reverse()\nx\n\n\nnumber_list = [10, 25, 42, 1.0]\nprint(number_list)\nnumber_list.sort()\nprint(number_list)\n\nNote that in order to sort, we had to have all elements in our list be numbers (int and float), more on this below.\nWe could actually do the same with a list of strings. In this case, sort will put the items in alphabetical order.\n\nstr_list = [\"NY\", \"AZ\", \"TX\"]\nprint(str_list)\nstr_list.sort()\nprint(str_list)\n\nThe append method adds an element to the end of existing list.\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.append(10)\nprint(num_list)\n\nHowever, if you call append with a list, it adds a list to the end, rather than the numbers in that list.\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.append([20, 4])\nprint(num_list)\n\nTo combine the lists instead…\n\nnum_list = [10, 25, 42, 8]\nprint(num_list)\nnum_list.extend([20, 4])\nprint(num_list)\n\n\n\n\nSee exercise 1 in the exercise list.\n\n\n\n\n\nWhile most examples above have all used a list with a single type of variable, this is not required.\nLet’s carefully make a small change to the first example: replace 2.0 with 2\n\nx = [2, 9.1, 12.5]\n\nThis behavior is identical for many operations you might apply to a list.\n\nimport numpy as np\nx = [2, 9.1, 12.5]\nnp.mean(x) == sum(x)/len(x)\n\nHere we have also introduced a new module, Numpy, which provides many functions for working with numeric data.\nTaking this further, we can put completely different types of elements inside of a list.\n\n# stored as the variable `x`\nx = [2, \"hello\", 3.0]\nprint(\"x has type\", type(x))\nx\n\nTo see the types of individual elements in the list:\n\nprint(f\"type(x[0]) = {type(x[0])}, type(x[1]) = {type(x[1])}, type(x[2]) = {type(x[2])}\")\n\nWhile no programming limitations prevent this, you should be careful if you write code with different numeric and non-numeric types in the same list.\nFor example, if the types within the list cannot be compared, then how could you sort the elements of the list? (i.e. How do you determine whether the string “hello” is less than the integer 2, “hello” &lt; 2?)\n\nx = [2, \"hello\", 3.0]\n# uncomment the line below and see what happens!\n# x.sort()\n\nA few key exceptions to this general rule are:\n\nLists with both integers and floating points are less error-prone (since mathematical code using the list would work with both types).\n\nWhen working with lists and data, you may want to represent missing values with a different type than the existing values.\n\n\n\n\nOne function you will see often in Python is the range function.\nIt has three versions:\n\nrange(N): goes from 0 to N-1\n\nrange(a, N): goes from a to N-1\n\nrange(a, N, d): goes from a to N-1, counting by d\n\nWhen we call the range function, we get back something that has type range:\n\nr = range(5)\nprint(\"type(r)\", type(r))\n\nTo turn the range into a list:\n\nlist(r)\n\n\n\n\nSee exercise 2 in the exercise list.\n\n\n\nTuples are very similar to lists and hold ordered collections of items.\nHowever, tuples and lists have three main differences:\n\nTuples are created using parenthesis — ( and ) — instead of square brackets — [ and ].\n\nTuples are immutable, which is a fancy computer science word meaning that they can’t be changed or altered after they are created.\n\nTuples and multiple return values from functions are tightly connected, as we will see in functions.\n\n\nt = (1, \"hello\", 3.0)\nprint(\"t is a\", type(t))\nt\n\nWe can convert a list to a tuple by calling the tuple function on a list.\n\nprint(\"x is a\", type(x))\nprint(\"tuple(x) is a\", type(tuple(x)))\ntuple(x)\n\nWe can also convert a tuple to a list using the list function.\n\nlist(t)\n\nAs with a list, we access items in a tuple t using t[N] where N is an int.\n\nt[0]  # still start counting at 0\n\n\nt[2]\n\n\n\n\nSee exercise 3 in the exercise list.\nTuples (and lists) can be unpacked directly into variables.\n\nx, y = (1, \"test\")\nprint(f\"x = {x}, y = {y}\")\n\nThis will be a convenient way to work with functions returning multiple values, as well as within comprehensions and loops.\n\n\n\nShould you use a list or tuple?\nThis depends on what you are storing, whether you might need to reorder the elements, or whether you’d add new elements without a complete reinterpretation of the underlying data.\nFor example, take data representing the GDP (in trillions) and population (in billions) for China in 2015.\n\nchina_data_2015 = (\"China\", 2015, 11.06, 1.371)\n\nprint(china_data_2015)\n\nIn this case, we have used a tuple since: (a) ordering would be meaningless; and (b) adding more data would require a reinterpretation of the whole data structure.\nOn the other hand, consider a list of GDP in China between 2013 and 2015.\n\ngdp_data = [9.607, 10.48, 11.06]\nprint(gdp_data)\n\nIn this case, we have used a list, since adding on a new element to the end of the list for GDP in 2016 would make complete sense.\nAlong these lines, collecting data on China for different years may make sense as a list of tuples (e.g. year, GDP, and population – although we will see better ways to store this sort of data in the Pandas section).\n\nchina_data = [(2015, 11.06, 1.371), (2014, 10.48, 1.364), (2013, 9.607, 1.357)]\nprint(china_data)\n\nIn general, a rule of thumb is to use a list unless you need to use a tuple.\nKey criteria for tuple use are when you want to:\n\nensure the order of elements can’t change\n\nensure the actual values of the elements can’t change\n\nuse the collection as a key in a dict (we will learn what this means soon)\n\n\n\n\nTwo functions that can be extremely useful are zip and enumerate.\nBoth of these functions are best understood by example, so let’s see them in action and then talk about what they do.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nz = zip(years, gdp_data)\nprint(\"type(z)\", type(z))\n\nTo see what is inside z, let’s convert it to a list.\n\nlist(z)\n\nNotice that we now have a list where each item is a tuple.\nWithin each tuple, we have one item from each of the collections we passed to the zip function.\nIn particular, the first item in z contains the first item from [2013, 2014, 2015] and the first item from [9.607, 10.48, 11.06].\nThe second item in z contains the second item from each collection and so on.\nWe can access an element in this and then unpack the resulting tuple directly into variables.\n\nl = list(zip(years, gdp_data))\nx, y = l[0]\nprint(f\"year = {x}, GDP = {y}\")\n\nNow let’s experiment with enumerate.\n\ne = enumerate([\"a\", \"b\", \"c\"])\nprint(\"type(e)\", type(e))\ne\n\nAgain, we call list(e) to see what is inside.\n\nlist(e)\n\nWe again have a list of tuples, but this time, the first element in each tuple is the index of the second tuple element in the initial collection.\nNotice that the third item is (2, 'c') because [\"a\", \"b\", \"c\"][2] is 'c'\n\n\n\nSee exercise 4 in the exercise list.\nAn important quirk of some iterable types that are not lists (such as the above zip) is that you cannot convert the same type to a list twice.\nThis is because zip, enumerate, and range produce what is called a generator.\nA generator will only produce each of its elements a single time, so if you call list on the same generator a second time, it will not have any elements to iterate over anymore.\nFor more information, refer to the Python documentation.\n\ngdp_data = [9.607, 10.48, 11.06]\nyears = [2013, 2014, 2015]\nz = zip(years, gdp_data)\nl = list(z)\nprint(l)\nm = list(z)\nprint(m)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/collections.html#associative-collections",
    "href": "tutorials/session_1/python_fundamentals/collections.html#associative-collections",
    "title": "Collections",
    "section": "",
    "text": "A dictionary (or dict) associates keys with values.\nIt will feel similar to a dictionary for words, where the keys are words and the values are the associated definitions.\nThe most common way to create a dict is to use curly braces — { and } — like this:\n\n{\"key1\": value1, \"key2\": value2, ..., \"keyN\": valueN}\n\nwhere the ... indicates that we can have any number of additional terms.\nThe crucial part of the syntax is that each key-value pair is written key: value and that these pairs are separated by commas — ,.\nLet’s see an example using our aggregate data on China in 2015.\n\nchina_data = {\"country\": \"China\", \"year\": 2015, \"GDP\" : 11.06, \"population\": 1.371}\nprint(china_data)\n\nUnlike our above example using a tuple, a dict allows us to associate a name with each field, rather than having to remember the order within the tuple.\nOften, code that makes a dict is easier to read if we put each key: value pair on its own line. (Recall our earlier comment on using whitespace effectively to improve readability!)\nThe code below is equivalent to what we saw above.\n\nchina_data = {\n    \"country\": \"China\",\n    \"year\": 2015,\n    \"GDP\" : 11.06,\n    \"population\": 1.371\n}\n\nMost often, the keys (e.g. “country”, “year”, “GDP”, and “population”) will be strings, but we could also use numbers (int, or float) or even tuples (or, rarely, a combination of types).\nThe values can be any type and different from each other.\n\n\n\nSee exercise 5 in the exercise list.\nThis next example is meant to emphasize how values can be anything – including another dictionary.\n\ncompanies = {\"AAPL\": {\"bid\": 175.96, \"ask\": 175.98},\n             \"GE\": {\"bid\": 1047.03, \"ask\": 1048.40},\n             \"TVIX\": {\"bid\": 8.38, \"ask\": 8.40}}\nprint(companies)\n\n\n\nWe can now ask Python to tell us the value for a particular key by using the syntax d[k], where d is our dict and k is the key for which we want to find the value.\nFor example,\n\nprint(china_data[\"year\"])\nprint(f\"country = {china_data['country']}, population = {china_data['population']}\")\n\nNote: when inside of a formatting string, you can use ' instead of \" as above to ensure the formatting still works with the embedded code.\nIf we ask for the value of a key that is not in the dict, we will get an error.\n\n# uncomment the line below to see the error\n# china_data[\"inflation\"]\n\nWe can also add new items to a dict using the syntax d[new_key] = new_value.\nLet’s see some examples.\n\nprint(china_data)\nchina_data[\"unemployment\"] = \"4.05%\"\nprint(china_data)\n\nTo update the value, we use assignment in the same way (which will create the key and value as required).\n\nprint(china_data)\nchina_data[\"unemployment\"] = \"4.051%\"\nprint(china_data)\n\nOr we could change the type.\n\nchina_data[\"unemployment\"] = 4.051\nprint(china_data)\n\n\n\n\nSee exercise 6 in the exercise list.\n\n\n\nWe can do some common things with dicts.\nWe will demonstrate them with examples below.\n\n# number of key-value pairs in a dict\nlen(china_data)\n\n\n# get a list of all the keys\nlist(china_data.keys())\n\n\n# get a list of all the values\nlist(china_data.values())\n\n\nmore_china_data = {\"irrigated_land\": 690_070, \"top_religions\": {\"buddhist\": 18.2, \"christian\" : 5.1, \"muslim\": 1.8}}\n\n# Add all key-value pairs in mydict2 to mydict.\n# if the key already appears in mydict, overwrite the\n# value with the value in mydict2\nchina_data.update(more_china_data)\nchina_data\n\n\n# Get the value associated with a key or return a default value\n# use this to avoid the NameError we saw above if you have a reasonable\n# default value\nchina_data.get(\"irrigated_land\", \"Data Not Available\")\n\n\nchina_data.get(\"death_rate\", \"Data Not Available\")\n\n\n\n\nSee exercise 7 in the exercise list.\n\n\n\nSee exercise 8 in the exercise list.\n\n\n\n\nPython has an additional way to represent collections of items: sets.\nSets come up infrequently, but you should be aware of them.\nIf you are familiar with the mathematical concept of sets, then you will understand the majority of Python sets already.\nIf you don’t know the math behind sets, don’t worry: we’ll cover the basics of Python’s sets here.\nA set is an unordered collection of unique elements.\nThe syntax for creating a set uses curly bracket { and }.\n\n{item1, item2, ..., itemN}\n\nHere is an example.\n\ns = {1, \"hello\", 3.0}\nprint(\"s has type\", type(s))\ns\n\n\n\n\nSee exercise 9 in the exercise list.\nAs with lists and tuples, we can check if something is in the set and check the set’s length:\n\nprint(\"len(s) =\", len(s))\n\"hello\" in s\n\nUnlike lists and tuples, we can’t extract elements of a set s using s[N] where N is a number.\n\n# Uncomment the line below to see what happens\n# s[1]\n\nThis is because sets are not ordered, so the notion of getting the second element (s[1]) is not well defined.\nWe add elements to a set s using s.add.\n\ns.add(100)\ns\n\n\ns.add(\"hello\") # nothing happens, why?\ns\n\nWe can also do set operations.\nConsider the set s from above and the set s2 = {\"hello\", \"world\"}.\n\ns.union(s2): returns a set with all elements in either s or s2\n\ns.intersection(s2): returns a set with all elements in both s and s2\n\ns.difference(s2): returns a set with all elements in s that aren’t in s2\n\ns.symmetric_difference(s2): returns a set with all elements in only one of s and s2\n\n\n\n\nSee exercise 10 in the exercise list.\nAs with tuples and lists, a set function can convert other collections to sets.\n\nx = [1, 2, 3, 1]\nset(x)\n\n\nt = (1, 2, 3, 1)\nset(t)\n\nLikewise, we can convert sets to lists and tuples.\n\nlist(s)\n\n\ntuple(s)"
  },
  {
    "objectID": "tutorials/session_1/python_fundamentals/collections.html#exercises",
    "href": "tutorials/session_1/python_fundamentals/collections.html#exercises",
    "title": "Collections",
    "section": "",
    "text": "In the first cell, try y.append(z).\nIn the second cell try y.extend(z).\nExplain the behavior.\nWhen you are trying to explain use y.append? and y.extend? to see a description of what these methods are supposed to do.\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# your code here\nprint(y)\n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# your code here\nprint(y)\n\n(back to text)\n\n\n\nExperiment with the other two versions of the range function.\n\n# try list(range(a, N)) -- you pick `a` and `N`\n\n\n# try list(range(a, N, d)) -- you pick `a`, `N`, and `d`\n\n(back to text)\n\n\n\nVerify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\n# change first element of t\n\n\n# appending to t\n\n\n# sorting t\n\n\n# reversing t\n\n(back to text)\n\n\n\nChallenging For the tuple foo below, use a combination of zip, range, and len to mimic enumerate(foo).\nVerify that your proposed solution is correct by converting each to a list and checking equality with ==.\nYou can see what the answer should look like by starting with list(enumerate(foo)).\n\nfoo = (\"good\", \"luck!\")\n\n(back to text)\n\n\n\nCreate a new dict which associates stock tickers with its stock price.\nHere are some tickers and a price.\n\nAAPL: 175.96\n\nGOOGL: 1047.43\n\nTVIX: 8.38\n\n\n# your code here\n\n(back to text)\n\n\n\nLook at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n# your code here\n\n(back to text)\n\n\n\nUse Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n# uncomment and use the Inspector or ?\n#china_data.pop()\n\n(back to text)\n\n\n\nExplain what happens to the value you popped.\nExperiment with calling pop twice.\n\n# your code here\n\n(back to text)\n\n\n\nTry creating a set with repeated elements (e.g. {1, 2, 1, 2, 1, 2}).\nWhat happens?\nWhy?\n\n# your code here\n\n(back to text)\n\n\n\nTest out two of the operations described above using the original set we created, s, and the set created below s2.\n\ns2 = {\"hello\", \"world\"}\n\n\n# Operation 1\n\n\n# Operation 2\n\n(back to text)"
  },
  {
    "objectID": "session_1_2/graphs/Untitled1.html",
    "href": "session_1_2/graphs/Untitled1.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport statsmodels.api as sm\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\ncount\n45.000000\n45.000000\n45.000000\n\n\nmean\n41.866667\n52.555556\n47.688889\n\n\nstd\n24.435072\n29.760831\n31.510332\n\n\nmin\n7.000000\n7.000000\n3.000000\n\n\n25%\n21.000000\n26.000000\n16.000000\n\n\n50%\n42.000000\n45.000000\n41.000000\n\n\n75%\n64.000000\n84.000000\n81.000000\n\n\nmax\n81.000000\n100.000000\n97.000000\n\n\n\n\n\n\n\n\ndf.cov()\n\n\n\n\n\n\n\n\nincome\neducation\nprestige\n\n\n\n\nincome\n597.072727\n526.871212\n645.071212\n\n\neducation\n526.871212\n885.707071\n798.904040\n\n\nprestige\n645.071212\n798.904040\n992.901010\n\n\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\n\n\nplt.figure(figsize=(8,6))\nplt.plot(df['education'],df['income'],'o')\nplt.grid()\nplt.xlabel(\"x (Education)\")\nplt.ylabel(\"y (Income)\")\nplt.savefig(\"data_description.png\")\n\n\n\n\n\n\n\n\n\nfor i in [1,2,3]:\n    xvec = np.linspace(10,100)\n\n    plt.figure(figsize=(12,8))\n    plt.plot(df['education'],df['income'],'o')\n\n    plt.plot(xvec, xvec * 0 + 50)\n    if i&gt;=2:\n        plt.plot(xvec, xvec )\n    if i&gt;=3:\n        plt.plot(xvec,  90- 0.6*xvec )\n\n    plt.grid()\n    plt.xlabel(\"x (Education)\")\n    plt.ylabel(\"y (Income)\")\n    plt.savefig(f\"which_line_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ipywidgets import interact\n\n\nimport matplotlib.patches as patches\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nplt.vlines(x, y+h, y, color='red')\n\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"error_0.png\")\n\n\n\n\n\n\n\n\n\nplt.vlines?\n\n\nSignature:\nplt.vlines(\n    x,\n    ymin,\n    ymax,\n    colors=None,\n    linestyles='solid',\n    label='',\n    *,\n    data=None,\n    **kwargs,\n)\nDocstring:\nPlot vertical lines.\nPlot vertical lines at each *x* from *ymin* to *ymax*.\nParameters\n----------\nx : float or array-like\n    x-indexes where to plot the lines.\nymin, ymax : float or array-like\n    Respective beginning and end of each line. If scalars are\n    provided, all lines will have same length.\ncolors : list of colors, default: :rc:`lines.color`\nlinestyles : {'solid', 'dashed', 'dashdot', 'dotted'}, optional\nlabel : str, default: ''\nReturns\n-------\n`~matplotlib.collections.LineCollection`\nOther Parameters\n----------------\n**kwargs : `~matplotlib.collections.LineCollection` properties.\nSee Also\n--------\nhlines : horizontal lines\naxvline: vertical line across the axes\nNotes\n-----\n.. note::\n    In addition to the above described arguments, this function can take\n    a *data* keyword argument. If such a *data* argument is given,\n    the following arguments can also be string ``s``, which is\n    interpreted as ``data[s]`` (unless this raises an exception):\n    *x*, *ymin*, *ymax*, *colors*.\n    Objects passed as **data** must support item access (``data[s]``) and\n    membership test (``s in data``).\nFile:      ~/.local/opt/miniconda/lib/python3.8/site-packages/matplotlib/pyplot.py\nType:      function\n\n\n\n\n\na = 0.1\nb = 1.0\nind = 23\n\n\napprox =  a + b*xvec\n\n# Create figure and axes\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\nplt.plot(df['education'],df['income'],'o')\nplt.plot(xvec, approx, color='red')\n\nx, y = df['education'][ind], df['income'][ind]\nplt.plot(x, y, 'o', color='red' )\np = a+b*x\nplt.grid(True)\nh = abs(p-y)\nif p-y&gt;0:\n    # Create a Rectangle patch\n    rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n    ax.add_patch(rect)\n    \nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.savefig(f\"errors_{1}.png\")\n\n\n\n\n\n\n\n\n\ndef L(a,b):\n    Δ = a + b*df['education'] - df['income']\n    return (Δ**2).sum()\n\n\na = 0.1\nb = 0.8\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_2.png\")\n\n\n\n\n\n\n\n\n\na = 90\nb = -0.6\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_3.png\")\n\n\n\n\n\n\n\n\n\nimport scipy.optimize\n\n\nscipy.optimize.minimize(lambda x: L(x[0], x[1]),np.array([0.5, 0.5]))\n\n      fun: 12480.970174488397\n hess_inv: array([[ 7.14169839e-09, -3.91281920e-09],\n       [-3.91281920e-09,  2.46663613e-09]])\n      jac: array([0.00024414, 0.00012207])\n  message: 'Desired error not necessarily achieved due to precision loss.'\n     nfev: 57\n      nit: 7\n     njev: 19\n   status: 2\n  success: False\n        x: array([10.60350224,  0.59485938])\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red')\n\nplt.grid(True)\nfor ind in range(df.shape[0]):\n    \n    x, y = df['education'][ind], df['income'][ind]\n    p = a+b*x\n\n    h = abs(p-y)\n    if p-y&gt;0:\n        # Create a Rectangle patch\n        rect = patches.Rectangle((x,y),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\n    else:\n        rect = patches.Rectangle((x,y-h),h,h,linewidth=1, color='red', fill=True, alpha=0.05)\n        ax.add_patch(rect)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"errors_4.png\")\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  a + b*xvec\n\n\n# plt.figure(figsize=(8,6))\nfig,ax = plt.subplots(1,figsize=(12,8))\n\n\nplt.plot(df['education'],df['income'],'o', label=f\"L({a,b})={L(a,b)}\")\nplt.plot(xvec, approx, color='red', alpha=0.5)\n\nplt.plot(60, a + b*60, 'o', color='red',)\n\nprint(a+b*60)\nplt.xlim(0,140)\nplt.ylim(0,100)\nplt.legend(loc='upper right')\nplt.savefig(f\"prediction.png\")\n\n45.4\n\n\n\n\n\n\n\n\n\n\na = 10\nb = 0.59\n\napprox =  (a + b*df['education'] - df['income'])\n\nplt.figure(figsize=(12,6))\n\nplt.subplot(121)\nplt.plot(approx)\nplt.grid(False)\nplt.title(\"Residuals\")\n\n\nplt.subplot(122)\ndistplot(approx)\nplt.title(\"Distribution of residuals\")\nplt.grid()\n\nplt.savefig(\"residuals.png\")\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\n(a + b*df['education'] - df['income']).std()\n\n16.842782676352154\n\n\n\n\n\n/home/pablo/.local/opt/miniconda/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f\n\n\nf(0.3)\n\nTypeError: _parse_args() missing 1 required positional argument: 'dfd'\n\n\n\nnp.rand\n\n\nK = 100\nxvec = np.linspace(0,1,K)\ne1 = np.random.randn(K)*0.1\nyvec = 0.1 + xvec*0.4 + e1\ne2 = np.random.randn(K)*0.05\nyvec2 = 0.1 + xvec*(xvec-1)/2 + e2\ne3 = np.random.randn(K)*xvec/2\nyvec3 = 0.1 + xvec + e3\n\nyvec4 = 0.1 + np.sin(xvec*6) + np.random.randn(K)*xvec/2\n\n\nfrom dolo.numeric.processes import VAR1\n\n\nsim = VAR1( ρ=0.8, Σ=0.001).simulate(N=1,T=100)\nyvec4 = 0.1 + xvec*0.4 + sim.ravel()\n\n\nplt.figure(figsize=(18,6))\nplt.subplot(241)\nplt.plot(xvec, yvec,'o')\nplt.plot(xvec, 0.1 + xvec*0.4 )\nplt.ylabel(\"Series\")\nplt.title(\"white noise\")\nplt.subplot(242)\nplt.plot(xvec, yvec2, 'o')\nplt.plot(xvec, yvec2*0)\nplt.title('nonlinear')\nplt.subplot(243)\nplt.plot(xvec, yvec3,'o')\nplt.plot(xvec, 0.1 + xvec)\nplt.title('heteroskedastic')\nplt.subplot(244)\nplt.plot(xvec, yvec4,'o')\nplt.plot(xvec, xvec*0.6)\n\nplt.title('correlated')\n\n\nplt.subplot(245)\nplt.plot(xvec, e1,'o')\nplt.ylabel(\"Residuals\")\nplt.subplot(246)\nplt.plot(xvec, yvec2-0.075, 'o')\n\nplt.subplot(247)\nplt.plot(xvec, e3,'o')\nplt.subplot(248)\nplt.plot(xvec, sim.ravel(),'o')\n\nplt.tight_layout()\n\nplt.savefig(\"residuals_circus.png\")"
  },
  {
    "objectID": "session_1_2/index.html#regressions",
    "href": "session_1_2/index.html#regressions",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Regressions",
    "text": "Regressions"
  },
  {
    "objectID": "session_1_2/index.html#what-is-machine-learning-1",
    "href": "session_1_2/index.html#what-is-machine-learning-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "What is Machine learning?",
    "text": "What is Machine learning?\nDefinition Candidates:\nArthur Samuel: Field of study that gives computers the ability to learn without being explicitly programmed\nTom Mitchell: A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."
  },
  {
    "objectID": "session_1_2/index.html#what-about-artificial-intelligence",
    "href": "session_1_2/index.html#what-about-artificial-intelligence",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "What about artificial intelligence ?",
    "text": "What about artificial intelligence ?\n\n\n\nAIs\n\nthink and learn\nmimmic human cognition"
  },
  {
    "objectID": "session_1_2/index.html#econometrics-vs-machine-learning",
    "href": "session_1_2/index.html#econometrics-vs-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Econometrics vs Machine Learning",
    "text": "Econometrics vs Machine Learning\n\nEconometrics is essentially a subfield of machine learning with a different jargon and a focus on:\n\nstudying properties and validity of results\n\ndata is scarce\ninference\n\nsingling out effects of specific explanatory variables\nestablishing causality\n\nMachine learning:\n\nstructure data\nmake predictions (interpolate data)"
  },
  {
    "objectID": "session_1_2/index.html#data-types",
    "href": "session_1_2/index.html#data-types",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Data types",
    "text": "Data types\n\nstructured:\n\ntabular\n\nlong\nwide\n\n\nunstructured:\n\nfiles\nnetworks\ntext, mails\nimages, sound"
  },
  {
    "objectID": "session_1_2/index.html#tabular-data",
    "href": "session_1_2/index.html#tabular-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Tabular Data",
    "text": "Tabular Data\n\ntabular data"
  },
  {
    "objectID": "session_1_2/index.html#networks",
    "href": "session_1_2/index.html#networks",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Networks",
    "text": "Networks\n\nBanking networks\nProduction network"
  },
  {
    "objectID": "session_1_2/index.html#big-data-1",
    "href": "session_1_2/index.html#big-data-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Big Data",
    "text": "Big Data\n\nBig data:\n\nwide data (K&gt;&gt;N)\nlong data (N&gt;&gt;K)\nheterogenous, unstructured data\n\nMight not even fit in memory\n\nout of core computations\nlearn from a subset of the data"
  },
  {
    "objectID": "session_1_2/index.html#big-subfields-of-machine-learning",
    "href": "session_1_2/index.html#big-subfields-of-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Big Subfields of Machine Learning",
    "text": "Big Subfields of Machine Learning\n\n\n\nTraditional classification\n\nsupervised (labelled data)\n\nregression: predict quantity\nclassification: predict index (categorical variable)\n\nunsupervised (no labels)\n\ndimension reduction\nclustering\n\nsemi-supervised / self-supervised\nreinforcement learning\n\nBazillions of different algorithms: https://scikit-learn.org/stable/user_guide.html\n\n\n\n\n\nregression:\n\nPredict: \\(y = f(x; \\theta)\\)\n\n\n\n\n\nsupervised: regression\n\n\n\n\n\nAge\n\n\nActivity\n\n\nSalary\n\n\n\n\n23\n\n\nExplorer\n\n\n1200\n\n\n\n\n40\n\n\nMortician\n\n\n2000\n\n\n\n\n45\n\n\nMortician\n\n\n2500\n\n\n\n\n33\n\n\nMovie Star\n\n\n3000\n\n\n\n\n35\n\n\nExplorer\n\n\n???\n\n\n\n\n\n\nsupervised: classification\n\nOutput is discrete\nRegular trick: \\(\\sigma(f(x; \\theta))\\) where \\(\\sigma(x)=\\frac{1}{1-e^{-x}}\\)\n\n\n\n\n\nclassification\n\n\n\n\n\nAge\n\n\nSalary\n\n\nActivity\n\n\n\n\n23\n\n\n1200\n\n\nExplorer\n\n\n\n\n40\n\n\n2000\n\n\nMortician\n\n\n\n\n45\n\n\n2500\n\n\nMortician\n\n\n\n\n33\n\n\n3000\n\n\nMovie Star\n\n\n\n\n35\n\n\n3000\n\n\n???\n\n\n\n\n\nunsupervised\n\norganize data without labels\n\ndimension reduction: describe data with less parameters\nclustering: sort data into “similar groups” (exemple)\n\n\n\n\n\nAge\n\n\nSalary\n\n\nActivity\n\n\n\n\n23\n\n\n1200\n\n\nExplorer\n\n\n\n\n40\n\n\n2000\n\n\nMortician\n\n\n\n\n45\n\n\n2500\n\n\nMortician\n\n\n\n\n33\n\n\n3000\n\n\nMovie Star\n\n\n\n\n35\n\n\n3000\n\n\nExplorer\n\n\n\n\n\nunsupervised: clustering\n\n\n\nkmeansclustering\n\n\n\n\nunsupervised: clustering\nWomen buying dresses during the year:"
  },
  {
    "objectID": "session_1_2/index.html#difference-with-traditional-regression",
    "href": "session_1_2/index.html#difference-with-traditional-regression",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\\[\\underbrace{y}_{\\text{explained variable}} = a \\underbrace{x}_{\\text{explanatory variable}} + b\\]"
  },
  {
    "objectID": "session_1_2/index.html#difference-with-traditional-regression-1",
    "href": "session_1_2/index.html#difference-with-traditional-regression-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\\[\\underbrace{y}_{\\text{labels}} = a \\underbrace{x}_{\\text{features}} + b\\]\n\n\n\n\n\n\n\n\nEconometrics\nMachine learning\n\n\n\n\nRegressand / independent variable / explanatory variable\nFeatures\n\n\nRegressor / dependent variable / explained variable\nLabels\n\n\nRegression\nModel Training"
  },
  {
    "objectID": "session_1_2/index.html#difference-with-traditional-regression-2",
    "href": "session_1_2/index.html#difference-with-traditional-regression-2",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Difference with traditional regression",
    "text": "Difference with traditional regression\n\nBig data requires other means to process the data:\n\ndata is long: so many observations \\(x\\) doesn’t fit in the memory\n\nneed to use incremental training method to use only a subsample at a time\n\ndata is wide: so many features, the model is crudely overspecified\n\nneed to build dimension reduction into the objective\n\ndata is nonlinear:\n\nuse nonlinear model (and nonlinear training)\n\ndata is not a simple vector…\n\nsame as nonlinear"
  },
  {
    "objectID": "session_1_2/index.html#long-data",
    "href": "session_1_2/index.html#long-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Long data",
    "text": "Long data\nLong data is characterized by a high number of observations.\n\n\n\n\n\nModern society is gathering a lot of data.\n\nin doesn’t fit in the computer memory so we can’t run a basic regression\n\nIn some cases we would also like to update our model continuously:\n\nincremental regression\n\n\n\nWe need a way to fit a model on a subset of the data at a time."
  },
  {
    "objectID": "session_1_2/index.html#long-data-1",
    "href": "session_1_2/index.html#long-data-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Long data",
    "text": "Long data\n\n\n\nTraditional regression:\n\nfull sample \\(X,Y=(x_i,y_i)_{i=1:N}\\)\nOLS: \\(\\min_{a,b} \\sum_{i=1}^N (a x_i + b - y_i)^2\\)\nclosed-form solution: \\(a = X^{\\prime}X Y\\) and \\(b= ...\\)\nhard to compute if \\(X\\) is very big\n\n\n\n\n\nIncremental learning:\n\ngiven initial \\(a_n\\), \\(b_n\\)\npick \\(N\\) random observations (the batch)\n\nregress them to get new estimate \\(a\\), \\(b\\)\nthis minimizes the square of errors\n\nupdate with learning rate \\(\\beta\\):\n\n\\(a_{n+1} \\leftarrow a_n (1-\\beta_n) + \\beta_n a\\)\n\\(b_{n+1} \\leftarrow b_n (1-\\beta_n) + \\beta_n b\\)\n\nprocess is not biased (that is \\(a\\) converges to the true value) as long as one decreases \\(\\beta\\) sufficiently fast over time (ex: \\(\\beta_n=\\frac{1}{n}\\))"
  },
  {
    "objectID": "session_1_2/index.html#formalisation-a-typical-machine-learning-task",
    "href": "session_1_2/index.html#formalisation-a-typical-machine-learning-task",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Formalisation: a typical machine learning task",
    "text": "Formalisation: a typical machine learning task\n\nvector of unknowns: \\(\\theta=(a,b)\\)\ndataset \\(X,Y=(x_i,y_i)_{i=1:N}\\)\nfor a random draw \\(\\omega = (a_{\\sigma(i)}, b_{\\sigma(i)})_{i=[1,N]} \\subset (X,Y)\\)\n\n\\(\\omega\\) is just a random batch of size \\(N\\)\n\ndefine the empirical risk (or empirical cost) \\[\\xi(\\theta, \\omega) = \\sum_{(x,y) \\in \\omega} (y - (a x + b))^2\\]\nwe want to minimize theoretical risk: \\[\\Xi(\\theta) = \\mathbb{E} \\left[ \\xi(\\theta, \\omega)\\right]\\]"
  },
  {
    "objectID": "session_1_2/index.html#training-gradient-descent",
    "href": "session_1_2/index.html#training-gradient-descent",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Training: Gradient Descent",
    "text": "Training: Gradient Descent\n\n\n\nHow do we minimize a function \\(f(a,b)\\)?\nGradient descent:\n\n\\(a_k, b_k\\) given\ncompute the gradient (slope) \\(\\nabla_{a,b} f = \\begin{bmatrix} \\frac{\\partial f}{\\partial a} \\\\\\\\ \\frac{\\partial f}{\\partial b}\\end{bmatrix}\\)\nfollow the steepest slope: (Newton Algorithm)\n\n\\[ \\begin{bmatrix} a_{k+1} \\\\\\\\ b_{k+1} \\end{bmatrix} \\leftarrow  \\begin{bmatrix} a_k \\\\\\\\ b_k \\end{bmatrix} - \\nabla_{a,b} f\\]\n\nbut not too fast: use learning rate \\(\\lambda\\): \\[ \\begin{bmatrix} a_{k+1} \\\\\\\\ b_{k+1} \\end{bmatrix} \\leftarrow  (1-\\lambda) \\begin{bmatrix} a_k \\\\\\\\ b_k \\end{bmatrix} + \\lambda (- \\nabla_{a,b} f )\\]"
  },
  {
    "objectID": "session_1_2/index.html#not-everything-goes-wrong-all-the-time",
    "href": "session_1_2/index.html#not-everything-goes-wrong-all-the-time",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Not everything goes wrong all the time",
    "text": "Not everything goes wrong all the time\n \n\nIn practice, choosing the right learning rate \\(\\lambda\\) is crucial\n\\(\\lambda\\) is a metaparameter of the model training."
  },
  {
    "objectID": "session_1_2/index.html#wide-data",
    "href": "session_1_2/index.html#wide-data",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wide data",
    "text": "Wide data\n\nWide Data is characterized by a high number of features compared to the number of observations.\n\n\nProblem:\n\nwith many independent variables \\(x_1, ... x_K\\), \\(K&gt;&gt;N\\) and one dependent variable \\(y\\) the regression \\[y = a_1 x_1 + a_2 x_2 + \\cdots + a_N x_N + b\\] is grossly overidentified."
  },
  {
    "objectID": "session_1_2/index.html#wide-data-regression",
    "href": "session_1_2/index.html#wide-data-regression",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wide data regression",
    "text": "Wide data regression\n\nMain Idea: penalize non-zero coefficients to encourage scarcity\n\nRidge: \\[\\Xi(a,b) = \\min_{a,b} \\sum_{i=1}^N ( \\sum_j a_j x_j + b - y_i)^2 + \\mu \\sum_i |a_i|^2\\]\n\nshrinks parameters towards zero\nclosed form\n\nLasso: \\[\\Xi(a,b) = \\min_{a,b} \\sum_{i=1}^N (\\sum_j a_j x_j + b - y_i)^2 + \\mu \\sum_i |a_i|\\]\n\neliminates zero coefficients\n\nElastic: Ridge + Lasso\n\nRemarks:\n\n\\(\\mu\\) is called a regularization term.\nit is a hyperparameter\n\\(\\mu \\uparrow\\), bias increases, variance decreases"
  },
  {
    "objectID": "session_1_2/index.html#training",
    "href": "session_1_2/index.html#training",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Training",
    "text": "Training\nTo perform Lasso and ridge regression:\n\nAI approach:\n\nminimize objective \\(\\Xi(a,b)\\) directly.\napproach is known as (stochastic) Gradient Descent\n\nUse special algorithms"
  },
  {
    "objectID": "session_1_2/index.html#example-imf-challenge",
    "href": "session_1_2/index.html#example-imf-challenge",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Example: IMF challenge",
    "text": "Example: IMF challenge\n\nAn internal IMF challenge to predict crises in countries\nLots of different approaches\nLots of data:\n\nwhich one is relevant\nmachine must select relevant informations\n\nExample: Lasso Regressions and Forecasting Models in Applied Stress Testing by Jorge A. Chan-Lau\n\nin a given developing country\ntries to predict probability of default in various sectors"
  },
  {
    "objectID": "session_1_2/index.html#nonlinear-regression-1",
    "href": "session_1_2/index.html#nonlinear-regression-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Nonlinear Regression",
    "text": "Nonlinear Regression\n\nSo far, we have assumed,\n\n\\(y_i = a + b x_i\\)\n\\(y_i = a + b x_i + μ_1 (a^2 + b^2) + μ_2 (|a| + |b|)\\)\ndefined \\(\\Xi(a,b)\\) and tried to minimize it\n\nSame approach works for fully nonlinear models\n\n\\(y_i = a x_i + a^2 x_i^2 + c\\)\n\\(y_i = \\varphi(x; \\theta)\\) ()\n\nSpecial case: neural network:\n\nprimer tensor playground"
  },
  {
    "objectID": "session_1_2/index.html#how-to-evaluate-the-machine-learning",
    "href": "session_1_2/index.html#how-to-evaluate-the-machine-learning",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "how to evaluate the machine learning",
    "text": "how to evaluate the machine learning\nIn machine learning we can’t perform statistical inference easily. How do we assess the validity of a model?\n\nBasic idea (independent of how complex the algorithm is)\n\nseparate data in\n\ntraining set (in-sample)\ntest set (out of sample)\n\ntrain using only the training set\nevaluate performance on the test set\n\nPerformance can be:\n\nfitness, number of classification errors (false positive, false negative)"
  },
  {
    "objectID": "session_1_2/index.html#how-to-evaluate-the-machine-learning-1",
    "href": "session_1_2/index.html#how-to-evaluate-the-machine-learning-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "how to evaluate the machine learning",
    "text": "how to evaluate the machine learning\nIn case the training method depends itself on many parameters (the hyperparameters) we make three samples instead:\n\ntraining set (in-sample)\nvalidation set (to update hyperparameters)\ntest set (out of sample)\n\nGolden Rule: the test set should not be used to estimate the model, and should not affect the choice any training parameter (hyperparameter)."
  },
  {
    "objectID": "session_1_2/index.html#section",
    "href": "session_1_2/index.html#section",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "",
    "text": "Traintest\nThe test set reveals that orange model is overfitting."
  },
  {
    "objectID": "session_1_2/index.html#how-to-choose-the-validation-set",
    "href": "session_1_2/index.html#how-to-choose-the-validation-set",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "How to choose the validation set?",
    "text": "How to choose the validation set?\n\nHoldout validation approach:\n\nkeeps x% of the data for the training, (100-x)% for the test\n\nHow to choose the sizes of the subsets?\n\nsmall dataset: 90-10\nbig data set: 70-30 (we can afford to waste more training data for the test)\n\n\n\n\nProblem:\n\nare we sure the validation size is correct? Are the results determined by an (un-) lucky draw?\na problem for smaller datasets"
  },
  {
    "objectID": "session_1_2/index.html#how-to-choose-the-validation-set-1",
    "href": "session_1_2/index.html#how-to-choose-the-validation-set-1",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "How to choose the validation set?",
    "text": "How to choose the validation set?\nA more robust solution: \\(k\\)-fold validation\n\n\n\nsplit dataset randomly in \\(K\\) subsets of equal size \\(S_1, ... S_K\\)\nuse subset \\(S_i\\) as test set, the rest as training set, compute the score\ncompare the scores obtained for all \\(i\\in[1,K]\\)\n\nthey should be similar (compute standard deviation)\n\naverage them"
  },
  {
    "objectID": "session_1_2/index.html#wait",
    "href": "session_1_2/index.html#wait",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "Wait",
    "text": "Wait\n\nAnother library to do regression ?\nstatsmodels:\n\nexplanatory analysis\nstatistical tests\nformula interface for many estimation algorithms\n\nstateless approach (model.fit() returns another object)\n\n\nlinearmodels\n\nextends statsmodels (very similar interface)\n\n(panel models, IV, systems…)\n\n\nsklearn:\n\nprediction\nfaster for big datasets\ncommon interface for several machine learning tasks\n\nstateful approach (model is modified by .fit operation)\n\ndefacto standard for machine learning"
  },
  {
    "objectID": "session_1_2/index.html#in-practice",
    "href": "session_1_2/index.html#in-practice",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "In practice",
    "text": "In practice\n\n\nBasic sklearn workflow:\n\n\nimport data\n\nfeatures: a matrix X (2d numpy array)\nlabels: a vector y (1d numpy array)\n\nsplit the data, between training and test datasets\n\nsplit needs to be random to avoid any bias\n\nnormalize the data\n\nmost ML algorithm are sensitive to scale\n\ncreate a model (independent from data)\ntrain the model on training dataset\nevaluate accuracy on test dataset (here \\(R^2\\))\nuse the model to make predictions\n\n\nThe workflow is always the same, no matter what the model is\n\ntry sklearn.linear_model.Lasso instead of LinearRegression\n\n\nfrom sklearn.datasets import load_diabetes\ndataset = load_diabetes()\nX = dataset['data']\ny = dataset['target']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)\n\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\nmodel.score(X_test, y_test)\nmodel.predict(X_new)"
  },
  {
    "objectID": "session_1_2/index.html#k-fold-validation-with-sklearn",
    "href": "session_1_2/index.html#k-fold-validation-with-sklearn",
    "title": "Introduction to Machine Learning (1/2)",
    "section": "\\(k\\)-fold validation with sklearn",
    "text": "\\(k\\)-fold validation with sklearn\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=10)\n\nfor train_index, test_index in kf.split(X):\n   X_train, X_test = X[train_index], X[test_index]\n   y_train, y_test = y[train_index], y[test_index]\n\n   ## train a model in X_train, y_train\n   ## test it on X_test, y_test"
  },
  {
    "objectID": "exercises/python.html",
    "href": "exercises/python.html",
    "title": "Python Basics",
    "section": "",
    "text": "(adapted from Quantecon)"
  },
  {
    "objectID": "exercises/python.html#basics",
    "href": "exercises/python.html#basics",
    "title": "Python Basics",
    "section": "Basics",
    "text": "Basics\n\nExercise 1 Run the following code in the python interpreter:\ndef say_hello(name):\n    \"\"\"This function prints morning greetings\"\"\"\n\n    print(f\"Good morning {name}!\\n\")\n\n    # we can import libraries\n    import datetime\n    t = datetime.datetime.now()\n\n    # blocks are defined by indentation and colons\n    if (t.hour,t.min) &lt;= (9,15):\n        print(\"All good?\\n\")\n    else:\n        print(\"Time to get started?\\n\")\n\n\nsay_hello(\"Pablo\")\n\n\nExercise 2 What do you think the value of z is after running the code below?\n\nz = 3\nz = z + 4\nprint(\"z is\", z)\n\nz is 7\n\n\n\n\n# your response there\n\n\nExercise 3 Read about what the len function does (by writing len?).\nWhat will it produce if we give it the variable x?\nCheck whether you were right by running the code len(x).\n\n\n# your code here\n\n\nExercise 4 We can use our introspection skills to investigate a package’s contents.\nIn the cell below, use tab completion to find a function from the time module that will display the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the function you found) to see information about that function and then call the function.\nLook for something to do with the word local\n\n\nimport time\n# your code here\n\n\nExercise 5 The code below is invalid Python code (once uncommented)\n\n\n# x = 'What's wrong with this string'"
  },
  {
    "objectID": "exercises/python.html#collections",
    "href": "exercises/python.html#collections",
    "title": "Python Basics",
    "section": "Collections",
    "text": "Collections\n\nExercise 6 In the first cell, try y.append(z).\nIn the second cell try y.extend(z).\nExplain the behavior.\nWhen you are trying to explain use y.append? and y.extend? to see a description of what these methods are supposed to do.\n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# \n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# \n\n\nExercise 7 Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\n\nt = (1,2,3,4)\n\n\nExercise 8 Look at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n\n# your code here\n\n\nExercise 9 Use Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n\n# uncomment and use the Inspector or ?\n#china_data.pop()\n\n\nExercise 10 Explain what happens to the value you popped.\nExperiment with calling pop twice.\n\n\n# your code here"
  },
  {
    "objectID": "exercises/python.html#control",
    "href": "exercises/python.html#control",
    "title": "Python Basics",
    "section": "Control",
    "text": "Control\n\nExercise 11 Run the following two variations on the code with only a single change in the indentation.\nAfter, modify the x to print 3 and then 2, 3 instead.\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\n    print(\"2\")\nprint(\"3\")\n\n1\n2\n3\n\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\nprint(\"2\") # changed the indentation\nprint(\"3\")\n\n1\n2\n3\n\n\n\nExercise 12 Write a for loop that uses the lists of cities and states below to print the same “{city} is in {state}” using a zip instead of an enumerate.\n\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n\nfor i,c in enumerate(cities):\n    print(c, \" : \", states[i])\n\nPhoenix  :  Arizona\nAustin  :  Texas\nSan Diego  :  California\nNew York  :  New York\n\n\n\n# your code here"
  },
  {
    "objectID": "exercises/pushups_1.html",
    "href": "exercises/pushups_1.html",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "See “Check Your Understanding” from Basics and Collections\n\n\nBelow this cell, add\n\nA Markdown cell with\n\n\n\ntwo levels of headings;\n\na numbered list (We ask for a list in Markdown, not a Python list object);\n\nan unnumbered list (again not a Python list object);\n\ntext with a * and a - sign (hint: look at this cell and escape characters)\n\nbackticked code (see https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n\n\nA Markdown cell with\n\n\n\nthe quadratic formula embedded in the cell using LaTeX\n\n\n\n\nComplete the following code, which sets up variables a, b, and c, to find the roots using the quadratic formula.\n\\[\nx=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n\\]\nNote: because there are two roots, you will need to calculate two values of x\n\na = 1.0\nb = 2.0\nc = 1.0\n# Your code goes here\n\n\n\n\nIn the cell below, use tab completion to find a function from the time module that displays the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the name of the function you found) to see information about that function, then call the function. (Hint: look for something involving the word local).\n\nimport time\n# Your code goes here\n# time. # uncomment and hit &lt;TAB&gt; to see functions\n\nHint: if you are using an online jupyter server, the time will be based on the server settings. If it doesn’t match your location, don’t worry about it.\n\n\n\nCreate the following variables:\n\nD: A floating point number with the value 10,000\n\nr: A floating point number with the value 0.025\n\nT: An integer with the value 30\n\nCompute the present discounted value of a payment (D) made in T years, assuming an interest rate of 2.5%. Save this value to a new variable called PDV and print your output.\nHint: The formula is\n\\[\n\\text{PDV} = \\frac{D}{(1 + r)^T}\n\\]\n\n# Your code goes here\n\n\n\n\nHow could you use the variables x and y to create the sentence Hello World ?\nHint: Think about how to represent a space as a string.\n\nx = \"Hello\"\ny = \"World\"\n# Your code goes here\n\n\n\n\nSuppose you are working with price data and come across the value \"€6.50\".\nWhen Python tries to interpret this value, it sees the value as the string \"€6.50\" instead of the number 6.50. (Quiz: why is this a problem? Think about the examples above.)\nIn this exercise, your task is to convert the variable price below into a number.\nHint: Once the string is in a suitable format, you can call float(clean_price) to make it a number.\n\nprice = \"€6.50\"\n# Your code goes here\n\n\n\n\nUse Python formatting (e.g. print(f\"text {somecode}\") where somecode is a valid expression or variable name) to produce the following output.\nThe 1st quarter revenue was $110M\nThe 2nd quarter revenue was $95M\nThe 3rd quarter revenue was $100M\nThe 4th quarter revenue was $130M\n\n# Your code goes here\n\n\n\n\nDefine two lists y and z.\nThey can contain anything you want.\nCheck what happens when you do y + z. When you have finished that, try 2 * x and x * 2 where x represents the object you created from y + z.\nBriefly explain.\n\ny = [] # fill me in!\nz = [] # fill me in!\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-1",
    "href": "exercises/pushups_1.html#question-1",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Below this cell, add\n\nA Markdown cell with\n\n\n\ntwo levels of headings;\n\na numbered list (We ask for a list in Markdown, not a Python list object);\n\nan unnumbered list (again not a Python list object);\n\ntext with a * and a - sign (hint: look at this cell and escape characters)\n\nbackticked code (see https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n\n\nA Markdown cell with\n\n\n\nthe quadratic formula embedded in the cell using LaTeX"
  },
  {
    "objectID": "exercises/pushups_1.html#question-2",
    "href": "exercises/pushups_1.html#question-2",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Complete the following code, which sets up variables a, b, and c, to find the roots using the quadratic formula.\n\\[\nx=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n\\]\nNote: because there are two roots, you will need to calculate two values of x\n\na = 1.0\nb = 2.0\nc = 1.0\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-3",
    "href": "exercises/pushups_1.html#question-3",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "In the cell below, use tab completion to find a function from the time module that displays the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the name of the function you found) to see information about that function, then call the function. (Hint: look for something involving the word local).\n\nimport time\n# Your code goes here\n# time. # uncomment and hit &lt;TAB&gt; to see functions\n\nHint: if you are using an online jupyter server, the time will be based on the server settings. If it doesn’t match your location, don’t worry about it."
  },
  {
    "objectID": "exercises/pushups_1.html#question-4",
    "href": "exercises/pushups_1.html#question-4",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Create the following variables:\n\nD: A floating point number with the value 10,000\n\nr: A floating point number with the value 0.025\n\nT: An integer with the value 30\n\nCompute the present discounted value of a payment (D) made in T years, assuming an interest rate of 2.5%. Save this value to a new variable called PDV and print your output.\nHint: The formula is\n\\[\n\\text{PDV} = \\frac{D}{(1 + r)^T}\n\\]\n\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-5",
    "href": "exercises/pushups_1.html#question-5",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "How could you use the variables x and y to create the sentence Hello World ?\nHint: Think about how to represent a space as a string.\n\nx = \"Hello\"\ny = \"World\"\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-6",
    "href": "exercises/pushups_1.html#question-6",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Suppose you are working with price data and come across the value \"€6.50\".\nWhen Python tries to interpret this value, it sees the value as the string \"€6.50\" instead of the number 6.50. (Quiz: why is this a problem? Think about the examples above.)\nIn this exercise, your task is to convert the variable price below into a number.\nHint: Once the string is in a suitable format, you can call float(clean_price) to make it a number.\n\nprice = \"€6.50\"\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-7",
    "href": "exercises/pushups_1.html#question-7",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Use Python formatting (e.g. print(f\"text {somecode}\") where somecode is a valid expression or variable name) to produce the following output.\nThe 1st quarter revenue was $110M\nThe 2nd quarter revenue was $95M\nThe 3rd quarter revenue was $100M\nThe 4th quarter revenue was $130M\n\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1.html#question-8",
    "href": "exercises/pushups_1.html#question-8",
    "title": "Python Pushups (1)",
    "section": "",
    "text": "Define two lists y and z.\nThey can contain anything you want.\nCheck what happens when you do y + z. When you have finished that, try 2 * x and x * 2 where x represents the object you created from y + z.\nBriefly explain.\n\ny = [] # fill me in!\nz = [] # fill me in!\n# Your code goes here"
  },
  {
    "objectID": "exercises/pushups_1_correction.html",
    "href": "exercises/pushups_1_correction.html",
    "title": "Problem Set 1",
    "section": "",
    "text": "See “Check Your Understanding” from Basics and Collections\n\n\nBelow this cell, add\n\nA Markdown cell with\n\n\n\ntwo levels of headings;\n\na numbered list (We ask for a list in Markdown, not a Python list object);\n\nan unnumbered list (again not a Python list object);\n\ntext with a * and a - sign (hint: look at this cell and escape characters)\n\nbackticked code (see https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n\n\nA Markdown cell with\n\n\n\nthe quadratic formula embedded in the cell using LaTeX\n\nresponse:"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-1",
    "href": "exercises/pushups_1_correction.html#question-1",
    "title": "Problem Set 1",
    "section": "",
    "text": "Below this cell, add\n\nA Markdown cell with\n\n\n\ntwo levels of headings;\n\na numbered list (We ask for a list in Markdown, not a Python list object);\n\nan unnumbered list (again not a Python list object);\n\ntext with a * and a - sign (hint: look at this cell and escape characters)\n\nbackticked code (see https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n\n\nA Markdown cell with\n\n\n\nthe quadratic formula embedded in the cell using LaTeX\n\nresponse:"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#is-a-rose",
    "href": "exercises/pushups_1_correction.html#is-a-rose",
    "title": "Problem Set 1",
    "section": "is a rose",
    "text": "is a rose\n\nis a rose\n\nbrexit\nis brexit\nis brexit\n\nHere is nice quadratic formula: \\[\nx=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n\\]"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-2",
    "href": "exercises/pushups_1_correction.html#question-2",
    "title": "Problem Set 1",
    "section": "Question 2",
    "text": "Question 2\nComplete the following code, which sets up variables a, b, and c, to find the roots using the quadratic formula.\n\\[\nx=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n\\]\nNote: because there are two roots, you will need to calculate two values of x\n\na = 1.0\nb = 2.0\nc = 1.0\n# we need the square root function\nfrom math import sqrt\n\nx1 = -b+sqrt(b**2-4*a*c)/(2*a)\nx2 = -b-sqrt(b**2-4*a*c)/(2*a)\n\nprint(f\"The two roots are {x1} and {x2}\")\n\nThe two roots are -2.0 and -2.0"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-3",
    "href": "exercises/pushups_1_correction.html#question-3",
    "title": "Problem Set 1",
    "section": "Question 3",
    "text": "Question 3\nIn the cell below, use tab completion to find a function from the time module that displays the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the name of the function you found) to see information about that function, then call the function. (Hint: look for something involving the word local).\n\nimport time\n# Your code goes here\n# time. # uncomment and hit &lt;TAB&gt; to see functions\n\ntime.localtime()\n\ntime.struct_time(tm_year=2023, tm_mon=2, tm_mday=7, tm_hour=23, tm_min=15, tm_sec=33, tm_wday=1, tm_yday=38, tm_isdst=0)\n\n\nHint: if you are using an online jupyter server, the time will be based on the server settings. If it doesn’t match your location, don’t worry about it."
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-4",
    "href": "exercises/pushups_1_correction.html#question-4",
    "title": "Problem Set 1",
    "section": "Question 4",
    "text": "Question 4\nCreate the following variables:\n\nD: A floating point number with the value 10,000\n\nr: A floating point number with the value 0.025\n\nT: An integer with the value 30\n\nCompute the present discounted value of a payment (D) made in T years, assuming an interest rate of 2.5%. Save this value to a new variable called PDV and print your output.\nHint: The formula is\n\\[\n\\text{PDV} = \\frac{D}{(1 + r)^T}\n\\]\n\n# Your code goes here\nD = 10.0\nr = 0.025\nT = 30\n\nPDV = D/(1+r)**T\n\nf\"Present discount factor is: {PDV: .2f}\"   # the .2f is an instruction to limit the number of float numbers\n\n'Present discount factor is:  4.77'"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-5",
    "href": "exercises/pushups_1_correction.html#question-5",
    "title": "Problem Set 1",
    "section": "Question 5",
    "text": "Question 5\nHow could you use the variables x and y to create the sentence Hello World ?\nHint: Think about how to represent a space as a string.\n\nx = \"Hello\"\ny = \"World\"\n# Your code goes here\n\nx+\" \"+y\n\n'Hello World'"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-6",
    "href": "exercises/pushups_1_correction.html#question-6",
    "title": "Problem Set 1",
    "section": "Question 6",
    "text": "Question 6\nSuppose you are working with price data and come across the value \"€6.50\".\nWhen Python tries to interpret this value, it sees the value as the string \"€6.50\" instead of the number 6.50. (Quiz: why is this a problem? Think about the examples above.)\nIn this exercise, your task is to convert the variable price below into a number.\nHint: Once the string is in a suitable format, you can call float(clean_price) to make it a number.\n\nprice = \"€6.50\"\n# Your code goes here\n\n# remove the euro symbol\nprice[1:]\ns = price.strip(\"€\")\n\nfloat(s)\n\n6.5"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-7",
    "href": "exercises/pushups_1_correction.html#question-7",
    "title": "Problem Set 1",
    "section": "Question 7",
    "text": "Question 7\nUse Python formatting (e.g. print(f\"text {somecode}\") where somecode is a valid expression or variable name) to produce the following output.\nThe 1st quarter revenue was $110M\nThe 2nd quarter revenue was $95M\nThe 3rd quarter revenue was $100M\nThe 4th quarter revenue was $130M\n\nns = [110, 95, 100, 130]\nqs = [\"1st\", \"2nd\", \"3rd\", \"4th\"]\n\n\nfor i in [0, 1, 2, 3]:\n    q = qs[i]\n    n = ns[i]\n    s = f\"The {q} quarter revenue was {n}M\"\n    print(s)\n\nThe 1st quarter revenue was 110M\nThe 2nd quarter revenue was 95M\nThe 3rd quarter revenue was 100M\nThe 4th quarter revenue was 130M"
  },
  {
    "objectID": "exercises/pushups_1_correction.html#question-8",
    "href": "exercises/pushups_1_correction.html#question-8",
    "title": "Problem Set 1",
    "section": "Question 8",
    "text": "Question 8\nDefine two lists y and z.\nThey can contain anything you want.\nCheck what happens when you do y + z. When you have finished that, try 2 * x and x * 2 where x represents the object you created from y + z.\nBriefly explain.\n\ny = [1,2,3,4,5] # fill me in!\nz = [\"once\", \"I\", \"caught\", \"a\", \"fish\", \"alive\"] # fill me in!\n# Your code goes here\n\n[1, 2, 3, 4, 5, 'once', 'I', 'caught', 'a', 'fish', 'alive']\n\n\n\nx = y+z # concatenates the two strings\nx\n\n[1, 2, 3, 4, 5, 'once', 'I', 'caught', 'a', 'fish', 'alive']\n\n\n\n2*x # repeats the list twice\n\n[1,\n 2,\n 3,\n 4,\n 5,\n 'once',\n 'I',\n 'caught',\n 'a',\n 'fish',\n 'alive',\n 1,\n 2,\n 3,\n 4,\n 5,\n 'once',\n 'I',\n 'caught',\n 'a',\n 'fish',\n 'alive']"
  },
  {
    "objectID": "session_1_3/graphs/inference.html",
    "href": "session_1_3/graphs/inference.html",
    "title": "AI for Research",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\ndef generate_dataset(μ1, μ2, α, β, σ, N=10):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    return pd.DataFrame({'x': xvec, 'y': yvec})\n\n\ndf = generate_dataset(0.0, 1.0, 0.1, 0.8, 0.1)\n\n\nplt.plot(df['x'], df['y'], 'o')\nplt.grid()\n\n\n\n\n\n\n\n\n\ndef plot_distribution(α, β, σ, N=100000, μ1=0.0, μ2=1.0):\n    xvec = np.random.uniform(μ1, μ2, N)\n    yvec = α + β*xvec + np.random.normal(size=N)*σ\n    plt.plot(xvec, yvec, '.r', alpha=0.005)\n    plt.plot(xvec, α + β*xvec, color='black')\n\n# missing ridge line\n\n\nimport statsmodels\n\n\nμ1 = 0\nμ2 = 1.0\nα = 0.1\nβ = 0.8\nσ = 0.2\nN = 20\nK = 1000\n\n\nimport statsmodels.formula.api as smf\n\n\ndf = generate_dataset(μ1, μ2, α, β, σ, N=N)\n\n\nres = smf.ols(formula='y ~ x + 1', data=df).fit()\nparams = res.params\nαhat = params['Intercept']\nβhat = params['x']\nσhat = res.resid.std()\n\n\nres.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ny\nR-squared:\n0.692\n\n\nModel:\nOLS\nAdj. R-squared:\n0.675\n\n\nMethod:\nLeast Squares\nF-statistic:\n40.48\n\n\nDate:\nTue, 26 Jan 2021\nProb (F-statistic):\n5.41e-06\n\n\nTime:\n04:02:36\nLog-Likelihood:\n7.6662\n\n\nNo. Observations:\n20\nAIC:\n-11.33\n\n\nDf Residuals:\n18\nBIC:\n-9.341\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.1210\n0.077\n1.565\n0.135\n-0.041\n0.283\n\n\nx\n0.7941\n0.125\n6.362\n0.000\n0.532\n1.056\n\n\n\n\n\n\nOmnibus:\n1.410\nDurbin-Watson:\n1.507\n\n\nProb(Omnibus):\n0.494\nJarque-Bera (JB):\n0.890\n\n\nSkew:\n-0.081\nProb(JB):\n0.641\n\n\nKurtosis:\n1.979\nCond. No.\n4.20\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nres.predict(df['x'])\n\n0     0.326200\n1     0.211704\n2     0.798819\n3     0.603306\n4     0.573319\n5     0.823919\n6     0.740622\n7     0.503227\n8     0.292622\n9     0.489566\n10    0.138720\n11    0.355157\n12    0.594171\n13    0.883917\n14    0.266229\n15    0.827021\n16    0.912376\n17    0.163088\n18    0.684858\n19    0.732782\ndtype: float64\n\n\n\nfor i in [1,2,3]:\n    \n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {α:.2f} + {β:.2f} x + {σ:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n\n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    if i&gt;=3:\n        plt.plot(df['x'], res.predict(), label=f'$\\hat{{α}}={αhat:.2f}; \\hat{{β}}={βhat:.2f}$')\n        plt.legend(loc='lower right')\n    plt.title(\"Random Draw\")\n    plt.grid()\n    \n    plt.savefig(f\"regression_uncertainty_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scipy.stats\n\n\ndatasets = [generate_dataset(μ1, μ2, αhat, βhat, σhat, N=N) for i in range(K)]\nall_params = [smf.ols(formula='x ~ y + 1', data=df).fit() for df in datasets]\nαvec = np.array( [e.params['Intercept'] for e in all_params] )\nβvec = np.array( [e.params['y'] for e in all_params] )\n\n\ngkd = scipy.stats.kde.gaussian_kde(βvec)\n\n\nfor i in [1,2,3,4,5,6,7,8,9,10,100]:\n\n    fig = plt.figure(figsize=(10,14))\n    plt.subplot(311)\n    plot_distribution(0.1, 0.8, 0.2)\n    plt.grid()\n    plt.title(f\"True Distribution: $y = {αhat:.2f} + {βhat:.2f} x + {σhat:.2f} u$\")\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    \n    plt.subplot(312)\n    plt.xlim(0,1)\n    plt.ylim(-0.5, 1.5)\n    df = datasets[i]\n    if i&gt;=2:\n        plt.plot(df['x'], df['y'], 'o')\n    plt.title(\"Random Draw\")\n    plt.grid()\n\n    plt.subplot(313)\n    if i==3:\n        plt.plot(βvec[i], βvec[i]*0, 'o')\n    if i&gt;4:\n        plt.plot(βvec[3:i], βvec[3:i]*0, 'o')\n    if i&gt;10:\n        xx = np.linspace(0.2, 1.4, 10000)\n        plt.plot( βvec, gkd.pdf(βvec), '.')\n    plt.title(\"Distribution of β\")\n    plt.xlim(0.2, 1.4)\n    plt.ylim(-0.1, 4)\n    plt.grid()\n\n    plt.tight_layout()\n\n    plt.savefig(f\"random_estimates_{i}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot( βvec, βvec*0, 'o')"
  }
]