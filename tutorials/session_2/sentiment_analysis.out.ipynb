{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "The ultimate goal of this exercise consists performing the same\n",
        "exercise, namely sentiment analysis, using traditional NLP and GPT-4.\n",
        "\n",
        "## The Dataset\n",
        "\n",
        "We use the [News Sentiment\n",
        "Dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset)\n",
        "from Kaggle."
      ],
      "id": "60b42a82-6a19-4021-a5e0-1930902b7b33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'tutorials/session_2'\n",
            "/home/pablo/Teaching/escp/ai_for_research/tutorials/session_2"
          ]
        }
      ],
      "source": [
        "# cd tutorials/session_2"
      ],
      "id": "cell-3"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'/home/pablo/Teaching/escp/ai_for_research/tutorials/session_2'"
            ]
          }
        }
      ],
      "source": [
        "pwd"
      ],
      "id": "cell-4"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment_analysis_correction.ipynb  sentiment_analysis.ipynb*  Tweets.csv*"
          ]
        }
      ],
      "source": [
        "ls"
      ],
      "id": "cell-5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Import Dataset as a pandas dataframe**"
      ],
      "id": "aaa8b4ba-26ba-4098-bca0-d2c561e24b3c"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "df = pandas.read_csv(\"Tweets.csv\")"
      ],
      "id": "cell-7"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "cell-8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Describe Dataset (text and graphs)**"
      ],
      "id": "253193c6-372b-44fb-8638-90151f48d8dd"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.describe()"
      ],
      "id": "cell-10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "np.int64(27481)"
            ]
          }
        }
      ],
      "source": [
        "df['sentiment'].unique()\n",
        "df['sentiment'].count()\n",
        "[(e,sum(df['sentiment']==e)) for e in df['sentiment'].unique()]\n"
      ],
      "id": "cell-11"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     11118\n",
              "positive     8582\n",
              "negative     7781\n",
              "Name: count, dtype: int64"
            ]
          }
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "id": "cell-12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Split Dataset into training, validation and test set. What is the\n",
        "    purpose of the validation set?**"
      ],
      "id": "49f39de8-a776-4644-8d6c-2f784c59605a"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "id": "cell-14"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.3)"
      ],
      "id": "cell-15"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "textID           0.699975\n",
              "text             0.699964\n",
              "selected_text    0.699964\n",
              "sentiment        0.699975\n",
              "dtype: float64"
            ]
          }
        }
      ],
      "source": [
        "train_df.count() / df.count()"
      ],
      "id": "cell-16"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Mining\n",
        "\n",
        "1.  **Extract features from the training dataset. What do you do with\n",
        "    non-words / punctuation?**\n",
        "\n",
        "2.  **Convert occurrencies to frequencies. Make another version with\n",
        "    tf-idf.**\n",
        "\n",
        "3.  **Choose a classifier to predict the sentiment on the *validation*\n",
        "    set. Compute the confusion matrix.**\n",
        "\n",
        "## Sentiment Analysis using GPT completion\n",
        "\n",
        "1.  **Setup an openai key. Explore openai *completion* API.**"
      ],
      "id": "e7ea11a4-6904-42db-8c9a-de642252d055"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai"
      ],
      "id": "cell-26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai"
      ],
      "id": "cell-27"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'1.3.5'"
            ]
          }
        }
      ],
      "source": [
        "# make sure we have the right version\n",
        "from openai import version\n",
        "openai.version.VERSION"
      ],
      "id": "cell-28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = \"\""
      ],
      "id": "cell-29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Design a prompt to extract the sentiment from a tweet. Test it on\n",
        "    very few tweets from the training dataset. Propose different\n",
        "    versions.**\n",
        "\n",
        "2.  **Write a function which takes in: the prompt template, the tweet\n",
        "    text and returns the sentiment as an integer.**"
      ],
      "id": "e37123a5-6467-43af-a174-2cab8bc12175"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "bbank",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  }
}