{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Openai"
      ],
      "id": "7c799ed1-507e-4336-955c-e727e0485d37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = \"\" # set the openAI api key"
      ],
      "id": "cell-1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## REST API\n",
        "\n",
        "The openAI services are accessible through a REST API. REST is a\n",
        "protocol designed to call services (through) http requests (`POST` and\n",
        "`GET` requests)."
      ],
      "id": "e07bf919-8adf-453f-9e4f-3de2ef9c81ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "{'warning': 'This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations',\n",
              " 'id': 'cmpl-8VL769136bxJoq4c1qQhKbk7JStuX',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1702480020,\n",
              " 'model': 'text-davinci-002',\n",
              " 'choices': [{'text': ', there was a web socket, that you could message, that almost always engaged',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 4, 'completion_tokens': 16, 'total_tokens': 20}}"
            ]
          }
        }
      ],
      "source": [
        "# example of a an api call (from https://stackoverflow.com/questions/74578315/call-openai-api-with-python-requests-is-missing-a-model-parameter)\n",
        "import requests\n",
        "key = \"\"\n",
        "url = \" https://api.openai.com/v1/completions\"\n",
        "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
        "data = {'model': 'text-davinci-002', 'prompt': 'Once upon a time'}\n",
        "requests.post(url, headers=headers, json=data).json()"
      ],
      "id": "cell-3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Use the `requests` library to download the list of available\n",
        "    engines. Which ones can be used with the competions API.**"
      ],
      "id": "65739ed5-ca02-44bb-8f64-6fca832d1dcb"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Request call\n",
        "# the following call lists all available AI engines\n"
      ],
      "id": "cell-5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Locate the openAI API documentation. Find out how to complete the\n",
        "    following sentence:** *Le coup passa si près que le chapeau*\n",
        "\n",
        "2.  **Use the Chat api to complete the following (apocryphal)\n",
        "    dialogue:**\n",
        "\n",
        "-   *Lady Astor: If I were married to you, I would poison your tea*\n",
        "-   *Churchill:*\n",
        "\n",
        "## Python API\n",
        "\n",
        "1.  **Import `openai` python library. Check that version number is\n",
        "    \\>=1.**"
      ],
      "id": "bd066646-fadd-4c56-af47-f26336da753f"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import openai python library\n",
        "import openai"
      ],
      "id": "cell-12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  **Redo same exercises as with the Rest API.**\n",
        "\n",
        "## What is GPT’s favourite color?\n",
        "\n",
        "1.  **What is GPT’s answer when you ask “What is your favourite\n",
        "    color?”**\n",
        "\n",
        "2.  **Compare the responses: for the different engines, the different\n",
        "    types of calls. What is the difference between\n",
        "    instruct/chat/completion calls?**\n",
        "\n",
        "3.  **(bonus) By providing more context, can you override ChatGPT’s\n",
        "    default answer?**\n",
        "\n",
        "# Preference Survey Module\n",
        "\n",
        "The *The Preference Survey Module: A Validated Instrument for Measuring\n",
        "Risk, Time, and Social Preferences* by Falk et al has created a\n",
        "qualtative survey meant to measure preferences of humans in a such a way\n",
        "that it replicates incentivized experiments carried on in laboratories.\n",
        "\n",
        "In *AI responses to the preference survey module* Mimra and Winant, have\n",
        "adapted the same survey to measure the preference of common large\n",
        "language models.\n",
        "\n",
        "The goal here is to replicate one of the experiments to measure\n",
        "altruism.\n",
        "\n",
        "Two questions are asked:\n",
        "\n",
        "-   Imagine the following situation: you won 1,000 dollars in a\n",
        "    lottery.Considering your current situation, how much would you\n",
        "    donate to charity?\n",
        "\n",
        "-   How do you assess your willingness to share with others without\n",
        "    expecting anything in return when it comes to charity? Respond on a\n",
        "    scale from 0 0 to 10, where 0 means you are “completely unwilling to\n",
        "    share” and a 10 means you are “very willing to share”. You can also\n",
        "    use the values in-between to indicate where you fall on the scale.\n",
        "\n",
        "Eeach response should be normalized between 0 and 10. Then multliply the\n",
        "first response by 0.1845 and add the second response multiplied by\n",
        "0.3210, to get the final evaluation.\n",
        "\n",
        "1.  Design a prompt to measure the preferences from gpt4? What context\n",
        "    would you use?\n",
        "\n",
        "2.  How can you extract the result programmatically?"
      ],
      "id": "3a7be4b9-aa26-4b19-8915-f32a2bf3bad0"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}